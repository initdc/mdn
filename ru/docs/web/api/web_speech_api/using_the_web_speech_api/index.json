{"doc":{"isMarkdown":false,"isTranslated":true,"isActive":true,"flaws":{},"title":"Применение Web Speech API","mdn_url":"/ru/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API","locale":"ru","native":"Русский","sidebarHTML":"","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p class=\"summary\">Web Speech API предоставляет 2 основных типа функциональности — <a href=\"/ru/docs/Web/API/SpeechRecognition\">распознавание речи пользователя</a> и <a href=\"/en-US/docs/Web/API/SpeechSynthesis\">речевое воспроизведение текста</a>. Это предоставляет новые возможности для взаимодействия с интерфейсом и открывает перед нами новые горизонты создания уникального пользовательского опыта. Эта статья даёт краткое описание обоих направлений с примерами кода и ссылкой на работающее приложение онлайн.</p>"}},{"type":"prose","value":{"id":"распознавание_речи","title":"Распознавание речи","isH3":false,"content":"<p>Механизм распознавания речи способен принимать речевой поток через микрофон устройства, а затем проверять его, используя свои внутренние алгоритмы. Для более точной работы рекомендуется использовать интерфейс <a href=\"/ru/docs/Web/API/SpeechGrammar\">SpeechGrammar</a>, предоставляющий контейнер для определённого набора грамматики, которое ваше приложение должно использовать. Грамматика определяется с помощью <a href=\"https://www.w3.org/TR/jsgf/\" class=\"external\" rel=\" noopener\">JSpeech Grammar Format(JSGF.)</a>.</p>\n\n<p>После того, как пользовательская речь была распознана, алгоритм возвращает результат (список результатов) в качестве текстовой строки, с которой мы можем продолжить работу.</p>\n\n<div class=\"note notecard\" id=\"sect1\">\n<p><strong>Внимание:</strong> В Chrome распознавание речи на веб-странице завязано на взаимодействие с сервером. Ваш звук отправляется на веб-службу для обработки распознавания, поэтому приложение не будет работать в офлайн-режиме.</p>\n</div>"}},{"type":"prose","value":{"id":"демо","title":"Демо","isH3":true,"content":"<p>Для запуска демо достаточно перейти по <a href=\"https://ru.web-speech-api-example.cheliz.top/\" class=\"external\" rel=\" noopener\">ссылке на приложение </a>или скачать <a href=\"https://github.com/Oleg-Miniuk/ru_web_speech_example\" class=\"external\" rel=\" noopener\">репозиторий</a>, установить зависимости (<code>npm install</code>) и запустить приложение (<code>npm run start</code>), после чего открыть <strong>localhost:4001</strong> в браузере.</p>\n\n<p><img alt=\"\" src=\"https://pp.userapi.com/c831409/v831409509/1c0226/S_tm-BfW-U8.jpg\" loading=\"lazy\"></p>\n\n<p>после озвучки команды</p>\n\n<p><img alt=\"\" src=\"https://pp.userapi.com/c831409/v831409509/1c022e/uWRjlOvjopk.jpg\" loading=\"lazy\"></p>"}},{"type":"prose","value":{"id":"браузерная_поддержка","title":"Браузерная поддержка","isH3":true,"content":"<p>Поддержка интерфейса ещё только распространяется на основные браузеры, и на текущий момент ограничена следующим образом:</p>\n\n<ul>\n <li dir=\"ltr\">\n  <p dir=\"ltr\">Мобильный и десктопный Firefox поддерживает его в Gecko 44+ без префиксов, и его можно включить, установив значение флага <code>media.webspeech.recognition.enable</code> на <code>true</code> в <code>about:config</code></p>\n </li>\n <li dir=\"ltr\">\n  <p dir=\"ltr\">Chrome для настольных компьютеров и версия для Android поддерживали его с версии 33, но с прописанными префиксами, поэтому вам нужно использовать префиксную версию, например <code>webkitSpeechRecognition</code></p>\n </li>\n</ul>\n\n<p dir=\"ltr\">Традиционно, самая актуальная информация по поддержке чего-либо в браузерах на <a href=\"https://caniuse.com/#search=speech\" class=\"external\" rel=\" noopener\">caniuse</a>.</p>"}},{"type":"prose","value":{"id":"html_и_css","title":"HTML и CSS","isH3":true,"content":"<p>Разметка и стили предельно просты. У нас есть значок микрофона, на который мы можем кликнуть для начала записи, анимация звукозаписи, которая включается после клика, и фоновый контейнер, который будет изменять свой цвет, в зависимости от того, что озвучит пользователь.</p>\n\n<p>CSS задаёт простые отзывчивые стили, для корректного отображения и работы на всех устройствах</p>"}},{"type":"prose","value":{"id":"javascript","title":"JavaScript","isH3":true,"content":"<p>А вот на реализацию логики давайте обратим более пристальное внимание.</p>\n\n<h4 id=\"поддержка_chrome\">Поддержка Chrome </h4>\n\n<p>Как уже упоминалось ранее, в настоящее время Chrome поддерживает интерфейс распознавания речи с указанными префиксами, поэтому в начале нашего кода мы включаем строки префиксов для использования нужных объектов в Chrome и ссылки на объекты без префиксов для Firefox.</p>\n\n<pre class=\"notranslate\">const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nconst SpeechGrammarList = window.SpeechGrammarList || window.webkitSpeechGrammarList;\nconst SpeechRecognitionEvent = window.SpeechRecognitionEvent || window.webkitSpeechRecognitionEvent;\n</pre>\n\n<h4 id=\"грамматика\">Грамматика</h4>\n\n<p>Следующая часть нашего кода определяет грамматику, которую мы хотим, применять для поиска соответствий.</p>\n\n<p>Определяем следующие переменные:</p>\n\n<pre class=\"notranslate\">const colors = {\n  красный: 'red',\n  оранжевый: 'orange',\n  жёлтый: 'yellow',\n  зелёный: 'green',\n  голубой: 'blue',\n  синий: 'darkblue',\n  фиолетовый: 'violet'\n};\n\nconst colorsList = Object.keys(colors);\n\nconst grammar = '#JSGF V1.0; grammar colors; public &lt;color&gt; = ' + colorsList.join(' | ') + ' ;';\n\nФормат “грамматики“ используемой нами - это <a href=\"https://www.w3.org/TR/jsgf/\" class=\"external\" rel=\" noopener\">JSpeech Grammar Format</a> (JSGF) - по ссылке можете почитать про это больше.</pre>\n\n<p dir=\"ltr\">Быстро пробежимся по основным принципам:</p>\n\n<ul>\n <li dir=\"ltr\">\n  <p dir=\"ltr\">Линии разделены точкой с запятой, как и в JavaScript.</p>\n </li>\n <li dir=\"ltr\">\n  <p dir=\"ltr\">Первая строка - <code>#JSGF V1.0;</code> - указывает формат и версию. Это всегда необходимо включать в первую очередь.</p>\n </li>\n <li dir=\"ltr\">\n  <p dir=\"ltr\">Вторая строка указывает значение, которое мы хотим распознать. public объявляет, что это общедоступное правило, строка в угловых скобках определяет распознанное имя для этого значения (цвет), а список элементов, следующих за знаком равенства, - это альтернативные варианты, которые будут распознаны и могут быть приняты в качестве возможного значения. Обратите внимание, как каждый из них разделяется вертикальной линией (“|” - “pipe character”).</p>\n </li>\n <li dir=\"ltr\">\n  <p dir=\"ltr\">У вас может быть множество значений, определённых отдельно, как указано выше, и содержащих довольно сложные определения грамматики. Для нашего демонстрационного примера мы делаем все просто.</p>\n </li>\n</ul>\n\n<h4 id=\"подключение_грамматики_к_нашему_распознаванию_речи\"><strong id=\"docs-internal-guid-5c511c58-7fff-3f7e-ba1f-2130d83c633a\">Подключение грамматики к нашему распознаванию речи</strong></h4>\n\n<p>Следующее, что нужно сделать, это определить экземпляр объекта распознавания речи для управления записью нашего приложения.</p>\n\n<p dir=\"ltr\">Это делается с помощью конструктора <code>SpeechRecognition()</code>. Мы также создаём новый речевой грамматический список, чтобы содержать нашу грамматику, используя конструктор <code>SpeechGrammarList()</code>.</p>\n\n<pre class=\"notranslate\">const recognition = new SpeechRecognition();\nconst speechRecognitionList = new SpeechGrammarList();</pre>\n\n<p>Добавляем нашу “грамматику” в список, используя метод <code>SpeechGrammarList.addFromString()</code>. Он принимает в качестве параметров строку, плюс необязательное значение веса, которое указывает важность этой грамматики по отношению к другим грамматикам, доступным в списке (может быть от 0 до 1 включительно). Добавленная грамматика доступна в списке как экземпляр объекта <code>SpeechGrammar</code>.</p>\n\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code>speechRecognitionList<span class=\"token punctuation\">.</span><span class=\"token function\">addFromString</span><span class=\"token punctuation\">(</span>grammar<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre></div>\n\n<p dir=\"ltr\">Затем мы добавляем <code><a href=\"/en-US/docs/Web/API/SpeechGrammarList\">SpeechGrammarList</a></code> к уже созданному объекту распознавания речи, присваивая его значение свойству <code><a href=\"/en-US/docs/Web/API/SpeechRecognition/grammars\">SpeechRecognition.grammars</a></code>. Также зададим ещё несколько свойств объекту, прежде чем двигаться дальше:</p>\n\n<ul>\n <li dir=\"ltr\">\n  <p dir=\"ltr\"><code><a href=\"/en-US/docs/Web/API/SpeechRecognition/lang\">SpeechRecognition.lang</a></code>: устанавливает язык распознавания. Его установка - это хорошая практика, поэтому рекомендуется не пропускать.</p>\n </li>\n <li dir=\"ltr\">\n  <p dir=\"ltr\"><code><a href=\"/en-US/docs/Web/API/SpeechRecognition/interimResults\">SpeechRecognition.interimResults</a></code>: определяет, должна ли система распознавания речи возвращать промежуточные результаты или только конечные результаты. Только конечные результаты подойдут для этой нашего простого приложения.</p>\n </li>\n <li dir=\"ltr\">\n  <p dir=\"ltr\"><code><a href=\"/en-US/docs/Web/API/SpeechRecognition/maxAlternatives\">SpeechRecognition.maxAlternatives</a></code>: устанавливает количество альтернативных потенциальных совпадений, которые должны быть возвращены на каждый результат. Иногда это может быть полезно, скажем, если результат распознан не точно, и вы хотите отобразить пользователю список вариантов. Но это для простого примера это не нужно, поэтому мы просто указываем один (который по сути является вариантом по умолчанию).</p>\n </li>\n</ul>\n\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code>recognition<span class=\"token punctuation\">.</span>grammars <span class=\"token operator\">=</span> speechRecognitionList<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">//recognition.continuous = false;</span>\nrecognition<span class=\"token punctuation\">.</span>lang <span class=\"token operator\">=</span> <span class=\"token string\">'ru-RU'</span><span class=\"token punctuation\">;</span>\nrecognition<span class=\"token punctuation\">.</span>interimResults <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\nrecognition<span class=\"token punctuation\">.</span>maxAlternatives <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n</code></pre></div>\n\n<div class=\"note notecard\" id=\"sect2\">\n<p dir=\"ltr\"><strong>Внимание:</strong>  <code><a href=\"/en-US/docs/Web/API/SpeechRecognition/continuous\">SpeechRecognition.continuous</a></code> задаёт, отслеживаются ли продолжающиеся результаты или только 1 результат, каждый раз, когда запись начата. Это закомментировано, поскольку данное свойство в ещё не реализовано в Gecko.</p>\n\n<p dir=\"ltr\">Вы можете получить аналогичный результат, просто прекратив распознавание после получения первого результата.</p>\n</div>\n\n<h4 id=\"запуск_распознавания_речи\">Запуск распознавания речи</h4>\n\n<p>После получения ссылок на DOM-элементы, необходимые нам для обработки пользовательских событий и обновления цвета фона приложения, мы реализуем обработчик <code>onclick</code>, чтобы при нажатии на значок микрофона сервис распознавания речи начинал работу. Запуск происходит путём вызова функции <code>SpeechRecognition.start()</code>.</p>\n\n<pre class=\"notranslate\">microphoneIcon.onclick = function() {\n  recognition.start();\n  console.log('Ready to receive a color command.');\n};\n\nrecognition.onaudiostart = function() {\n  microphoneWrapper.style.visibility = 'hidden';\n  audioRecordAnimation.style.visibility = 'visible';\n};\n</pre>\n\n<h4 id=\"получение_и_обработка_результата\">Получение и обработка результата</h4>\n\n<p>После того, как процесс распознавания речи был запущен, есть много обработчиков событий, которые могут быть использованы для работы с результатом и другой сопутствующей информацией (см. <a href=\"/ru/docs/Web/API/SpeechRecognition#%D0%9E%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%87%D0%B8%D0%BA%D0%B8_%D1%81%D0%BE%D0%B1%D1%8B%D1%82%D0%B8%D0%B9\">Список обработчиков событий SpeechRecognition</a>.) Наиболее распространённый, который вы, вероятно, и будете использовать, это <a href=\"/en-US/docs/Web/API/SpeechRecognition/onresult\">SpeechRecognition.onresult</a>, который запускается сразу после получения успешного результата. Значение цвета получаем вызовом функции <code>getColor()</code></p>\n\n<pre class=\"notranslate\">function getColor(speechResult) {\n  for (let index = 0; index &lt; colorsList.length; index += 1) {\n    if (speechResult.indexOf(colorsList[index]) !== -1) {\n      const colorKey = colorsList[index];\n      return [colorKey, colors[colorKey]];\n    }\n  }\n  return null;\n}\n\nrecognition.onresult = function(event) {\n  const last = event.results.length - 1;\n  const colors = getColor(event.results[last][0].transcript);\n  recognitionTextResult.textContent = 'Результат: ' + colors[0];\n  speechRecognitionSection.style.backgroundColor = colors[1];\n  console.log('Confidence: ' + event.results[0][0].confidence);\n};</pre>\n\n<p>Третья строка здесь выглядит немного усложнённой, поэтому давайте разберёмся с ней подробнее. Свойство <code><a href=\"/en-US/docs/Web/API/SpeechRecognitionEvent/results\">SpeechRecognitionEvent.results</a></code> возвращает объект <code><a href=\"/en-US/docs/Web/API/SpeechRecognitionResultList\">SpeechRecognitionResultList</a></code>, содержащий в себе другие объекты типа <code><a href=\"/en-US/docs/Web/API/SpeechRecognitionResult\">SpeechRecognitionResult</a></code>. У него есть геттер, поэтому он может быть доступен как массив, поэтому переменная <code>last</code> определяет ссылку на <code>SpeechRecognitionResult</code> из списка. Каждый объект <code>SpeechRecognitionResult</code> содержит объекты <code><a href=\"/en-US/docs/Web/API/SpeechRecognitionAlternative\">SpeechRecognitionAlternative</a></code>, которые содержат отдельные распознанные слова. Они также имеют геттеры, поэтому к ним можно получить доступ как к массивам, поэтому логично, что [0] возвращает значение <code>SpeechRecognitionAlternative</code> по индексу 0. Затем мы возвращаем строку, содержащую индивидуально распознанный результат, используя который и можем установить цвет фона.</p>\n\n<p>Мы также используем свойство <code><a href=\"/en-US/docs/Web/API/SpeechRecognition/onspeechend\">SpeechRecognition.speechend</a></code>, чтобы задать обработчик на завершение работы распознавателя речи (вызов <code><a href=\"/en-US/docs/Web/API/SpeechRecognition/stop\">SpeechRecognition.stop()</a></code> ), как только одно слово было распознано, и входящий речевой поток был остановлен.</p>\n\n<pre class=\"notranslate\">recognition.onspeechend = function() {\n  recognition.stop();\n  microphoneWrapper.style.visibility = 'visible';\n  audioRecordAnimation.style.visibility = 'hidden';\n};\n\n</pre>\n\n<h4 id=\"обработка_ошибок\">Обработка ошибок</h4>\n\n<p>Последние два обработчика используются для отлова ошибок: когда речь была признана не в соответствии с определённой грамматикой или произошла ошибка. По логике, <code><a href=\"/en-US/docs/Web/API/SpeechRecognition/onnomatch\">SpeechRecognition.onnomatch</a></code>, должен обрабатывать первый случай, но обратите внимание, что на данный момент он не срабатывает правильно в Firefox или Chrome, он просто возвращает все, что было распознано в любом случае:</p>\n\n<pre class=\"notranslate\">recognition.onnomatch = function(event) {\n  alert(\"I didn't recognise that color.\");\n};</pre>\n\n<p><code><a href=\"/en-US/docs/Web/API/SpeechRecognition/onerror\">SpeechRecognition.onerror</a></code> обрабатывает случаи, когда имела место быть фактическая ошибка при распознавании. Свойство <code><a href=\"/en-US/docs/Web/API/SpeechRecognitionError/error\">SpeechRecognitionError.error</a></code> содержит возвращаемую фактическую ошибку:</p>\n\n<pre class=\"notranslate\">recognition.onerror = function(event) {\n  alert(`Error occurred in recognition: ${event.error}`);\n};\n</pre>"}},{"type":"prose","value":{"id":"синтез_речи","title":"Синтез речи","isH3":false,"content":"<p>Синтез речи (text-to-speech или tts) подразумевает получение синтезированного текста приложения и его речевое воспроизведение.<br>\n <br>\n Для этой цели Web Speech API предоставляет интерфейс - <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis\">SpeechSynthesis</a></code> - плюс ряд близких интерфейсов для нужного нам воспроизведения текста (utterances - “дикция”), набор голосов, которыми приложение будет “говорить”, и т. д.<br>\n Опять же, большинство ОС имеют некоторые встроенные системы синтеза речи, которые будут задействованы нашим API для этой цели.</p>"}},{"type":"prose","value":{"id":"демо_2","title":"Демо","isH3":true,"content":"<p>То же самое приложение из предыдущего примера.<br>\n <a href=\"https://ru.web-speech-api-example.cheliz.top/\" class=\"external\" rel=\" noopener\">Ссылка на приложение</a> или <a href=\"https://github.com/Oleg-Miniuk/ru_web_speech_example\" class=\"external\" rel=\" noopener\">репозиторий</a> (клонируем, затем <code>npm install &amp;&amp; npm run start</code> в терминале, после чего открыть <strong>localhost:4001</strong> в браузере).<br>\n <br>\n Пользовательский интерфейс включает в себя набор элементов для ввода текста, задания высоты тона, скорости воспроизведения и непосредственного выбора голоса, которым будет текст произнесён.</p>\n\n<p>После ввода текста вы можете нажать <strong>Play</strong> для запуска.</p>\n\n<p><img alt=\"\" src=\"https://pp.userapi.com/c847220/v847220505/1103b9/Jlnq5hDThyQ.jpg\" loading=\"lazy\"></p>"}},{"type":"prose","value":{"id":"браузерная_поддержка_2","title":"Браузерная поддержка","isH3":true,"content":"<p>Поддержка интерфейса ещё только распространяется на основные браузеры, и на текущий момент ограничена следующим образом:</p>\n\n<ul>\n <li dir=\"ltr\">\n  <p dir=\"ltr\">Мобильный и десктопный Firefox поддерживает его в Gecko 44+ без префиксов, и его можно включить, установив значение флага media.webspeech.synth.enabled на true в about:config</p>\n </li>\n <li dir=\"ltr\">\n  <p dir=\"ltr\">Chrome для настольных компьютеров и версия для Android поддерживали его с версии 33 без префиксов</p>\n </li>\n</ul>\n\n<ul>\n <li>\n  <p>Традиционно, самая актуальная информация по поддержке чего-либо в браузерах на <a href=\"https://caniuse.com/#search=SpeechSynthesis\" class=\"external\" rel=\" noopener\">caniuse</a>.</p>\n </li>\n</ul>"}},{"type":"prose","value":{"id":"html_и_css_2","title":"HTML и CSS","isH3":true,"content":"<p>HTML и CSS снова достаточно тривиальны.<br>\n Заголовок и форму с некоторыми простыми элементами управления.<br>\n Элемент <code>&lt;select&gt; </code>изначально пуст, но заполняется с помощью <code>&lt;option&gt;</code> через JavaScript (см. ниже).</p>\n\n<p>CSS задаёт простые отзывчивые стили, для корректного отображения и работы на всех устройствах</p>\n\n<pre class=\"notranslate\">&lt;section&gt;\n  &lt;h1&gt;Синтез речи&lt;/h1&gt;\n  &lt;p&gt;Введите текст в поле ниже и нажмите кнопку \"Play\", чтобы прослушать запись. Выбирайте возможные голоса из списка ниже&lt;/p&gt;\n\n  &lt;form&gt;\n    &lt;input type=\"text\" class=\"text\"&gt;\n    &lt;div class=\"row\"&gt;\n      &lt;div class=\"values-box\"&gt;\n        &lt;div class=\"value-box\"&gt;\n          &lt;div&gt;Темп (Rate)&lt;/div&gt;\n          &lt;div class=\"value value--rate-value\"&gt;1&lt;/div&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"value-box\"&gt;\n          &lt;div&gt;Диапазон (Pitch)&lt;/div&gt;\n          &lt;div class=\"value value--pitch-value\"&gt;1&lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n\n      &lt;div class=\"ranges-box\"&gt;\n        &lt;input type=\"range\" min=\"0.5\" max=\"2\" value=\"1\" step=\"0.1\" id=\"rate\"&gt;\n        &lt;input type=\"range\" min=\"0\" max=\"2\" value=\"1\" step=\"0.1\" id=\"pitch\"&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n\n    &lt;select&gt;\n    &lt;/select&gt;\n\n    &lt;button id=\"play\" type=\"submit\"&gt;Play&lt;/button&gt;\n\n  &lt;/form&gt;</pre>"}},{"type":"prose","value":{"id":"javascript_2","title":"JavaScript","isH3":true,"content":"<p>Давайте более детально рассмотрим скрипт, задающий логику нашему приложения.</p>\n\n<h4 id=\"задание_переменных\">Задание переменных</h4>\n\n<p>Прежде всего, создаём ссылки на все нужные нам DOM-элементы.</p>\n\n<p dir=\"ltr\">Входная точка API - <code><a href=\"/en-US/docs/Web/API/Window/speechSynthesis\">window.speechSynthesis</a></code>, возвращает экземпляр <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis\">SpeechSynthesis</a></code>, интерфейс контроллера для синтеза речи в вебе.</p>\n\n<pre class=\"notranslate\">const synth = window.speechSynthesis;\nconst inputForm = document.querySelector('form');\nconst inputTxt = document.querySelector('.text');\nconst voicesList = document.querySelector('select');\nconst pitch = document.querySelector('#pitch');\nconst pitchValue = document.querySelector('.value--pitch-value');\nconst rate = document.querySelector('#rate');\nconst rateValue = document.querySelector('.value--rate-value');\nlet voices = [];</pre>\n\n<h4 id=\"заполнение_выпадающего_списка\">Заполнение выпадающего списка</h4>\n\n<p>Чтобы заполнить элемент <code><a href=\"/ru/docs/Web/HTML/Element/select\">&lt;select&gt;</a></code> различными вариантами голоса, доступных на устройстве, напишем функцию <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis/getVoices\">populateVoiceList()</a></code>. Сначала мы вызываем <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis/getVoices\">SpeechSynthesis.getVoices()</a></code>, который возвращает список всех доступных вариантов голосов, представленных объектами <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisVoice\">SpeechSynthesisVoice</a></code>. Затем мы проходимся по списку, создавая элемент <code><a href=\"/ru/docs/Web/HTML/Element/option\">&lt;option&gt;</a></code> для каждого отдельного случая, задаём его текстовое содержимое, соответствующее названию голоса (взято из <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisVoice/name\">SpeechSynthesisVoice.name</a></code>), языка голоса (из <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisVoice/lang\">SpeechSynthesisVoice.lang</a></code>), и  “по умолчанию”, если голос является голосом по умолчанию для механизма синтеза (проверяется, если функция <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisVoice/default\">SpeechSynthesisVoice.default</a></code> возвращает значение <code>true</code>.)</p>\n\n<p>Мы также задаём <code>data-</code> атрибуты для каждого варианта, содержащие имя и язык связанного голоса, благодаря чему мы можем легко их собрать их позже, а затем вложить все варианты в качестве дочерних элементов нашего списка (<code>&lt;select&gt;</code>).</p>\n\n<pre class=\"notranslate\">function populateVoiceList() {\n  voices = synth.getVoices();\n  const selectedIndex =\n  voicesList.selectedIndex &lt; 0 ? 0 : voicesList.selectedIndex;\n  voicesList.innerHTML = '';\n\n  for(i = 0; i &lt; voices.length ; i++) {\n    const option = document.createElement('option');\n    option.textContent = voices[i].name + ' (' + voices[i].lang + ')';\n\n    if(voices[i].default) {\n      option.textContent += ' -- DEFAULT';\n    }\n\n    option.setAttribute('data-lang', voices[i].lang);\n    option.setAttribute('data-name', voices[i].name);\n    voiceSelect.appendChild(option);\n  }\n  voicesList.selectedIndex = selectedIndex;\n}</pre>\n\n<p>Когда мы собираемся запустить функцию, мы делаем следующее. Это связано с тем, что Firefox не поддерживает свойство <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis/onvoiceschanged\">SpeechSynthesis.onvoiceschanged</a></code> и будет только возвращать список голосов при запуске <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis/getVoices\">SpeechSynthesis.getVoices()</a></code>. Однако, в Chrome вам нужно дождаться триггера события перед заполнением списка, следовательно, нужно условие, описанное в блоке с <code>if</code> ниже.</p>\n\n<pre class=\"notranslate\">populateVoiceList();\n  if (speechSynthesis.onvoiceschanged !== undefined) {\n  speechSynthesis.onvoiceschanged = populateVoiceList;\n}</pre>\n\n<h4 id=\"озвучка_введённого_текста\">Озвучка введённого текста</h4>\n\n<p>Затем мы создаём обработчик событий, чтобы начать “произносить” текст, введённый в текстовом поле, при нажатии на кнопку <code>Enter/Return</code> или на <code>Play</code>. Для этого используем обработчик <code><a href=\"/ru/docs/Web/API/GlobalEventHandlers/onsubmit\">onsubmit</a></code> в html-формы. В функции-обработчике <code>speak()</code> мы создаём новый экземпляр <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance/SpeechSynthesisUtterance\">SpeechSynthesisUtterance()</a></code>, передавая значение текстового поля в конструктор.</p>\n\n<p dir=\"ltr\">Затем нам нужно выяснить, какой голос использовать. Мы используем свойство <code><a href=\"/ru/docs/Web/API/HTMLSelectElement\">HTMLSelectElement</a></code> <code>selectedOptions</code> для получения выбранного элемента <code><a href=\"/en-US/docs/Web/HTML/Element/option\">&lt;option&gt;</a></code>, у которого берём атрибут data-name, и находим объект <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisVoice\">SpeechSynthesisVoice</a></code>, имя которого соответствует значению имеющегося атрибута. После этого устанавливаем соответствующий “голосовой” объект как значение свойства <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance/voice\">SpeechSynthesisUtterance.voice</a></code>.</p>\n\n<p>Наконец, мы устанавливаем <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance/pitch\">SpeechSynthesisUtterance.pitch</a></code> (высота тона) и <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance/rate\">SpeechSynthesisUtterance.rate</a></code> (скорость) в соответствии со значениями соответствующих элементов формы. Затем, после всего проделанного, мы запускаем произношение речи, вызывая <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis/speak\">SpeechSynthesis.speak()</a></code>, и передавая ему экземпляр <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance\">SpeechSynthesisUtterance</a></code> в качестве аргумента.</p>\n\n<p>Внутри функции <code>speak()</code> мы выполняем проверку на то, воспроизводится ли речь в данный момент, с помощью свойства <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis/speaking\">SpeechSynthesis.speaking</a></code> <br>\n Если да, то останавливаем процесс функцией <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis/cancel\" title=\"The cancel() method of the SpeechSynthesis interface removes all utterances from the utterance queue.\">SpeechSynthesis.cancel()</a></code> и запускаем рекурсивно заново.</p>\n\n<p>В последней части функции мы включаем обработчик <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance/onpause\">SpeechSynthesisUtterance.onpause</a></code>, чтобы показать пример применения <code><a href=\"/en-US/docs/Web/API/SpeechSynthesisEvent\">SpeechSynthesisEvent</a></code> в различных ситуациях. Вызов <code><a href=\"/en-US/docs/Web/API/SpeechSynthesis/pause\">SpeechSynthesis.pause() </a></code>возвращает сообщение с информацией о номере символа и слове, на котором была вызвана пауза.</p>\n\n<p>Наконец, мы назовём <code>blur()</code> у текстового поля. Это, прежде всего, для того, чтобы скрыть клавиатуру в ОС Firefox.</p>\n\n<pre class=\"notranslate\">function speak() {\n  if (synth.speaking) {\n    console.error('speechSynthesis.speaking');\n    synth.cancel();\n    setTimeout(speak, 300);\n  } else if (inputTxt.value !== '') {\n      const utterThis = new SpeechSynthesisUtterance(inputTxt.value);\n      utterThis.onend = function(event) {\n        console.log('SpeechSynthesisUtterance.onend');\n      };\n\n      utterThis.onerror = function(event) {\n        console.error('SpeechSynthesisUtterance.onerror');\n      };\n      const selectedOption = voicesList.selectedOptions[0].getAttribute('data-name');\n\n      for (i = 0; i &lt; voices.length; i++) {\n        if (voices[i].name === selectedOption) {\n          utterThis.voice = voices[i];\n        }\n      }\n\n      utterThis.onpause = function(event) {\n        const char = event.utterance.text.charAt(event.charIndex);\n        console.log('Speech paused at character ' +\n          event.charIndex +\n          ' of \"' +\n          event.utterance.text +\n          '\", which is \"' +\n          char +\n          '\".'\n        );\n      };\n\n      utterThis.pitch = pitch.value;\n      utterThis.rate = rate.value;\n      synth.speak(utterThis);\n    }\n}\n\ninputForm.onsubmit = function(event) {\n  event.preventDefault();\n  speak();\n  inputTxt.blur();\n};\n</pre>\n\n<h4 id=\"обновление_отображаемых_значений_высоты_тона_и_скорости\">Обновление отображаемых значений высоты тона и скорости</h4>\n\n<p>Последний пример кода просто обновляет значения высоты тона/скорости, отображаемые в пользовательском интерфейсе, каждый раз, когда позиции ползунка перемещаются.</p>\n\n<pre class=\"notranslate\">pitch.onchange = function() {\n  pitchValue.textContent = pitch.value;\n};\n\nrate.onchange = function() {\n  rateValue.textContent = rate.value;\n};\n</pre>"}}],"toc":[{"text":"Распознавание речи","id":"распознавание_речи"},{"text":"Синтез речи","id":"синтез_речи"}],"summary":"Web Speech API предоставляет 2 основных типа функциональности — распознавание речи пользователя и речевое воспроизведение текста. Это предоставляет новые возможности для взаимодействия с интерфейсом и открывает перед нами новые горизонты создания уникального пользовательского опыта. Эта статья даёт краткое описание обоих направлений с примерами кода и ссылкой на работающее приложение онлайн.","popularity":0.0003,"modified":"2022-10-01T03:41:16.000Z","other_translations":[{"title":"Using the Web Speech API","locale":"en-US","native":"English (US)"},{"title":"Uso de la Web Speech API","locale":"es","native":"Español"},{"title":"Utiliser l'API Web Speech","locale":"fr","native":"Français"},{"title":"Web Speech APIを使う","locale":"ja","native":"日本語"},{"title":"使用 Web Speech API","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"ru/web/api/web_speech_api/using_the_web_speech_api","github_url":"https://github.com/mdn/translated-content/blob/main/files/ru/web/api/web_speech_api/using_the_web_speech_api/index.html","last_commit_url":"https://github.com/mdn/translated-content/commit/921c46a374ab0a9f4cc809af0370f8c412e54701","filename":"index.html"},"parents":[{"uri":"/ru/docs/Web","title":"Веб-технологии для разработчиков"},{"uri":"/ru/docs/Web/API","title":"Интерфейсы веб API"},{"uri":"/ru/docs/Web/API/Web_Speech_API","title":"Web Speech API"},{"uri":"/ru/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API","title":"Применение Web Speech API"}],"pageTitle":"Применение Web Speech API - Интерфейсы веб API | MDN","noIndexing":false}}