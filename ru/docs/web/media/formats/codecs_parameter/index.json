{"doc":{"isMarkdown":false,"isTranslated":true,"isActive":true,"flaws":{},"title":"Параметр \"codecs\" для распространённых типов носителей","mdn_url":"/ru/docs/Web/Media/Formats/codecs_parameter","locale":"ru","native":"Русский","sidebarHTML":"\n<ol></ol>\n","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<div id=\"sect1\"></div>\n\n<div id=\"sect2\">На базовом уровне, можно задать тип медиа файла, используя простой</div>\n\n<p><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Glossary/mime\">MIME <small>(en-US)</small></a> тип, такой как  <code>video/mp4</code> или <code>audio/mpeg</code>. Однако, многие медиа типы, особенно те, которые поддерживают видео дорожки, более привлекательные из-за способности более точного описания содержащегося формата данных. Например, просто описывая видео в  файле <a href=\"/en-US/docs/Web/Media/Formats/Containers#mp4\">MPEG-4</a>  с  MIME типом <code>video/mp4</code> ничего не скажет о том, какой формат в действительности он содержит.</p>\n\n<p>По этой причине в MIME тип может быть добавлен параметр  <code>codecs</code> , описывающий медиа контент, предоставляя более подробную информацию о содержимом. Эта информация может содержать, к примеру, профиль видео кодека, или тип, используемый аудио треками, и так далее.</p>\n\n<p>В этом руководстве кратко рассматривается синтаксис параметра <code>codecs </code>мультимедийного типа и его использование со строкой, описывающей  MIME тип, для предоставления подробных сведений о содержимом аудио- или видеоматериалов, помимо простого указания типа</p>"}},{"type":"prose","value":{"id":"общий_синтаксис","title":"Общий синтаксис","isH3":false,"content":"<p>Основной медиатип определяется установкой строкового значения  (<code>audio</code>, <code>video</code>, и т.д.), после которого идёт символ слеша (<code>/</code>), затем указывается формат контейнера, который будет содержать информацию:</p>\n\n<dl>\n <dt id=\"audiompeg\"><code>audio/mpeg</code></dt>\n <dd>Аудио файл, использующий тип файла <a href=\"/en-US/docs/Web/Media/Formats/Containers#mpeg\">MPEG</a> , к примеру, MP3.</dd>\n <dt id=\"videoogg\"><code>video/ogg</code></dt>\n <dd>Видео файл, использующий тип файла  <a href=\"/en-US/docs/Web/Media/Formats/Containers#ogg\">Ogg</a>.</dd>\n <dt id=\"videomp4\"><code>video/mp4</code></dt>\n <dd>Видео файл, использующий тип файла  <a href=\"/en-US/docs/Web/Media/Formats/Containers#mp4\">MPEG-4</a>.</dd>\n <dt id=\"videoquicktime\"><code>video/quicktime</code></dt>\n <dd>Видео файл, Apple формата <a href=\"/en-US/docs/Web/Media/Formats/Containers#quicktime\">QuickTime</a>. Как уже отмечалось, этот формат обычно  используется в Сети, поскольку требует использования плагинов.</dd>\n</dl>\n\n<p>Однако эти MIME являются не прозрачными. Все эти типы поддерживают несколько кодеков, и эти кодеки могут содержать несколько профилей, уровней , и других факторов конфигурирования. По этой причине указывается строковый параметр медиа типа <code>codecs</code>.</p>\n\n<p>Для его добавления, перед ним ставиться точка с запятой (<code>;</code>) , за которой следует строка  <code>codecs=</code> , в значении указывается формат содержимого файла. Некоторые типы носителей позволяют указывать только имена используемых кодеков, в то время как другие позволяют также указывать различные ограничения для этих кодеков. Вы можете указать несколько кодеков, разделяя их запятыми.</p>\n\n<dl>\n <dt id=\"audioogg_codecsvorbis\"><code>audio/ogg; codecs=vorbis</code></dt>\n <dd>Файл <a href=\"/en-US/docs/Web/Media/Formats/Containers#ogg\">Ogg</a> содержит  <a href=\"/en-US/docs/Web/Media/Formats/Audio_codecs#vorbis\">Vorbis</a> аудио трек.</dd>\n <dt id=\"videowebm_codecsvp8_vorbis\"><code>video/webm; codecs=\"vp8, vorbis\"</code></dt>\n <dd>Файл <a href=\"/en-US/docs/Web/Media/Formats/Containers#webm\">WebM</a> , содержащий <a href=\"/en-US/docs/Web/Media/Formats/Video_codecs#vp8\">VP8</a> видео и/или <a href=\"/en-US/docs/Web/Media/Formats/Audio_codecs#vorbis\">Vorbis</a> аудио.</dd>\n <dt id=\"videomp4_codecsavc1.4d002a\"><code>video/mp4; codecs=\"avc1.4d002a\"</code></dt>\n <dd>Файл <a href=\"/en-US/docs/Web/Media/Formats/Containers#mp4\">MPEG-4</a> , содержащий  <a href=\"/en-US/docs/Web/Media/Formats/Video_codecs#avc_(h.264)\">AVC</a> (H.264) видео, Основной профиль, Уровень 4.2.</dd>\n</dl>\n\n<p>Как и в случае с  любым параметром MIME типа , <code>codecs</code> должен заменяться на <code>codecs*</code> (обратите внимание на символ звёздочки, <code>*</code>) , если какое-либо из свойств кодека использует специальные символы для указания дополнительной информации (языковые отметки, кодировка байтов в шестнадцатеричные значения и т.д.), входящие в <a href=\"https://datatracker.ietf.org/doc/html/rfc2231#section-4\" class=\"external\" rel=\" noopener\">RFC 2231, секция 4: MIME Parameter Value and Encoded Word Extensions</a>. Можно использовать функции JavaScript <a href=\"/ru/docs/Web/JavaScript/Reference/Global_Objects/encodeURI\"><code>encodeURI()</code></a> для кодирования списка параметров, можно использовать   <a href=\"/ru/docs/Web/JavaScript/Reference/Global_Objects/decodeURI\"><code>decodeURI()</code></a> для декодирования предварительно закодированного списка параметров.</p>\n\n<div class=\"note notecard\" id=\"sect3\">\n<p> Когда используется параметр <code>codecs</code>, указанный список кодеков должен включать каждый кодек, используемый для содержимого файла Список также может содержать кодеки, которых нет в файле.</p>\n</div>"}},{"type":"prose","value":{"id":"свойства_кодеков_для_контейнеров","title":"Свойства кодеков для контейнеров","isH3":false,"content":"<p>Контейнеры ниже поддерживают расширенные свойства кодеков в своих параметрах <code>codecs</code> :</p>\n\n<div class=\"index\" id=\"sect4\">\n<ul>\n <li><a href=\"#iso-bmff\">3GP</a></li>\n <li><a href=\"#av1\">AV1</a></li>\n <li><a href=\"#iso-bmff\">ISO BMFF</a></li>\n <li><a href=\"#iso-bmff\">MPEG-4</a></li>\n <li><a href=\"#iso-bmff\">QuickTime</a></li>\n <li><a href=\"#webm\">WebM</a></li>\n</ul>\n</div>\n\n<p>Несколько ссылок выше входят в одину и то же секцию, потому, что все медиатипы основаны на файловом формате  ISO Base Media File Format (ISO BMFF), поэтому они  используют тот же синтаксис.</p>"}},{"type":"prose","value":{"id":"av1","title":"AV1","isH3":true,"content":"<p>Синтаксис параметра <code>codecs</code> для AV1 определяется спецификацией <a href=\"https://aomediacodec.github.io/av1-isobmff\" class=\"external\" rel=\" noopener\">AV1 Codec ISO Media File Format Binding</a> , секция 5: <a href=\"https://aomediacodec.github.io/av1-isobmff/#codecsparam\" class=\"external\" rel=\" noopener\">Строки параметра codecs </a>.</p>\n\n<pre class=\"notranslate\">av01.P.LLT.DD[.M[.CCC[.cp[.tc[.mc[.F]]]]]]</pre>\n\n<p>Компоненты строковых параметров кодеков описываются более подробно в таблице ниже. Каждый компонент имеет фиксированное количество символов, и если значение меньше этой длины, оно должно быть дополнено начальными нулями.</p>\n\n<table class=\"standard-table\">\n <caption>AV1 компоненты строковых параметров кодека</caption>\n <thead>\n  <tr>\n   <th scope=\"col\">Компонент</th>\n   <th scope=\"col\">Описание</th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td><code>P</code></td>\n   <td>\n    <p>Однознаковый номер профиля:</p>\n\n    <table class=\"standard-table\">\n     <caption>AV1 номера профилей</caption>\n     <thead>\n      <tr>\n       <th scope=\"col\">Номер профиля</th>\n       <th scope=\"col\">Описание</th>\n      </tr>\n     </thead>\n     <tbody>\n      <tr>\n       <td>0</td>\n       <td>\"Основной\" профиль; поддерживает  YUV 4:2:0 или одноцветный поток битов с глубиной  8 или 10 бит на компонент.</td>\n      </tr>\n      <tr>\n       <td>1</td>\n       <td>\"Высокий\" профиль добавляет поддержку выбора цветности  4:4:4.</td>\n      </tr>\n      <tr>\n       <td>2</td>\n       <td>\"Профессиональный\" профиль добавляет поддержку выбора цветности 4:2:2 и 12 бит на один цвет компонента.</td>\n      </tr>\n     </tbody>\n    </table>\n   </td>\n  </tr>\n  <tr>\n   <td><code>LL</code></td>\n   <td>Двухзначный номер уровня, который преобразуется в формат X.Y, где<code>X = 2 + (LL &gt;&gt; 2)</code> , и  <code>Y = LL &amp; 3</code>. Подробнее <a href=\"https://aomediacodec.github.io/av1-spec/#levels\" class=\"external\" rel=\" noopener\">Дополнение A, секция 3</a> в спецификации  AV1 .</td>\n  </tr>\n  <tr>\n   <td><code>T</code></td>\n   <td>The one-character tier indicator. For the Main tier (<code>seq_tier</code> equals 0), this character is the letter <code>M</code>. For the High tier (<code>seq_tier</code> is 1), this character is the letter <code>H</code>. The High tier is only available for level 4.0 and up.</td>\n  </tr>\n  <tr>\n   <td><code>DD</code></td>\n   <td>The two-digit component bit depth. This value must be one of 8, 10, or 12; which values are valid varies depending on the profile and other properties.</td>\n  </tr>\n  <tr>\n   <td><code>M</code></td>\n   <td>The one-digit monochrome flag; if this is 0, the video includes the U and V planes in addition to the Y plane. Otherwise, the video data is entirely in the Y plane and is therefore monochromatic. See <a href=\"/en-US/docs/Web/Media/Formats/Video_concepts#yuv\">YUV</a> в <a href=\"/en-US/docs/Web/Media/Formats/Video_concepts\">Digital video concepts</a> for details on how the YUV color system works. The default value is 0 (not monochrome).</td>\n  </tr>\n  <tr>\n   <td><code>CCC</code></td>\n   <td>\n    <p><code>CCC</code> indicates the chroma subsampling as three digits. The first digit is <code>subsampling_x</code>, the second is <code>subsampling_y</code>. If both of those are 1, the third is the value of <code>chroma_sample_position</code>; otherwise, the third digit is always 0. This, combined with the <code>M</code> component, can be used to construct the chroma subsampling format:</p>\n\n    <table class=\"standard-table\">\n     <caption>Determining the chroma subsampling format</caption>\n     <thead>\n      <tr>\n       <th scope=\"col\">subsampling_x</th>\n       <th scope=\"col\">subsampling_y</th>\n       <th scope=\"col\">Monochrome flag</th>\n       <th scope=\"col\">Chroma subsampling format</th>\n      </tr>\n     </thead>\n     <tbody>\n      <tr>\n       <td>0</td>\n       <td>0</td>\n       <td>0</td>\n       <td>YUV 4:4:4</td>\n      </tr>\n      <tr>\n       <td>1</td>\n       <td>0</td>\n       <td>0</td>\n       <td>YUV 4:2:2</td>\n      </tr>\n      <tr>\n       <td>1</td>\n       <td>1</td>\n       <td>0</td>\n       <td>YUV 4:2:0</td>\n      </tr>\n      <tr>\n       <td>1</td>\n       <td>1</td>\n       <td>1</td>\n       <td>YUV 4:0:0 (Monochrome)</td>\n      </tr>\n     </tbody>\n    </table>\n\n    <p>The third digit in <code>CCC</code> indicates the chroma sample position, with a value of 0 indicating that the position is unknown and must be separately provided during decoding; a value of 1 indicating that the sample position is horizontally colocated with the (0, 0) luma sample; and a value of 2 indicating that the sample position is colocated with (0, 0) luma.</p>\n\n    <p>The default value is <code>110</code> (4:2:0 chroma subsampling).</p>\n   </td>\n  </tr>\n  <tr>\n   <td><code>cp</code></td>\n   <td>The two-digit <code>color_primaries</code> value indicates the color system used by the media. For example, BT.2020/BT.2100 color, as used for HDR video, is <code>09</code>. The information for this—and for each of the remaining components—is found in the <a href=\"https://aomediacodec.github.io/av1-spec/#color-config-semantics\" class=\"external\" rel=\" noopener\">Color config semantics section</a> of the AV1 specification. The default value is <code>01</code> (ITU-R BT.709).</td>\n  </tr>\n  <tr>\n   <td><code>tc</code></td>\n   <td>The two-digit <code>transfer_characteristics</code> value. This value defines the function used to map the gamma (delightfully called the \"opto-electrical transfer function\" in technical parlance) from the source to the display. For example, 10-bit BT.2020 is <code>14</code>. The default value is <code>01</code> (ITU-R BT.709).</td>\n  </tr>\n  <tr>\n   <td><code>mc</code></td>\n   <td>The two-digit <code>matrix_coefficients</code> constant selects the matrix coefficients used to convert the red, blue, and green channels into luma and chroma signals. For example, the standard coefficients used for BT.709 are indicated using the value <code>01</code>. The default value is <code>01</code> (ITU-R BT.709).</td>\n  </tr>\n  <tr>\n   <td><code>F</code></td>\n   <td>A one-digit flag indicating whether the color should be allowed to use the full range of possible values (<code>1</code>), or should be constrained to those values considered legal for the specified color configuration (that is, the <strong>studio swing representation</strong>). The default is 0 (use the studio swing representation).</td>\n  </tr>\n </tbody>\n</table>\n\n<p>All fields from <code>M</code> (monochrome flag) onward are optional; you may stop including fields at any point (but can't arbitrarily leave out fields). The default values are included in the table above. Some example AV1 codec strings:</p>\n\n<dl>\n <dt id=\"av01.2.15m.10.0.100.09.16.09.0\"><code>av01.2.15M.10.0.100.09.16.09.0</code></dt>\n <dd>AV1 Professional Profile, level 5.3, Main tier, 10 bits per color component, 4:2:2 chroma subsampling using ITU-R BT.2100 color primaries, transfer characteristics, and YCbCr color matrix. The studio swing representation is indicated.</dd>\n <dt id=\"av01.0.15m.10\"><code>av01.0.15M.10</code></dt>\n <dd>AV1 Main Profile, level 5.3, Main tier, 10 bits per color component. The remaining properties are taken from the defaults: 4:2:0 chroma subsampling, BT.709 color primaries, transfer characteristics, and matrix coefficients. Studio swing representation.</dd>\n</dl>"}},{"type":"prose","value":{"id":"iso_base_media_file_format_mp4_quicktime_and_3gp","title":"<a id=\"ISO-BMFF\">ISO Base Media File Format: MP4, QuickTime, and 3GP</a>","isH3":true,"content":"<p>All media types based upon the <a title=\"ISO Base Media File Format\" href=\"https://ru.wikipedia.org/wiki/ISO_Base_Media_File_Format\" class=\"external\" rel=\" noopener\">ISO Base Media File Format</a> (ISO BMFF) share the same syntax for the <code>codecs</code> parameter. These media types include <a href=\"/en-US/docs/Web/Media/Formats/Containers#mp4\">MPEG-4</a> (and, in fact, the <a href=\"/en-US/docs/Web/Media/Formats/Containers#quicktime\">QuickTime</a> file format upon which MPEG-4 is based) as well as <a href=\"/en-US/docs/Web/Media/Formats/Containers#3gp\">3GP</a>. Both video and audio tracks can be described using the <code>codecs</code> parameter with the following MIME types:</p>\n\n<table class=\"standard-table\">\n <caption>Base MIME types supporting the ISO BMFF codecs parameter</caption>\n <thead>\n  <tr>\n   <th scope=\"col\">MIME type</th>\n   <th scope=\"col\">Description</th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td><code>audio/3gpp</code></td>\n   <td>3GP audio (<a href=\"https://datatracker.ietf.org/doc/html/rfc3839\" class=\"external\" rel=\" noopener\">RFC 3839: MIME Type Registrations for 3rd generation Partnership Project (3GP) Multimedia files</a>)</td>\n  </tr>\n  <tr>\n   <td><code>video/3gpp</code></td>\n   <td>3GP video (<a href=\"https://datatracker.ietf.org/doc/html/rfc3839\" class=\"external\" rel=\" noopener\">RFC 3839: MIME Type Registrations for 3rd generation Partnership Project (3GP) Multimedia files</a>)</td>\n  </tr>\n  <tr>\n   <td><code>audio/3gp2</code></td>\n   <td>3GP2 audio (<a href=\"https://datatracker.ietf.org/doc/html/rfc4393\" class=\"external\" rel=\" noopener\">RFC 4393: MIME Type Registrations for 3GPP2 Multimedia files</a>)</td>\n  </tr>\n  <tr>\n   <td><code>video/3gp2</code></td>\n   <td>3GP2 video (<a href=\"https://datatracker.ietf.org/doc/html/rfc4393\" class=\"external\" rel=\" noopener\">RFC 4393: MIME Type Registrations for 3GPP2 Multimedia files</a>)</td>\n  </tr>\n  <tr>\n   <td><code>audio/mp4</code></td>\n   <td>MP4 audio (<a href=\"https://datatracker.ietf.org/doc/html/rfc4337\" class=\"external\" rel=\" noopener\">RFC 4337: MIME Type Registration for MPEG-4</a>)</td>\n  </tr>\n  <tr>\n   <td><code>video/mp4</code></td>\n   <td>MP4 audio (<a href=\"https://datatracker.ietf.org/doc/html/rfc4337\" class=\"external\" rel=\" noopener\">RFC 4337: MIME Type Registration for MPEG-4</a>)</td>\n  </tr>\n  <tr>\n   <td><code>application/mp4</code></td>\n   <td>Non-audiovisual media encapsulated in MPEG-4</td>\n  </tr>\n </tbody>\n</table>\n\n<p>Each codec described by the <code>codecs</code> parameter can be specified either as simply the container's name (<code>3gp</code>, <code>mp4</code>, <code>quicktime</code>, etc.) or as the container name plus additional parameters to specify the codec and its configuration. Each entry in the codec list may contain some number of components, separated by periods (<code>.</code>).</p>\n\n<p>The syntax for the value of <code>codecs</code> varies by codec; however, it always starts with the codec's four-character identifier, a period separator (<code>.</code>), followed by the Object Type Indication (OTI) value for the specific data format. For most codecs, the OTI is a two-digit hexadecimal number; however, it's six hexadecimal digits for <a href=\"/en-US/docs/Web/Media/Formats/Video_codecs#avc_(h.264)\">AVC (H.264)</a>.</p>\n\n<p>Thus, the syntaxes for each of the supported codecs look like this:</p>\n\n<dl>\n <dt id=\"cccc.pp\"><code>cccc[.pp]*</code> (Generic ISO BMFF)</dt>\n <dd>Where <code>cccc</code> is the four-character ID for the codec and <code>pp</code> is where zero or more two-character encoded property values go.</dd>\n <dt id=\"mp4a.oo.a\"><code>mp4a.oo[.A]</code> (MPEG-4 audio)</dt>\n <dd>Where <code>oo</code> is the Object Type Indication value describing the contents of the media more precisely and <code>A</code> is the one-digit <em>audio</em> OTI. The possible values for the OTI can be found on the MP4 Registration Authority web site's <a href=\"https://mp4ra.org/#/object_types\" class=\"external\" rel=\" noopener\">Object Types page</a>. For example, Opus audio in an MP4 file is <code>mp4a.ad</code>. For further details, see <a href=\"#mpeg-4_audio\">MPEG-4 audio</a>.</dd>\n <dt id=\"mp4v.oo.v\"><code>mp4v.oo[.V]</code> (MPEG-4 video)</dt>\n <dd>Here, <code>oo</code> is again the OTI describing the contents more precisely, while <code>V</code> is the one-digit <em>video</em> OTI.</dd>\n <dt id=\"avc1.oo.ppccll\"><code>avc1.oo[.PPCCLL]</code> (AVC video)</dt>\n <dd>\n <p><code>oo</code> is the OTI describing the contents, while <code>PPCCLL</code> is six hexadecimal digits specifying the profile number (<code>PP</code>), constraint set flags (<code>CC</code>), and level (<code>LL</code>). See <a href=\"#avc_profiles\">AVC profiles</a> for the possible values of <code>PP</code>.</p>\n\n <p>The constraint set flags byte is comprised of one-bit Boolean flags, with the most significant bit being referred to as flag 0 (or <code>constraint_set0_flag</code>, in some resources), and each successive bit being numbered one higher. Currently, only flags 0 through 2 are used; the other five bits <em>must</em> be zero. The meanings of the flags vary depending on the profile being used.</p>\n\n <p>The level is a fixed-point number, so a value of <code>14</code> (decimal 20) means level 2.0 while a value of <code>3D</code> (decimal 61) means level 6.1. Generally speaking, the higher the level number, the more bandwidth the stream will use and the higher the maximum video dimensions are supported.</p>\n </dd>\n</dl>\n\n<h4 id=\"avc_profiles\">AVC profiles</h4>\n\n<p>The following are the AVC profiles and their profile numbers for use in the <code>codecs</code> parameter, as well as the value to specify for the constraints component, <code>CC</code>.</p>\n\n<table class=\"standard-table\">\n <caption>Specifying an AVC profiles using the profile ID and constraints components of the <code>codecs</code> parameter</caption>\n <thead>\n  <tr>\n   <th scope=\"col\">Profile</th>\n   <th scope=\"col\">Number (Hex)</th>\n   <th scope=\"col\">Constraints byte</th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td><strong>Constrained Baseline Profile (CBP)</strong><br>\n    CBP is primarily a solution for scenarios in which resources are constrained, or resource use needs to be controlled to minimize the odds of the media performing poorly.</td>\n   <td><code>42</code></td>\n   <td><code>40</code></td>\n  </tr>\n  <tr>\n   <td><strong>Baseline Profile (BP)</strong><br>\n    Similar to CBP but with more data loss protections and recovery capabilities. This is not as widely used as it was before CBP was introduced. All CBP streams are considered to also be BP streams.</td>\n   <td><code>42</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>Extended Profile (XP)</strong><br>\n    Designed for streaming video over the network, with high compression capability and further improvements to data robustness and stream switching.</td>\n   <td><code>58</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>Main Profile (MP)</strong><br>\n    The profile used for standard-definition digital television being broadcast in MPEG-4 format. <em>Not</em> used for high-definition television broadcasts. This profile's importance has faded since the introduction of the High Profile—which was added for HDTV use—in 2004.</td>\n   <td><code>4D</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>High Profile (HiP)</strong><br>\n    Currently, HiP is the primary profile used for broadcast and disc-based HD video; it's used both for HD TV broadcasts and for  Blu-Ray video.</td>\n   <td><code>64</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>Progressive High Profile (PHiP)</strong><br>\n    Essentially High Profile without support for field coding.</td>\n   <td><code>64</code></td>\n   <td><code>08</code></td>\n  </tr>\n  <tr>\n   <td><strong>Constrained High Profile</strong><br>\n    PHiP, but without support for bi-predictive slices (\"B-slices\").</td>\n   <td><code>64</code></td>\n   <td><code>0C</code></td>\n  </tr>\n  <tr>\n   <td><strong>High 10 Profile (Hi10P)</strong><br>\n    High Profile, but with support for up to 10 bits per color component.</td>\n   <td><code>6E</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>High 4:2:2 Profile (Hi422P)</strong><br>\n    Expands upon Hi10P by adding support for 4:2:2 chroma subsampling along with up to10 bits per color component.</td>\n   <td><code>7A</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>High 4:4:4 Predictive Profile (Hi444PP)</strong><br>\n    In addition to the capabilities included in Hi422P, Hi444PP adds support for 4:4:4 chroma subsampling (in which no color information is discarded). Also includes support for up to 14 bits per color sample and efficient lossless region coding. The option to encode each frame as three separate color planes (that is, each color's data is stored as if it were a single monochrome frame).</td>\n   <td><code>F4</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>High 10 Intra Profile</strong><br>\n    High 10 constrained to all-intra-frame use. Primarily used for professional apps.</td>\n   <td><code>6E</code></td>\n   <td><code>10</code></td>\n  </tr>\n  <tr>\n   <td><strong>High 4:2:2 Intra Profile</strong><br>\n    The Hi422 Profile with all-intra-frame use.</td>\n   <td><code>7A</code></td>\n   <td><code>10</code></td>\n  </tr>\n  <tr>\n   <td><strong>High 4:4:4 Intra Profile</strong><br>\n    The High 4:4:4 Profile constrained to use only intra frames.</td>\n   <td><code>F4</code></td>\n   <td><code>10</code></td>\n  </tr>\n  <tr>\n   <td><strong>CAVLC 4:4:4 Intra Profile</strong><br>\n    The High 4:4:4 Profile constrained to all-intra use, and to using only CAVLC entropy coding.</td>\n   <td><code>44</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>Scalable Baseline Profile</strong><br>\n    Intended for use with video conferencing as well as surveillance and mobile uses, the <a title=\"SVC\" href=\"https://ru.wikipedia.org/wiki/SVC\" class=\"external\" rel=\" noopener\">SVC</a> Baseline Profile is based on AVC's Constrained Baseline profile. The base layer within the stream is provided at a high quality level, with some number of secondary substreams that offer alternative forms of the same video for use in various constrained environments. These may include any combination of reduced resolution, reduced frame rate, or increased compression levels.</td>\n   <td><code>53</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>Scalable Constrained Baseline Profile</strong><br>\n    Primarily used for real-time communication applications. Not yet supported by WebRTC, but an extension to the WebRTC API <a href=\"https://github.com/w3c/webrtc-svc\" class=\"external\" rel=\" noopener\">to allow SVC</a> is in development.</td>\n   <td><code>53</code></td>\n   <td><code>04</code></td>\n  </tr>\n  <tr>\n   <td><strong>Scalable High Profile</strong><br>\n    Meant mostly for use in broadcast and streaming applications. The base (or highest quality) layer must conform to the AVC High Profile.</td>\n   <td><code>56</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>Scalable Constrained High Profile</strong><br>\n    A subset of the Scalable High Profile designed mainly for real-time communticions.</td>\n   <td><code>56</code></td>\n   <td><code>04</code></td>\n  </tr>\n  <tr>\n   <td><strong>Scalable High Intra Profile</strong><br>\n    Primarily useful only for production applications, this profile supports only all-intra usage.</td>\n   <td><code>56</code></td>\n   <td><code>20</code></td>\n  </tr>\n  <tr>\n   <td><strong>Stereo High Profile</strong><br>\n    The Stereo High Profile provides stereoscopic video using two renderings of the scene (left eye and right eye). Otherwise, provides the same features as the High profile.</td>\n   <td><code>80</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>Multiview High Profile</strong><br>\n    Supports two or more views using both temporal and MVC inter-view prediction. <em>Does not support</em> field pictures or macroblock-adaptive frame-field coding.</td>\n   <td><code>76</code></td>\n   <td><code>00</code></td>\n  </tr>\n  <tr>\n   <td><strong>Multiview Depth High Profile</strong><br>\n    Based on the High Profile, to which the main substream must adhere. The remaining substreams must match the Stereo High Profile.</td>\n   <td><code>8A</code></td>\n   <td><code>00</code></td>\n  </tr>\n </tbody>\n</table>\n\n<h4 id=\"mpeg-4_audio\">MPEG-4 audio</h4>\n\n<p>When the value of an entry in the <code>codecs</code> list begins with <code>mp4a</code>, the syntax of the value should be:</p>\n\n<pre class=\"notranslate\">mp4a.oo[.A]</pre>\n\n<p>Here, <code>oo</code> is the two-digit hexadecimal Object Type Indication which specifies the codec class being used for the media. The OTIs are assigned by the <a href=\"https://mp4ra.org/\" class=\"external\" rel=\" noopener\">MP4 Registration Authority</a>, which maintains a <a href=\"https://mp4ra.org/#/object_types\" class=\"external\" rel=\" noopener\">list of the possible OTI values</a>. A special value is <code>40</code>; this indicates that the media is MPEG-4 audio (ISO/IEC 14496 Part 3). In order to be more specific still, a third component—the Audio Object Type—is added for OTI <code>40</code> to narrow the type down to a specific subtype of MPEG-4.</p>\n\n<p>The Audio Object Type is specified as a one or two digit <em>decimal</em> value (unlike most other values in the <code>codecs</code> parameter, which use hexadecimal). For example, MPEG-4's AAC-LC has an audio object type number of <code>2</code>, so the full <code>codecs</code> value representing AAC-LC is <code>mp4a.40.2</code>.</p>\n\n<p>Thus, ER AAC LC, whose Audio Object Type is 17, can be represented using the full <code>codecs</code> value <code>mp4a.40.17</code>. Single digit values can be given either as one digit (which is the best choice, since it will be the most broadly compatible) or with a leading zero padding it to two digits, such as <code>mp4a.40.02</code>.</p>\n\n<div class=\"note notecard\" id=\"sect5\">\n<p><strong>Note:</strong> The specification originally mandated that the Audio Object Type number in the third component be only one decimal digit. However, amendments to the specification over time extended the range of these values well beyond one decimal digit, so now the third parameter may be either one or two digits. Padding values below 10 with a leading <code>0</code> is optional. Older implementations of MPEG-4 codecs may not support two-digit values, however, so using a single digit when possible will maximize compatibility.</p>\n</div>\n\n<p>The Audio Object Types are defined in ISO/IEC 14496-3 subpart 1, section 1.5.1. The table below provides a basic list of the Audio Object Types and in the case of the more common object ypes provides a list of the profiles supporting it, but you should refer to the specification for details if you need to know more about the inner workings of any given MPEG-4 audio type.</p>\n\n<table class=\"standard-table\">\n <caption>MPEG-4 audio object types</caption>\n <thead>\n  <tr>\n   <th scope=\"col\">ID</th>\n   <th scope=\"col\">Audio Object Type</th>\n   <th scope=\"col\">Profile support</th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td><code>0</code></td>\n   <td>NULL</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>1</code></td>\n   <td>AAC Main</td>\n   <td>Main</td>\n  </tr>\n  <tr>\n   <td><code>2</code></td>\n   <td>AAC LC (Low Complexity)</td>\n   <td>Main, Scalable, HQ, LD v2, AAC, HE-AAC, HE-AAC v2</td>\n  </tr>\n  <tr>\n   <td><code>3</code></td>\n   <td>AAC SSR (Scalable Sampling Rate)</td>\n   <td>Main</td>\n  </tr>\n  <tr>\n   <td><code>4</code></td>\n   <td>AAC LTP (Long Term Prediction)</td>\n   <td>Main, Scalable, HQ</td>\n  </tr>\n  <tr>\n   <td><code>5</code></td>\n   <td>SBR (Spectral Band Replication)</td>\n   <td>HE-AAC, HE-AAC v2</td>\n  </tr>\n  <tr>\n   <td><code>6</code></td>\n   <td>AAC Scalable</td>\n   <td>Main, Scalable, HQ</td>\n  </tr>\n  <tr>\n   <td><code>7</code></td>\n   <td>TwinVQ (Coding for ultra-low bit rates)</td>\n   <td>Main, Scalable</td>\n  </tr>\n  <tr>\n   <td><code>8</code></td>\n   <td>CELP (Code-Excited Linear Prediction)</td>\n   <td>Main, Scalable, Speech, HQ, LD</td>\n  </tr>\n  <tr>\n   <td><code>9</code></td>\n   <td>HVXC (Harmonic Vector Excitation Coding)</td>\n   <td>Main, Scalable, Speech, LD</td>\n  </tr>\n  <tr>\n   <td><code>10</code> – <code>11</code></td>\n   <td><em>Reserved</em></td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>12</code></td>\n   <td>TTSI (Text to Speech Interface)</td>\n   <td>Main, Scalable, Speech, Synthetic, LD</td>\n  </tr>\n  <tr>\n   <td><code>13</code></td>\n   <td>Main Synthetic</td>\n   <td>Main, Synthetic</td>\n  </tr>\n  <tr>\n   <td><code>14</code></td>\n   <td>Wavetable Synthesis</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>15</code></td>\n   <td>General MIDI</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>16</code></td>\n   <td>Algorithmic Synthesis and Audio Effects</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>17</code></td>\n   <td>ER AAC LC (Error Resilient AAC Low-Complexity)</td>\n   <td>HQ, Mobile Internetworking</td>\n  </tr>\n  <tr>\n   <td><code>18</code></td>\n   <td><em>Reserved</em></td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>19</code></td>\n   <td>ER AAC LTP (Error Resilient AAC Long Term Prediction)</td>\n   <td>HQ</td>\n  </tr>\n  <tr>\n   <td><code>20</code></td>\n   <td>ER AAC Scalable (Error Resilient AAC Scalable)</td>\n   <td>Mobile Internetworking</td>\n  </tr>\n  <tr>\n   <td><code>21</code></td>\n   <td>ER TwinVQ (Error Resilient TwinVQ)</td>\n   <td>Mobile Internetworking</td>\n  </tr>\n  <tr>\n   <td><code>22</code></td>\n   <td>ER BSAC (Error Reslient Bit-Sliced Arithmetic Coding)</td>\n   <td>Mobile Internetworking</td>\n  </tr>\n  <tr>\n   <td><code>23</code></td>\n   <td>ER AAC LD (Error Resilient AAC Low-Delay; used for two-way communication)</td>\n   <td>LD, Mobile Internetworking</td>\n  </tr>\n  <tr>\n   <td><code>24</code></td>\n   <td>ER CELP (Error Resilient Code-Excited Linear Prediction)</td>\n   <td>HQ, LD</td>\n  </tr>\n  <tr>\n   <td><code>25</code></td>\n   <td>ER HVXC (Error Resilient Harmonic Vector Excitation Coding)</td>\n   <td>LD</td>\n  </tr>\n  <tr>\n   <td><code>26</code></td>\n   <td>ER HILN (Error Resilient Harmonic and Individual Line plus Noise)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>27</code></td>\n   <td>ER Parametric (Error Resilient Parametric)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>28</code></td>\n   <td>SSC (Sinusoidal Coding)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>29</code></td>\n   <td>PS (Parametric Stereo)</td>\n   <td>HE-AAC v2</td>\n  </tr>\n  <tr>\n   <td><code>30</code></td>\n   <td>MPEG Surround</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>31</code></td>\n   <td><em>Escape</em></td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>32</code></td>\n   <td>MPEG-1 Layer-1</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>33</code></td>\n   <td>MPEG-1 Layer-2 (MP2)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>34</code></td>\n   <td>MPEG-1 Layer-3 (MP3)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>35</code></td>\n   <td>DST (Direct Stream Transfer)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>36</code></td>\n   <td>ALS (Audio Lossless)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>37</code></td>\n   <td>SLS (Scalable Lossless)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>38</code></td>\n   <td>SLS Non-core (Scalable Lossless Non-core)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>39</code></td>\n   <td>ER AAC ELD (Error Resilient AAC Enhanced Low Delay)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>40</code></td>\n   <td>SMR Simple (Symbolic Music Representation Simple)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>41</code></td>\n   <td>SMR Main (Symbolic Music Representation Main)</td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>42</code></td>\n   <td><em>Reserved</em></td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>43</code></td>\n   <td>SAOC (Spatial Audio Object Coding)<sup><a href=\"#audio-object-types-foot-1\">[1]</a></sup></td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>44</code></td>\n   <td>LD MPEG Surround (Low Delay MPEG Surround)<sup><a href=\"#audio-object-types-foot-1\">[1]</a></sup></td>\n   <td></td>\n  </tr>\n  <tr>\n   <td><code>45</code> and up</td>\n   <td><em>Reserved</em></td>\n   <td></td>\n  </tr>\n </tbody>\n</table>\n\n<p><a name=\"audio-object-types-foot-1\">[1]</a> SAOC and LD MPEG Surround are defined in <a href=\"https://www.iso.org/standard/54838.html\" class=\"external\" rel=\" noopener\">ISO/IEC 14496-3:2009/Amd.2:2010(E)</a>.</p>","titleAsText":"ISO Base Media File Format: MP4, QuickTime, and 3GP"}},{"type":"prose","value":{"id":"webm","title":"WebM","isH3":true,"content":"<p>The basic form for a WebM <code>codecs</code> parameter is to simply list one or more of the four WebM codecs by name, separated by commas. The table below shows some examples:</p>\n\n<table class=\"standard-table\">\n <caption>Examples of classic WebM MIME types with <code>codecs</code> parameter</caption>\n <thead>\n  <tr>\n   <th scope=\"col\">MIME type</th>\n   <th scope=\"col\">Description</th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td><code>video/webm;codecs=\"vp8\"</code></td>\n   <td>A WebM video with VP8 video in it; no audio is specified.</td>\n  </tr>\n  <tr>\n   <td><code>video/webm;codecs=\"vp9\"</code></td>\n   <td>A WebM video with VP9 video in it.</td>\n  </tr>\n  <tr>\n   <td><code>audio/webm;codecs=\"vorbis\"</code></td>\n   <td>Vorbis audio in a WebM container.</td>\n  </tr>\n  <tr>\n   <td><code>audio/webm;codecs=\"opus\"</code></td>\n   <td>Opus audio in a WebM container.</td>\n  </tr>\n  <tr>\n   <td><code>video/webm;codecs=\"vp8,vorbis\"</code></td>\n   <td>A WebM container with VP8 video and Vorbis audio.</td>\n  </tr>\n  <tr>\n   <td><code>video/webm;codecs=\"vp9,opus\"</code></td>\n   <td>A WebM container with VP9 video and Opus audio.</td>\n  </tr>\n </tbody>\n</table>\n\n<p>The strings <code>vp8.0</code> and <code>vp9.0</code> also work, but are not recommended.</p>\n\n<h4 id=\"iso_base_media_file_format_syntax\">ISO Base Media File Format syntax</h4>\n\n<p>As part of a move toward a standardized and powerful format for the <code>codecs</code> parameter, WebM is moving toward describing <em>video</em> content using a syntax based on that defined by the <a href=\"#iso-bmff\">ISO Base Media File Format</a>. This syntax is defined in <a href=\"https://www.webmproject.org/vp9/mp4\" class=\"external\" rel=\" noopener\">VP Codec ISO Media File Format Binding</a>, in the section <a href=\"https://www.webmproject.org/vp9/mp4/#codecs-parameter-string\" class=\"external\" rel=\" noopener\">Codecs Parameter String</a>. The audio codec continues to be indicated as either <code>vorbis</code> or <code>opus</code>.</p>\n\n<p>In this format, the <code>codecs</code> parameter's value begins with a four-character code identifying the codec being used in the container, which is then followed by a series of period (<code>.</code>) separated two-digit values.</p>\n\n<pre class=\"notranslate\">cccc.PP.LL.DD.CC[.cp[.tc[.mc[.FF]]]]</pre>\n\n<p>The first five components are required; everything from <code>cp</code> (color primaries) onward is optional; you can stop including components at any point from then onward. Each of these components is described in the following table. Following the table are some examples.</p>\n\n<table class=\"standard-table\">\n <caption>WebM codecs parameter components</caption>\n <thead>\n  <tr>\n   <th scope=\"col\">Component</th>\n   <th scope=\"col\">Details</th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td><code>cccc</code></td>\n   <td>\n    <p>A four-character code indicating which indicates which of the possible codecs is being described. Potential values are:</p>\n\n    <table class=\"standard-table\">\n     <caption>Four-character codes for WebM-supported codecs</caption>\n     <thead>\n      <tr>\n       <th scope=\"col\">Four-character code</th>\n       <th scope=\"col\">Codec</th>\n      </tr>\n     </thead>\n     <tbody>\n      <tr>\n       <td><code>vp08</code></td>\n       <td>VP8</td>\n      </tr>\n      <tr>\n       <td><code>vp09</code></td>\n       <td>VP9</td>\n      </tr>\n      <tr>\n       <td><code>vp10</code></td>\n       <td>VP10</td>\n      </tr>\n     </tbody>\n    </table>\n   </td>\n  </tr>\n  <tr>\n   <td><code>PP</code></td>\n   <td>\n    <p>The two-digit profile number, padded with leading zeroes if necessary to be exactly two digits.</p>\n\n    <table class=\"standard-table\">\n     <caption>WebM profile numbers</caption>\n     <thead>\n      <tr>\n       <th scope=\"col\">Profile</th>\n       <th scope=\"col\">Description</th>\n      </tr>\n     </thead>\n     <tbody>\n      <tr>\n       <td><code>00</code></td>\n       <td>Only 4:2:0 (chroma subsampled both horizontally and vertically). Allows only 8 bits per color component.</td>\n      </tr>\n      <tr>\n       <td><code>01</code></td>\n       <td>All chroma subsampling formats are allowed. Allows only 8 bits per color component.</td>\n      </tr>\n      <tr>\n       <td><code>02</code></td>\n       <td>Only 4:2:0 (chroma subsampled both horizontally and vertically). Supports 8, 10, or 12 bits per color sample component.</td>\n      </tr>\n      <tr>\n       <td><code>03</code></td>\n       <td>All chroma subsampling formats are allowed. Supports 8, 10, or 12 bits per color sample component.</td>\n      </tr>\n     </tbody>\n    </table>\n   </td>\n  </tr>\n  <tr>\n   <td><code>LL</code></td>\n   <td>The two-digit level number. The level number is a fixed-point notation, where the first digit is the ones digit, and the second digit represents tenths. For example, level 3 is <code>30</code> and level 6.1 is <code>61</code>.</td>\n  </tr>\n  <tr>\n   <td><code>DD</code></td>\n   <td>The bit depth of the luma and color component values; permitted values are 8, 10, and 12.</td>\n  </tr>\n  <tr>\n   <td><code>CC</code></td>\n   <td>\n    <p>A two-digit value indicating which chroma subsampling format to use. The following table lists permitted values; see <a href=\"en-US/docs/Web/Media/Formats/Video_concepts#Chroma_subsampling\">Chroma subsampling</a> в <a href=\"en-US/docs/Web/Media/Formats/Video_concepts\">Digital video concepts</a> for additional information about this topic and others.</p>\n\n    <table class=\"standard-table\">\n     <caption>WebM chroma subsampling identifiers</caption>\n     <thead>\n      <tr>\n       <th scope=\"col\">Value</th>\n       <th scope=\"col\">Chroma subsampling format</th>\n      </tr>\n     </thead>\n     <tbody>\n      <tr>\n       <td><code>00</code></td>\n       <td>4:2:0 with the chroma samples sited interstitially between the pixels</td>\n      </tr>\n      <tr>\n       <td><code>01</code></td>\n       <td>4:2:0 chroma subsampling with the samples colocated with luma (0, 0)</td>\n      </tr>\n      <tr>\n       <td><code>02</code></td>\n       <td>4:2:2 chroma subsampling (4 out of each 4 horizontal pixels' luminance are used)</td>\n      </tr>\n      <tr>\n       <td><code>03</code></td>\n       <td>4:4:4 chroma subsampling (every pixel's luminance and chrominance are both retained)</td>\n      </tr>\n      <tr>\n       <td><code>04</code></td>\n       <td><em>Reserved</em></td>\n      </tr>\n     </tbody>\n    </table>\n   </td>\n  </tr>\n  <tr>\n   <td><code>cp</code></td>\n   <td>\n    <p>A two-digit integer specifying which of the color primaries from Section 8.1 of the <a href=\"https://www.itu.int/rec/T-REC-H.273/en\" class=\"external\" rel=\" noopener\">ISO/IEC 23001-8:2016</a> standard. This component, and every component after it, is optional.</p>\n\n    <p>The possible values of the color primaries component are:</p>\n\n    <table class=\"standard-table\">\n     <caption>ISO/IEC Color primary identifiers</caption>\n     <thead>\n      <tr>\n       <th scope=\"col\">Value</th>\n       <th scope=\"col\">Details</th>\n      </tr>\n     </thead>\n     <tbody>\n      <tr>\n       <td><code>00</code></td>\n       <td><em>Reserved for future use by ITU or ISO/IEC</em></td>\n      </tr>\n      <tr>\n       <td><code>01</code></td>\n       <td>BT.709, sRGB, sYCC. BT.709 is the standard for high definition (HD) television; sRGB is the most common color space used for computer displays. Broadcast BT.709 uses 8-bit color depth with the legal range being from 16 (black) to 235 (white).</td>\n      </tr>\n      <tr>\n       <td><code>02</code></td>\n       <td>Image characteristics are unknown, or are to be determined by the application</td>\n      </tr>\n      <tr>\n       <td><code>03</code></td>\n       <td><em>Reserved for future use by ITU or ISO/IEC</em></td>\n      </tr>\n      <tr>\n       <td><code>04</code></td>\n       <td>BT.470 System M, NTSC (standard definition television in the United States)</td>\n      </tr>\n      <tr>\n       <td><code>05</code></td>\n       <td>BT.470 System B, G; BT.601; BT.1358 625; BT.1700 625 PAL and 625 SECAM</td>\n      </tr>\n      <tr>\n       <td><code>06</code></td>\n       <td>BT.601 525; BT.1358 525 or 625; BT.1700 NTSC; SMPTE 170M. <em>Functionally identical to <code>7</code>.</em></td>\n      </tr>\n      <tr>\n       <td><code>70</code></td>\n       <td><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Glossary/SMPTE\">SMPTE <small>(en-US)</small></a> 240M (historical). <em>Functionally identical to <code>6</code>.</em></td>\n      </tr>\n      <tr>\n       <td><code>08</code></td>\n       <td>Generic film</td>\n      </tr>\n      <tr>\n       <td><code>09</code></td>\n       <td>BT.2020; BT.2100. Used for ultra-high definition (4K) High Dynamic Range (HDR) video, these have a very wide color gamut and support 10-bit and 12-bit color component depths.</td>\n      </tr>\n      <tr>\n       <td><code>10</code></td>\n       <td>SMPTE ST 428 (D-Cinema Distribution Master: Image characteristics). Defines the uncompressed image characteristics for DCDM.</td>\n      </tr>\n      <tr>\n       <td><code>11</code></td>\n       <td>SMPTE RP 431 (D-Cinema Quality: Reference projector and environment). Describes the reference projector and environment conditions that provide a consistent film presentation experience.</td>\n      </tr>\n      <tr>\n       <td><code>12</code></td>\n       <td>SMPTE EG 432 (Digital Source Processing: Color Processing for D-Cinema). Engineering guideline making color signal decoding recommendations for digital movies.</td>\n      </tr>\n      <tr>\n       <td><code>13</code> – <code>21</code></td>\n       <td><em>Reserved for future use by ITU-T or ISO/IEC</em></td>\n      </tr>\n      <tr>\n       <td><code>22</code></td>\n       <td>EBU Tech 3213-E</td>\n      </tr>\n      <tr>\n       <td><code>23</code> – <code>255</code></td>\n       <td><em>Reserved for future use by ITU-T or ISO/IEC</em></td>\n      </tr>\n     </tbody>\n    </table>\n   </td>\n  </tr>\n  <tr>\n   <td><code>tc</code></td>\n   <td>A two-digit integer indicating the <code>transferCharacteristics</code> for the video. This value is from Section 8.2 of <a href=\"https://www.itu.int/rec/T-REC-H.273/en\" class=\"external\" rel=\" noopener\">ISO/IEC 23001-8:2016</a>, and indicates the transfer characteristics to be used when adapting the decoded color to the render target.</td>\n  </tr>\n  <tr>\n   <td><code>mc</code></td>\n   <td>The two-digit value for the <code>matrixCoefficients</code> property. This value comes from the table in Section 8.3 of the <a href=\"https://www.itu.int/rec/T-REC-H.273/en\" class=\"external\" rel=\" noopener\">ISO/IEC 23001-8:2016</a> specification. This value indicates which set of coefficients to use when mapping from the native red, blue, and green primaries to the luma and chroma signals. These coefficients are in turn used with the equations found in that same section.</td>\n  </tr>\n  <tr>\n   <td><code>FF</code></td>\n   <td>Indicates whether to restrict the black level and color range of each color component to the legal range. For 8 bit color samples, the legal range is 16-235. A value of <code>00</code> indicates that these limitations should be enforced, while a value of <code>01</code> allows the full range of possible values for each component, even if the resulting color is out of bounds for the color system.</td>\n  </tr>\n </tbody>\n</table>\n\n<h4 id=\"webm_media_type_examples\">WebM media type examples</h4>\n\n<dl>\n <dt id=\"videowebmcodecsvp08.00.41.08vorbis\"><code>video/webm;codecs=\"vp08.00.41.08,vorbis\"</code></dt>\n <dd>VP8 video, profile 0 level 4.1, using 8-bit YUV with 4:2:0 chroma subsampling, using BT.709 color primaries, transfer function, and matrix coefficients, with the luminance and chroma values encoded within the legal (\"studio\") range. The video is Vorbis.</dd>\n <dt id=\"videowebmcodecsvp09.02.10.10.01.09.16.09.01opus\"><code>video/webm;codecs=\"vp09.02.10.10.01.09.16.09.01,opus\"</code></dt>\n <dd>VP9 video, profile 2 level 1.0, with 10-bit YUV content using 4:2:0 chroma subsampling, BT.2020 primaries, ST 2084 EOTF (HDR SMPTE), BT.2020 non-constant luminance color matrix, and full-range chroma and luma encoding. The audio is in Opus format.</dd>\n</dl>"}},{"type":"prose","value":{"id":"using_the_codecs_parameter","title":"Using the codecs parameter","isH3":false,"content":"<p>You can use the <code>codecs</code> parameter in a few situations. Firstly, you can use it with the <a href=\"/ru/docs/Web/HTML/Element/source\"><code>&lt;source&gt;</code></a> element when creating an <a href=\"/ru/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a> or <a href=\"/ru/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a> element, in order to establish a group of options for the browser to choose from when selecting the format of the media to present to the user in the element.</p>\n\n<p>You can also use the codecs parameter when specifying a MIME media type to the <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaSource/isTypeSupported\"><code>MediaSource.isTypeSupported()</code> <small>(en-US)</small></a> method; this method returns a Boolean which indicates whether or not the media is likely to work on the current device.</p>"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n <li><a href=\"/en-US/docs/Web/Media\">Web media technologies</a></li>\n <li><a href=\"/en-US/docs/Web/Media/Formats\">Guide to media types and formats on the web</a></li>\n <li><a href=\"/en-US/docs/Web/Media/Formats/Audio_codecs\">Guide to audio codecs used on the web</a></li>\n <li><a href=\"/en-US/docs/Web/Media/Formats/Video_codecs\">Guide to video codecs used on the web</a></li>\n <li><a href=\"/en-US/docs/Web/Media/Formats/WebRTC_codecs\">Codecs used by WebRTC</a></li>\n</ul>"}}],"toc":[{"text":"Общий синтаксис","id":"общий_синтаксис"},{"text":"Свойства кодеков для контейнеров","id":"свойства_кодеков_для_контейнеров"},{"text":"Using the codecs parameter","id":"using_the_codecs_parameter"},{"text":"See also","id":"see_also"}],"summary":"MIME (en-US) тип, такой как  video/mp4 или audio/mpeg. Однако, многие медиа типы, особенно те, которые поддерживают видео дорожки, более привлекательные из-за способности более точного описания содержащегося формата данных. Например, просто описывая видео в  файле MPEG-4  с  MIME типом video/mp4 ничего не скажет о том, какой формат в действительности он содержит.","popularity":0,"modified":"2022-10-01T03:41:16.000Z","other_translations":[{"title":"The \"codecs\" parameter in common media types","locale":"en-US","native":"English (US)"},{"title":"일반 미디어 타입에서 \"codecs\" 파라미터 사용하기","locale":"ko","native":"한국어"}],"source":{"folder":"ru/web/media/formats/codecs_parameter","github_url":"https://github.com/mdn/translated-content/blob/main/files/ru/web/media/formats/codecs_parameter/index.html","last_commit_url":"https://github.com/mdn/translated-content/commit/921c46a374ab0a9f4cc809af0370f8c412e54701","filename":"index.html"},"parents":[{"uri":"/ru/docs/Web","title":"Веб-технологии для разработчиков"},{"uri":"/ru/docs/Web/Media","title":"Web media technologies"},{"uri":"/ru/docs/Web/Media/Formats","title":"Media type and format guide: image, audio, and video content"},{"uri":"/ru/docs/Web/Media/Formats/codecs_parameter","title":"Параметр \"codecs\" для распространённых типов носителей"}],"pageTitle":"Параметр \"codecs\" для распространённых типов носителей - Web media technologies | MDN","noIndexing":false}}