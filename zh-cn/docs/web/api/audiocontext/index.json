{"doc":{"isMarkdown":true,"isTranslated":true,"isActive":true,"flaws":{},"title":"AudioContext","mdn_url":"/zh-CN/docs/Web/API/AudioContext","locale":"zh-CN","native":"中文 (简体)","sidebarHTML":"<ol><li><strong><a href=\"/zh-CN/docs/Web/API/Web_Audio_API\">Web Audio API</a></strong></li><li><strong><a href=\"/zh-CN/docs/Web/API/AudioContext\"><code>AudioContext</code></a></strong></li><li class=\"toggle\"><details open=\"\"><summary>构造函数</summary><ol><li><a href=\"/zh-CN/docs/Web/API/AudioContext/AudioContext\"><code>AudioContext()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>属性</summary><ol><li><a href=\"/zh-CN/docs/Web/API/AudioContext/baseLatency\"><code>baseLatency</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/outputLatency\"><code>outputLatency</code> <small>(en-US)</small></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>方法</summary><ol><li><a href=\"/zh-CN/docs/Web/API/AudioContext/close\"><code>close()</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioContext/createMediaElementSource\"><code>createMediaElementSource()</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioContext/createMediaStreamDestination\"><code>createMediaStreamDestination()</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioContext/createMediaStreamSource\"><code>createMediaStreamSource()</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource\"><code>createMediaStreamTrackSource()</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/getOutputTimestamp\"><code>getOutputTimestamp()</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioContext/resume\"><code>resume()</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioContext/suspend\"><code>suspend()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>继承</summary><ol><li><a href=\"/zh-CN/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/zh-CN/docs/Web/API/EventTarget\"><code>EventTarget</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Web Audio API 的相关页面</summary><ol><li><a href=\"/zh-CN/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/zh-CN/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/zh-CN/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/zh-CN/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/zh-CN/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/zh-CN/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li><li><a href=\"/zh-CN/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code> <small>(en-US)</small></a></li><li><a href=\"/zh-CN/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p><code>AudioContext</code>接口表示由链接在一起的音频模块构建的音频处理图，每个模块由一个<a href=\"/zh-CN/docs/Web/API/AudioNode\"><code>AudioNode</code></a>表示。音频上下文控制它包含的节点的创建和音频处理或解码的执行。在做任何其他操作之前，您需要创建一个<code>AudioContext</code>对象，因为所有事情都是在上下文中发生的。建议创建一个<code>AudioContext</code>对象并复用它，而不是每次初始化一个新的<code>AudioContext</code>对象，并且可以对多个不同的音频源和管道同时使用一个<code>AudioContext</code>对象。</p><svg viewBox=\"-1 -1 650 42\" preserveAspectRatio=\"xMinYMin meet\">\n  <a style=\"text-decoration: none;\" xlink:href=\"/zh-CN/docs/Web/API/EventTarget\">\n    <rect x=\"0\" y=\"0\" width=\"88\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"44\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      EventTarget\n    </text>\n  </a>\n  <line x1=\"88\" y1=\"14\" x2=\"118\" y2=\"14\" stroke=\"#D4DDE4\" \"=\"\"></line>\n  <polyline points=\"88,14 98,9 98,19 88,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" xlink:href=\"/zh-CN/docs/Web/API/BaseAudioContext\">\n    <rect x=\"118\" y=\"0\" width=\"128\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"182\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      BaseAudioContext\n    </text>\n  </a>\n  <line x1=\"246\" y1=\"14\" x2=\"276\" y2=\"14\" stroke=\"#D4DDE4\" \"=\"\"></line>\n  <polyline points=\"246,14 256,9 256,19 246,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" xlink:href=\"/zh-CN/docs/Web/API/AudioContext\" aria-current=\"page\">\n    <rect x=\"276\" y=\"0\" width=\"96\" height=\"25\" fill=\"#F4F7F8\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"324\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      AudioContext\n    </text>\n  </a></svg>"}},{"type":"prose","value":{"id":"构造函数","title":"构造函数","isH3":false,"content":"<dl>\n  <dt id=\"audiocontext\"><a href=\"/zh-CN/docs/Web/API/AudioContext/AudioContext\" title=\"AudioContext()\"><code>AudioContext()</code></a></dt>\n  <dd>\n    <p>创建并返回一个新的 <code>AudioContext</code> 对象。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"属性","title":"属性","isH3":false,"content":"<p><em>也从其父接口继承属性，<a href=\"/zh-CN/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>.</em></p>\n<dl>\n  <dt id=\"audiocontext.baselatency\"><a href=\"/zh-CN/docs/Web/API/AudioContext/baseLatency\"><code>AudioContext.baseLatency</code></a> <span title=\"该属性的值无法更改\" class=\"badge inline readonly\">只读 </span> <svg class=\"icon icon-experimental\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-experimental\"></use>\n</svg></dt>\n  <dd>\n    <p>返回<a href=\"/zh-CN/docs/Web/API/AudioContext\" aria-current=\"page\"><code>AudioContext</code></a>将音频从<a href=\"/zh-CN/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a>传递到音频子系统的处理延迟的秒数。</p>\n  </dd>\n  <dt id=\"audiocontext.outputlatency_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/outputLatency\"><code>AudioContext.outputLatency</code> <small>(en-US)</small></a> <span title=\"该属性的值无法更改\" class=\"badge inline readonly\">只读 </span> <svg class=\"icon icon-experimental\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-experimental\"></use>\n</svg></dt>\n  <dd>\n    <p>返回对当前音频上下文的预估输出延迟。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"方法","title":"方法","isH3":false,"content":"<p><em>也从其父接口继承方法 ​​​​, <a href=\"/zh-CN/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>.</em></p>\n<dl>\n  <dt id=\"audiocontext.close\"><a href=\"/zh-CN/docs/Web/API/AudioContext/close\"><code>AudioContext.close()</code></a></dt>\n  <dd>\n    <p>关闭一个音频环境，释放任何正在使用系统资源的音频。</p>\n  </dd>\n  <dt id=\"audiocontext.createmediaelementsource\"><a href=\"/zh-CN/docs/Web/API/AudioContext/createMediaElementSource\"><code>AudioContext.createMediaElementSource()</code></a></dt>\n  <dd>\n    <p>创建一个<a href=\"/zh-CN/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a>接口来关联<a href=\"/zh-CN/docs/Web/API/HTMLMediaElement\"><code>HTMLMediaElement</code></a>. 这可以用来播放和处理来自<a href=\"/zh-CN/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a>或<a href=\"/zh-CN/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a> 元素的音频。</p>\n  </dd>\n  <dt id=\"audiocontext.createmediastreamsource\"><a href=\"/zh-CN/docs/Web/API/AudioContext/createMediaStreamSource\"><code>AudioContext.createMediaStreamSource()</code></a></dt>\n  <dd>\n    <p>创建一个<a href=\"/zh-CN/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a>接口来关联可能来自本地计算机麦克风或其他来源的音频流<a href=\"/zh-CN/docs/Web/API/MediaStream\"><code>MediaStream</code></a>。</p>\n  </dd>\n  <dt id=\"audiocontext.createmediastreamdestination\"><a href=\"/zh-CN/docs/Web/API/AudioContext/createMediaStreamDestination\"><code>AudioContext.createMediaStreamDestination()</code></a></dt>\n  <dd>\n    <p>创建一个<a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code> <small>(en-US)</small></a>接口来关联可能储存在本地或已发送至其他计算机的<a href=\"/zh-CN/docs/Web/API/MediaStream\"><code>MediaStream</code></a>音频。</p>\n  </dd>\n  <dt id=\"audiocontext.createmediastreamtracksource_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource\"><code>AudioContext.createMediaStreamTrackSource()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>创建一个<a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamTrackAudioSourceNode\"><code>MediaStreamTrackAudioSourceNode</code> <small>(en-US)</small></a>，它与一个<a href=\"/zh-CN/docs/Web/API/MediaStream\"><code>MediaStream</code></a>相关联，表示一个媒体流轨迹。</p>\n  </dd>\n  <dt id=\"audiocontext.getoutputtimestamp_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/getOutputTimestamp\"><code>AudioContext.getOutputTimestamp()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>返回一个新的 AudioTimestamp 对象，该对象包含两个与当前音频上下文相关的音频时间戳。</p>\n  </dd>\n  <dt id=\"audiocontext.resume\"><a href=\"/zh-CN/docs/Web/API/AudioContext/resume\"><code>AudioContext.resume()</code></a></dt>\n  <dd>\n    <p>恢复之前被暂停的音频上下文中的时间进程。</p>\n  </dd>\n  <dt id=\"audiocontext.suspend\"><a href=\"/zh-CN/docs/Web/API/AudioContext/suspend\"><code>AudioContext.suspend()</code></a></dt>\n  <dd>\n    <p>暂停音频上下文中的时间进程，暂停音频硬件访问并减少进程中的 CPU/电池使用。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"例子","title":"例子","isH3":false,"content":"<p>简单声明：</p>\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">var</span> audioCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">;</span>\n</code></pre></div>\n<p>跨浏览器的方式：</p>\n<div class=\"code-example\"><pre class=\"brush: plain notranslate\">var AudioContext = window.AudioContext || window.webkitAudioContext;\nvar audioCtx = new AudioContext();\n\nvar oscillatorNode = audioCtx.createOscillator();\nvar gainNode = audioCtx.createGain();\nvar finish = audioCtx.destination;\n// etc.\n</pre></div>"}},{"type":"specifications","value":{"title":"规范","id":"规范","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#AudioContext","title":"Web Audio API"}],"query":"api.AudioContext"}},{"type":"browser_compatibility","value":{"title":"浏览器兼容性","id":"浏览器兼容性","isH3":false,"query":"api.AudioContext","dataURL":"/zh-CN/docs/Web/API/AudioContext/bcd.json"}},{"type":"prose","value":{"id":"相关链接","title":"相关链接","isH3":false,"content":"<ul>\n  <li>使用 <a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Web Audio API (en-US)</a></li>\n  <li><a href=\"/zh-CN/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li>\n</ul>"}}],"toc":[{"text":"构造函数","id":"构造函数"},{"text":"属性","id":"属性"},{"text":"方法","id":"方法"},{"text":"例子","id":"例子"},{"text":"规范","id":"规范"},{"text":"浏览器兼容性","id":"浏览器兼容性"},{"text":"相关链接","id":"相关链接"}],"summary":"AudioContext接口表示由链接在一起的音频模块构建的音频处理图，每个模块由一个AudioNode表示。音频上下文控制它包含的节点的创建和音频处理或解码的执行。在做任何其他操作之前，您需要创建一个AudioContext对象，因为所有事情都是在上下文中发生的。建议创建一个AudioContext对象并复用它，而不是每次初始化一个新的AudioContext对象，并且可以对多个不同的音频源和管道同时使用一个AudioContext对象。","popularity":0.0009,"modified":"2022-10-01T03:41:16.000Z","other_translations":[{"title":"AudioContext","locale":"en-US","native":"English (US)"},{"title":"AudioContext","locale":"fr","native":"Français"},{"title":"AudioContext","locale":"ja","native":"日本語"},{"title":"AudioContext","locale":"ko","native":"한국어"},{"title":"AudioContext","locale":"pt-BR","native":"Português (do Brasil)"},{"title":"AudioContext","locale":"ru","native":"Русский"}],"source":{"folder":"zh-cn/web/api/audiocontext","github_url":"https://github.com/mdn/translated-content/blob/main/files/zh-cn/web/api/audiocontext/index.md","last_commit_url":"https://github.com/mdn/translated-content/commit/921c46a374ab0a9f4cc809af0370f8c412e54701","filename":"index.md"},"parents":[{"uri":"/zh-CN/docs/Web","title":"Web 开发技术"},{"uri":"/zh-CN/docs/Web/API","title":"Web API 接口参考"},{"uri":"/zh-CN/docs/Web/API/AudioContext","title":"AudioContext"}],"pageTitle":"AudioContext - Web API 接口参考 | MDN","noIndexing":false}}