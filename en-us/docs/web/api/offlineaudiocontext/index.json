{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"OfflineAudioContext","mdn_url":"/en-US/docs/Web/API/OfflineAudioContext","locale":"en-US","native":"English (US)","sidebarHTML":"<ol><li><strong><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></strong></li><li><strong><a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Constructor</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/OfflineAudioContext\"><code>OfflineAudioContext()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Properties</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/length\"><code>length</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Methods</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/resume\"><code>resume()</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/startRendering\"><code>startRendering()</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/suspend\"><code>suspend()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Events</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\"><code>complete</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Inheritance:</summary><ol><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/EventTarget\"><code>EventTarget</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Web Audio API</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>The <code>OfflineAudioContext</code> interface is an <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> interface representing an audio-processing graph built from linked together <a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a>s. In contrast with a standard <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a>, an <code>OfflineAudioContext</code> doesn't render the audio to the device hardware; instead, it generates it, as fast as it can, and outputs the result to an <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a>.</p><svg viewBox=\"-1 -1 650 42\" preserveAspectRatio=\"xMinYMin meet\">\n  <a style=\"text-decoration: none;\" xlink:href=\"/en-US/docs/Web/API/EventTarget\">\n    <rect x=\"0\" y=\"0\" width=\"88\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"44\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      EventTarget\n    </text>\n  </a>\n  <line x1=\"88\" y1=\"14\" x2=\"118\" y2=\"14\" stroke=\"#D4DDE4\" \"=\"\"></line>\n  <polyline points=\"88,14 98,9 98,19 88,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" xlink:href=\"/en-US/docs/Web/API/BaseAudioContext\">\n    <rect x=\"118\" y=\"0\" width=\"128\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"182\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      BaseAudioContext\n    </text>\n  </a>\n  <line x1=\"246\" y1=\"14\" x2=\"276\" y2=\"14\" stroke=\"#D4DDE4\" \"=\"\"></line>\n  <polyline points=\"246,14 256,9 256,19 246,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" xlink:href=\"/en-US/docs/Web/API/OfflineAudioContext\" aria-current=\"page\">\n    <rect x=\"276\" y=\"0\" width=\"152\" height=\"25\" fill=\"#F4F7F8\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"352\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      OfflineAudioContext\n    </text>\n  </a></svg>"}},{"type":"prose","value":{"id":"constructor","title":"Constructor","isH3":false,"content":"<dl>\n  <dt id=\"offlineaudiocontext\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/OfflineAudioContext\" title=\"OfflineAudioContext()\"><code>OfflineAudioContext()</code></a></dt>\n  <dd>\n    <p>Creates a new <code>OfflineAudioContext</code> instance.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"properties","title":"Properties","isH3":false,"content":"<p><em>Also inherits properties from its parent interface, <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>.</em></p>\n<dl>\n  <dt id=\"offlineaudiocontext.length\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/length\"><code>OfflineAudioContext.length</code></a> <span title=\"This value may not be changed.\" class=\"badge inline readonly\">Read only </span></dt>\n  <dd>\n    <p>An integer representing the size of the buffer in sample-frames.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"methods","title":"Methods","isH3":false,"content":"<p><em>Also inherits methods from its parent interface, <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>.</em></p>\n<dl>\n  <dt id=\"offlineaudiocontext.suspend\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/suspend\"><code>OfflineAudioContext.suspend()</code></a></dt>\n  <dd>\n    <p>Schedules a suspension of the time progression in the audio context at the specified time and returns a promise.</p>\n  </dd>\n  <dt id=\"offlineaudiocontext.startrendering\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/startRendering\"><code>OfflineAudioContext.startRendering()</code></a></dt>\n  <dd>\n    <p>Starts rendering the audio, taking into account the current connections and the current scheduled changes. This page covers both the event-based version and the promise-based version.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"deprecated_methods","title":"Deprecated methods","isH3":true,"content":"<dl>\n  <dt id=\"offlineaudiocontext.resume\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/resume\"><code>OfflineAudioContext.resume()</code></a></dt>\n  <dd>\n    <p>Resumes the progression of time in an audio context that has previously been suspended.</p>\n  </dd>\n</dl>\n<div class=\"notecard note\" id=\"sect1\">\n  <p><strong>Note:</strong> The <code>resume()</code> method is still available — it is now defined on the <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a> interface (see <a href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>AudioContext.resume</code></a>) and thus can be accessed by both the <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> and <a href=\"/en-US/docs/Web/API/OfflineAudioContext\" aria-current=\"page\"><code>OfflineAudioContext</code></a> interfaces.</p>\n</div>"}},{"type":"prose","value":{"id":"events","title":"Events","isH3":false,"content":"<p>Listen to these events using <a href=\"/en-US/docs/Web/API/EventTarget/addEventListener\"><code>addEventListener()</code></a> or by assigning an event listener to the <code>oneventname</code> property of this interface:</p>\n<dl>\n  <dt id=\"complete\"><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\"><code>complete</code></a></dt>\n  <dd>\n    <p>Fired when the rendering of an offline audio context is complete.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"examples","title":"Examples","isH3":false,"content":"<p>In this simple example, we declare both an <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> and an <code>OfflineAudioContext</code> object. We use the <code>AudioContext</code> to load an audio track via XHR (<a href=\"/en-US/docs/Web/API/BaseAudioContext/decodeAudioData\"><code>BaseAudioContext.decodeAudioData</code></a>), then the <code>OfflineAudioContext</code> to render the audio into an <a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a> and play the track through. After the offline audio graph is set up, you need to render it to an <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> using <a href=\"/en-US/docs/Web/API/OfflineAudioContext/startRendering\"><code>OfflineAudioContext.startRendering</code></a>.</p>\n<p>When the <code>startRendering()</code> promise resolves, rendering has completed and the output <code>AudioBuffer</code> is returned out of the promise.</p>\n<p>At this point we create another audio context, create an <a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a> inside it, and set its buffer to be equal to the promise <code>AudioBuffer</code>. This is then played as part of a simple standard audio graph.</p>\n<div class=\"notecard note\" id=\"sect2\">\n  <p><strong>Note:</strong> For a working example, see our <a href=\"https://mdn.github.io/webaudio-examples/offline-audio-context-promise/\" class=\"external\" rel=\" noopener\">offline-audio-context-promise</a> GitHub repo (see the <a href=\"https://github.com/mdn/webaudio-examples/tree/master/offline-audio-context-promise\" class=\"external\" rel=\" noopener\">source code</a> too.)</p>\n</div>\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token comment\">// define online and offline audio context</span>\n\n<span class=\"token keyword\">const</span> audioCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> offlineCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">OfflineAudioContext</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">44100</span><span class=\"token operator\">*</span><span class=\"token number\">40</span><span class=\"token punctuation\">,</span><span class=\"token number\">44100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\nsource <span class=\"token operator\">=</span> offlineCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createBufferSource</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// use XHR to load an audio track, and</span>\n<span class=\"token comment\">// decodeAudioData to decode it and OfflineAudioContext to render it</span>\n\n<span class=\"token keyword\">function</span> <span class=\"token function\">getData</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  request <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">XMLHttpRequest</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  request<span class=\"token punctuation\">.</span><span class=\"token function\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'GET'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'viper.ogg'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  request<span class=\"token punctuation\">.</span>responseType <span class=\"token operator\">=</span> <span class=\"token string\">'arraybuffer'</span><span class=\"token punctuation\">;</span>\n\n  request<span class=\"token punctuation\">.</span><span class=\"token function-variable function\">onload</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=&gt;</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">const</span> audioData <span class=\"token operator\">=</span> request<span class=\"token punctuation\">.</span>response<span class=\"token punctuation\">;</span>\n\n    audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">decodeAudioData</span><span class=\"token punctuation\">(</span>audioData<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token parameter\">buffer</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=&gt;</span> <span class=\"token punctuation\">{</span>\n      myBuffer <span class=\"token operator\">=</span> buffer<span class=\"token punctuation\">;</span>\n      source<span class=\"token punctuation\">.</span>buffer <span class=\"token operator\">=</span> myBuffer<span class=\"token punctuation\">;</span>\n      source<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>offlineCtx<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      source<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token comment\">//source.loop = true;</span>\n      offlineCtx<span class=\"token punctuation\">.</span><span class=\"token function\">startRendering</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">then</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">renderedBuffer</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=&gt;</span> <span class=\"token punctuation\">{</span>\n        console<span class=\"token punctuation\">.</span><span class=\"token function\">log</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Rendering completed successfully'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">const</span> song <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createBufferSource</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        song<span class=\"token punctuation\">.</span>buffer <span class=\"token operator\">=</span> renderedBuffer<span class=\"token punctuation\">;</span>\n\n        song<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>audioCtx<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        play<span class=\"token punctuation\">.</span><span class=\"token function-variable function\">onclick</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=&gt;</span> <span class=\"token punctuation\">{</span>\n          song<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">catch</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">err</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=&gt;</span> <span class=\"token punctuation\">{</span>\n          console<span class=\"token punctuation\">.</span><span class=\"token function\">error</span><span class=\"token punctuation\">(</span><span class=\"token template-string\"><span class=\"token template-punctuation string\">`</span><span class=\"token string\">Rendering failed: </span><span class=\"token interpolation\"><span class=\"token interpolation-punctuation punctuation\">${</span>err<span class=\"token interpolation-punctuation punctuation\">}</span></span><span class=\"token template-punctuation string\">`</span></span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n          <span class=\"token comment\">// Note: The promise should reject when startRendering is called a second time on an OfflineAudioContext</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n\n  request<span class=\"token punctuation\">.</span><span class=\"token function\">send</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// Run getData to start the process off</span>\n\n<span class=\"token function\">getData</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre></div>"}},{"type":"specifications","value":{"title":"Specifications","id":"specifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#OfflineAudioContext","title":"Web Audio API"}],"query":"api.OfflineAudioContext"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.OfflineAudioContext","dataURL":"/en-US/docs/Web/API/OfflineAudioContext/bcd.json"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Using the Web Audio API</a></li>\n</ul>"}}],"toc":[{"text":"Constructor","id":"constructor"},{"text":"Properties","id":"properties"},{"text":"Methods","id":"methods"},{"text":"Events","id":"events"},{"text":"Examples","id":"examples"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"The OfflineAudioContext interface is an AudioContext interface representing an audio-processing graph built from linked together AudioNodes. In contrast with a standard AudioContext, an OfflineAudioContext doesn't render the audio to the device hardware; instead, it generates it, as fast as it can, and outputs the result to an AudioBuffer.","popularity":0.0007,"modified":"2022-09-09T05:17:24.000Z","other_translations":[{"title":"OfflineAudioContext","locale":"ja","native":"日本語"},{"title":"OfflineAudioContext","locale":"ko","native":"한국어"},{"title":"OfflineAudioContext","locale":"pt-BR","native":"Português (do Brasil)"},{"title":"OfflineAudioContext","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"en-us/web/api/offlineaudiocontext","github_url":"https://github.com/mdn/content/blob/style/old/files/en-us/web/api/offlineaudiocontext/index.md","last_commit_url":"https://github.com/mdn/content/commit/4b4638246aad5d39b9a2e5c572b179b4c39c0a84","filename":"index.md"},"parents":[{"uri":"/en-US/docs/Web","title":"Web technology for developers"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/OfflineAudioContext","title":"OfflineAudioContext"}],"pageTitle":"OfflineAudioContext - Web APIs | MDN","noIndexing":false}}