{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"Media Capture and Streams API (Media Stream)","mdn_url":"/en-US/docs/Web/API/Media_Capture_and_Streams_API","locale":"en-US","native":"English (US)","sidebarHTML":"<ol><li><strong><a href=\"/en-US/docs/Web/API/Media_Capture_and_Streams_API\">Media Capture and Streams API</a></strong></li><li><strong><a href=\"/en-US/docs/Web/API/Media_Capture_and_Streams_API\"><code>Media_Capture_and_Streams_API</code></a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Media Capture and Streams</summary><ol><li><a href=\"/en-US/docs/Web/API/CanvasCaptureMediaStreamTrack\"><code>CanvasCaptureMediaStreamTrack</code></a></li><li><a href=\"/en-US/docs/Web/API/HTMLCanvasElement/captureStream\"><code>HTMLCanvasElement.captureStream()</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaDevices\"><code>MediaDevices</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaDevices/getUserMedia\"><code>MediaDevices.getUserMedia()</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStream\"><code>MediaStream</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamTrack\"><code>MediaStreamTrack</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamTrackEvent\"><code>MediaStreamTrackEvent</code></a></li><li><a class=\"page-not-created\" title=\"The documentation about this has not yet been written; please consider contributing!\"><code>MediaTrackCapabilities</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaTrackConstraints\"><code>MediaTrackConstraints</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaTrackSettings\"><code>MediaTrackSettings</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaTrackSupportedConstraints\"><code>MediaTrackSupportedConstraints</code></a></li><li><a href=\"/en-US/docs/Web/API/Navigator/mediaDevices\"><code>Navigator.mediaDevices</code></a></li><li><a class=\"page-not-created\" title=\"The documentation about this has not yet been written; please consider contributing!\"><code>VideoStreamTrack</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>The <strong>Media Capture and Streams</strong> API, often called the <strong>Media Streams API</strong> or <strong>MediaStream API</strong>, is an API related to <a href=\"/en-US/docs/Web/API/WebRTC_API\">WebRTC</a> which provides support for streaming audio and video data.</p>\n<p>It provides the interfaces and methods for working with the streams and their constituent tracks, the constraints associated with data formats, the success and error callbacks when using the data asynchronously, and the events that are fired during the process.</p>"}},{"type":"prose","value":{"id":"concepts_and_usage","title":"Concepts and usage","isH3":false,"content":"<p>The API is based on the manipulation of a <a href=\"/en-US/docs/Web/API/MediaStream\"><code>MediaStream</code></a> object representing a flux of audio- or video-related data. See an example in <a href=\"/en-US/docs/Web/API/Media_Capture_and_Streams_API/Taking_still_photos#the_startup_function\">Get the media stream</a>.</p>\n<p>A <code>MediaStream</code> consists of zero or more <a href=\"/en-US/docs/Web/API/MediaStreamTrack\"><code>MediaStreamTrack</code></a> objects, representing various audio or video <strong>tracks</strong>. Each <code>MediaStreamTrack</code> may have one or more <strong>channels</strong>. The channel represents the smallest unit of a media stream, such as an audio signal associated with a given speaker, like <em>left</em> or <em>right</em> in a stereo audio track.</p>\n<p><code>MediaStream</code> objects have a single <strong>input</strong> and a single <strong>output</strong>. A <code>MediaStream</code> object generated by <a href=\"/en-US/docs/Web/API/MediaDevices/getUserMedia\" title=\"getUserMedia()\"><code>getUserMedia()</code></a> is called <em>local</em>, and has as its source input one of the user's cameras or microphones. A non-local <code>MediaStream</code> may be representing a media element, like <a href=\"/en-US/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a> or <a href=\"/en-US/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a>, a stream originating over the network, and obtained via the WebRTC <a href=\"/en-US/docs/Web/API/RTCPeerConnection\"><code>RTCPeerConnection</code></a> API, or a stream created using the <a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a> <a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a>.</p>\n<p>The output of the <code>MediaStream</code> object is linked to a <strong>consumer</strong>. It can be a media element, like <a href=\"/en-US/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a> or <a href=\"/en-US/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a>, the WebRTC <a href=\"/en-US/docs/Web/API/RTCPeerConnection\"><code>RTCPeerConnection</code></a> API or a <a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a> <a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a>.</p>"}},{"type":"prose","value":{"id":"interfaces","title":"Interfaces","isH3":false,"content":"<p>In these reference articles, you'll find the fundamental information you'll need to know about each of the interfaces that make up the Media Capture and Streams API.</p>\n<ul>\n  <li><a href=\"/en-US/docs/Web/API/CanvasCaptureMediaStreamTrack\"><code>CanvasCaptureMediaStreamTrack</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/InputDeviceInfo\"><code>InputDeviceInfo</code></a></li>\n  <li><a class=\"page-not-created\" title=\"The documentation about this has not yet been written; please consider contributing!\"><code>MediaDeviceKind</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaDeviceInfo\"><code>MediaDeviceInfo</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaDevices\"><code>MediaDevices</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaStream\"><code>MediaStream</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaStreamEvent\"><code>MediaStreamEvent</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaStreamTrack\"><code>MediaStreamTrack</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaStreamTrackEvent\"><code>MediaStreamTrackEvent</code></a></li>\n  <li><a class=\"page-not-created\" title=\"The documentation about this has not yet been written; please consider contributing!\"><code>MediaTrackCapabilities</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaTrackConstraints\"><code>MediaTrackConstraints</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaTrackSettings\"><code>MediaTrackSettings</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaTrackSupportedConstraints\"><code>MediaTrackSupportedConstraints</code></a></li>\n  <li><a class=\"page-not-created\" title=\"The documentation about this has not yet been written; please consider contributing!\"><code>NavigatorUserMedia</code></a></li>\n  <li><a class=\"page-not-created\" title=\"The documentation about this has not yet been written; please consider contributing!\"><code>NavigatorUserMediaError</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/OverconstrainedError\"><code>OverconstrainedError</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/URL\"><code>URL</code></a></li>\n</ul>\n<p>Early versions of the Media Capture and Streams API specification included separate <code>AudioStreamTrack</code> and <code>VideoStreamTrack</code> interfaces—each based upon <a href=\"/en-US/docs/Web/API/MediaStreamTrack\"><code>MediaStreamTrack</code></a>—which represented streams of those types. These no longer exist, and you should update any existing code to instead use <code>MediaStreamTrack</code> directly.</p>"}},{"type":"prose","value":{"id":"events","title":"Events","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/MediaStream/addtrack_event\" title=\"addtrack\"><code>addtrack</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaStreamTrack/ended_event\" title=\"ended\"><code>ended</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaStreamTrack/mute_event\" title=\"mute\"><code>mute</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaStreamTrack/overconstrained_event\" title=\"overconstrained\"><code>overconstrained</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaStream/removetrack_event\" title=\"removetrack\"><code>removetrack</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/MediaStreamTrack/unmute_event\" title=\"unmute\"><code>unmute</code></a></li>\n</ul>"}},{"type":"prose","value":{"id":"guides_and_tutorials","title":"Guides and tutorials","isH3":false,"content":"<p>The <a href=\"/en-US/docs/Web/API/Media_Capture_and_Streams_API/Constraints\">Capabilities, constraints, and settings</a> article discusses the concepts of <strong>constraints</strong> and <strong>capabilities</strong>, as well as media settings, and includes a <a href=\"/en-US/docs/Web/API/Media_Capture_and_Streams_API/Constraints#example_constraint_exerciser\">Constraint Exerciser</a> that lets you experiment with the results of different constraint sets being applied to the audio and video tracks coming from the computer's A/V input devices (such as its webcam and microphone).</p>\n<p>The <a href=\"/en-US/docs/Web/API/Media_Capture_and_Streams_API/Taking_still_photos\">Taking still photos with getUserMedia()</a> article shows how to use <a href=\"/en-US/docs/Web/API/MediaDevices/getUserMedia\"><code>getUserMedia()</code></a> to access the camera on a computer or mobile phone with <code>getUserMedia()</code> support and take a photo with it.</p>"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.MediaStream","dataURL":"/en-US/docs/Web/API/Media_Capture_and_Streams_API/bcd.json"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/WebRTC_API\">WebRTC</a> - the introductory page to the API</li>\n  <li><a href=\"/en-US/docs/Web/API/MediaDevices/getUserMedia\"><code>mediaDevices.getUserMedia()</code></a></li>\n  <li><a href=\"/en-US/docs/Web/API/Media_Capture_and_Streams_API/Taking_still_photos\">Taking still photos with WebRTC</a>: a demonstration and tutorial about using <code>getUserMedia()</code>.</li>\n</ul>"}}],"toc":[{"text":"Concepts and usage","id":"concepts_and_usage"},{"text":"Interfaces","id":"interfaces"},{"text":"Events","id":"events"},{"text":"Guides and tutorials","id":"guides_and_tutorials"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"The Media Capture and Streams API, often called the Media Streams API or MediaStream API, is an API related to WebRTC which provides support for streaming audio and video data.","popularity":0.003,"modified":"2022-09-09T05:17:24.000Z","other_translations":[{"title":"API de MediaStream","locale":"es","native":"Español"},{"title":"API MediaStream","locale":"fr","native":"Français"},{"title":"Media Capture and Streams API (Media Streams)","locale":"ja","native":"日本語"},{"title":"Media Capture and Streams API (미디어 스트림)","locale":"ko","native":"한국어"},{"title":"MediaStream API","locale":"zh-CN","native":"中文 (简体)"},{"title":"Media Capture and Streams API (Media Stream)","locale":"zh-TW","native":"正體中文 (繁體)"}],"source":{"folder":"en-us/web/api/media_capture_and_streams_api","github_url":"https://github.com/mdn/content/blob/style/old/files/en-us/web/api/media_capture_and_streams_api/index.md","last_commit_url":"https://github.com/mdn/content/commit/4b4638246aad5d39b9a2e5c572b179b4c39c0a84","filename":"index.md"},"parents":[{"uri":"/en-US/docs/Web","title":"Web technology for developers"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/Media_Capture_and_Streams_API","title":"Media Capture and Streams API (Media Stream)"}],"pageTitle":"Media Capture and Streams API (Media Stream) - Web APIs | MDN","noIndexing":false}}