{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"BaseAudioContext.createBuffer()","mdn_url":"/en-US/docs/Web/API/BaseAudioContext/createBuffer","locale":"en-US","native":"English (US)","sidebarHTML":"<ol><li><strong><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></strong></li><li><strong><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Properties</summary><ol><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/audioWorklet\"><code>audioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/currentTime\"><code>currentTime</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/destination\"><code>destination</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/listener\"><code>listener</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/sampleRate\"><code>sampleRate</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/state\"><code>state</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Methods</summary><ol><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createAnalyser\"><code>createAnalyser()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createBiquadFilter\"><code>createBiquadFilter()</code></a></li><li><em><code>createBuffer()</code></em></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createBufferSource\"><code>createBufferSource()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createChannelMerger\"><code>createChannelMerger()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createChannelSplitter\"><code>createChannelSplitter()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createConstantSource\"><code>createConstantSource()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createConvolver\"><code>createConvolver()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createDelay\"><code>createDelay()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createDynamicsCompressor\"><code>createDynamicsCompressor()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createGain\"><code>createGain()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createIIRFilter\"><code>createIIRFilter()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createOscillator\"><code>createOscillator()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createPanner\"><code>createPanner()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createPeriodicWave\"><code>createPeriodicWave()</code></a></li><li><svg class=\"icon icon-deprecated\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-deprecated\"></use>\n</svg><a href=\"/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor\"><code>createScriptProcessor()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createStereoPanner\"><code>createStereoPanner()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/createWaveShaper\"><code>createWaveShaper()</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext/decodeAudioData\"><code>decodeAudioData()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Inheritance:</summary><ol><li><a href=\"/en-US/docs/Web/API/EventTarget\"><code>EventTarget</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Web Audio API</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>\n  The <code>createBuffer()</code> method of the <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>\n  Interface is used to create a new, empty <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> object, which\n  can then be populated by data, and played via an <a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a>\n</p>\n<p>\n  For more details about audio buffers, check out the <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a>\n  reference page.\n</p>\n<div class=\"notecard note\" id=\"sect1\">\n  <p>\n    <strong>Note:</strong> <code>createBuffer()</code> used to be able to take compressed\n    data and give back decoded samples, but this ability was removed from the specification,\n    because all the decoding was done on the main thread, so\n    <code>createBuffer()</code> was blocking other code execution. The asynchronous method\n    <code>decodeAudioData()</code> does the same thing — takes compressed audio, such as an\n    MP3 file, and directly gives you back an <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> that you can\n    then play via an <a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a>. For simple use cases\n    like playing an MP3, <code>decodeAudioData()</code> is what you should be using.\n  </p>\n</div>"}},{"type":"prose","value":{"id":"syntax","title":"Syntax","isH3":false,"content":"<div class=\"code-example\"><pre class=\"brush: js-nolint notranslate\">createBuffer(numOfChannels, length, sampleRate)\n</pre></div>"}},{"type":"prose","value":{"id":"parameters","title":"Parameters","isH3":true,"content":"<div class=\"notecard note\" id=\"sect2\">\n  <p>\n    <strong>Note:</strong> For an in-depth explanation of how audio buffers work, and\n    what these parameters mean, read <a href=\"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_buffers.3a_frames.2c_samples_and_channels\">Audio buffers: frames, samples and channels</a> from our Basic concepts guide.\n  </p>\n</div>\n<dl>\n  <dt id=\"numofchannels\"><code>numOfChannels</code></dt>\n  <dd>\n    <p>\n      An integer representing the number of channels this buffer should have. The default\n      value is 1, and all user agents must support at least 32 channels.\n    </p>\n  </dd>\n  <dt id=\"length\"><code>length</code></dt>\n  <dd>\n    <p>\n      An integer representing the size of the buffer in sample-frames (where each\n      sample-frame is the size of a sample in bytes multiplied by\n      <code>numOfChannels</code>). To determine the <code>length</code> to use for a\n      specific number of seconds of audio, use <code>numSeconds * sampleRate</code>.\n    </p>\n  </dd>\n  <dt id=\"samplerate\"><code>sampleRate</code></dt>\n  <dd>\n    <p>\n      The sample rate of the linear audio data in sample-frames per second. All browsers\n      must support sample rates in at least the range 8,000 Hz to 96,000 Hz.\n    </p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"return_value","title":"Return value","isH3":true,"content":"<p>An <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> configured based on the specified options.</p>"}},{"type":"prose","value":{"id":"exceptions","title":"Exceptions","isH3":true,"content":"<dl>\n  <dt id=\"notsupportederror\"><code>NotSupportedError</code> <a href=\"/en-US/docs/Web/API/DOMException\"><code>DOMException</code></a></dt>\n  <dd>\n    <p>\n      Thrown if one or more of the options are negative or otherwise has an invalid value (such as\n      <code>numberOfChannels</code> being higher than supported, or a\n      <code>sampleRate</code> outside the nominal range).\n    </p>\n  </dd>\n  <dt id=\"rangeerror\"><a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/RangeError\"><code>RangeError</code></a></dt>\n  <dd>\n    <p>Thrown if there isn't enough memory available to allocate the buffer.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"examples","title":"Examples","isH3":false,"content":"<p>\n  First, a couple of simple trivial examples, to help explain how the parameters are\n  used:\n</p>\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">const</span> audioCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> buffer <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createBuffer</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">22050</span><span class=\"token punctuation\">,</span> <span class=\"token number\">44100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre></div>\n<p>\n  If you use this call, you will get a stereo buffer (two channels), that, when played\n  back on an AudioContext running at 44100Hz (very common, most normal sound cards run at\n  this rate), will last for 0.5 seconds: 22050 frames / 44100Hz = 0.5 seconds.\n</p>\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">const</span> audioCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> buffer <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createBuffer</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">22050</span><span class=\"token punctuation\">,</span> <span class=\"token number\">22050</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre></div>\n<p>\n  If you use this call, you will get a mono buffer (one channel), that, when played back\n  on an <code>AudioContext</code> running at 44100Hz, will be automatically *resampled* to\n  44100Hz (and therefore yield 44100 frames), and last for 1.0 second: 44100 frames /\n  44100Hz = 1 second.\n</p>\n<div class=\"notecard note\" id=\"sect3\">\n  <p>\n    <strong>Note:</strong> audio resampling is very similar to image resizing: say you've\n    got a 16 x 16 image, but you want it to fill a 32x32 area: you resize (resample) it.\n    the result has less quality (it can be blurry or edgy, depending on the resizing\n    algorithm), but it works, and the resized image takes up less space. Resampled audio\n    is exactly the same — you save space, but in practice you will be unable to properly\n    reproduce high frequency content (treble sound).\n  </p>\n</div>\n<p>\n  Now let's look at a more complex <code>createBuffer()</code> example, in which we\n  create a three-second buffer, fill it with white noise, and then play it via an <a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a>. The comment should clearly explain what is going\n  on. You can also <a href=\"https://mdn.github.io/webaudio-examples/audio-buffer/\" class=\"external\" rel=\" noopener\">run the code live</a>, or <a href=\"https://github.com/mdn/webaudio-examples/blob/master/audio-buffer/index.html\" class=\"external\" rel=\" noopener\">view the source</a>.\n</p>\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">const</span> audioCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token punctuation\">(</span>window<span class=\"token punctuation\">.</span>AudioContext <span class=\"token operator\">||</span> window<span class=\"token punctuation\">.</span>webkitAudioContext<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Create an empty three-second stereo buffer at the sample rate of the AudioContext</span>\n<span class=\"token keyword\">const</span> myArrayBuffer <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createBuffer</span><span class=\"token punctuation\">(</span>\n  <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n  audioCtx<span class=\"token punctuation\">.</span>sampleRate <span class=\"token operator\">*</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\n  audioCtx<span class=\"token punctuation\">.</span>sampleRate\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Fill the buffer with white noise;</span>\n<span class=\"token comment\">// just random values between -1.0 and 1.0</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">let</span> channel <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> channel <span class=\"token operator\">&lt;</span> myArrayBuffer<span class=\"token punctuation\">.</span>numberOfChannels<span class=\"token punctuation\">;</span> channel<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token comment\">// This gives us the actual ArrayBuffer that contains the data</span>\n  <span class=\"token keyword\">const</span> nowBuffering <span class=\"token operator\">=</span> myArrayBuffer<span class=\"token punctuation\">.</span><span class=\"token function\">getChannelData</span><span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">let</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> myArrayBuffer<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\">// Math.random() is in [0; 1.0]</span>\n    <span class=\"token comment\">// audio needs to be in [-1.0; 1.0]</span>\n    nowBuffering<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> Math<span class=\"token punctuation\">.</span><span class=\"token function\">random</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// Get an AudioBufferSourceNode.</span>\n<span class=\"token comment\">// This is the AudioNode to use when we want to play an AudioBuffer</span>\n<span class=\"token keyword\">const</span> source <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createBufferSource</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">// set the buffer in the AudioBufferSourceNode</span>\nsource<span class=\"token punctuation\">.</span>buffer <span class=\"token operator\">=</span> myArrayBuffer<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">// connect the AudioBufferSourceNode to the</span>\n<span class=\"token comment\">// destination so we can hear the sound</span>\nsource<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>audioCtx<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">// start the source playing</span>\nsource<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre></div>"}},{"type":"specifications","value":{"title":"Specifications","id":"specifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#dom-baseaudiocontext-createbuffer","title":"Web Audio API"}],"query":"api.BaseAudioContext.createBuffer"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.BaseAudioContext.createBuffer","dataURL":"/en-US/docs/Web/API/BaseAudioContext/createBuffer/bcd.json"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Using the Web Audio API</a></li>\n</ul>"}}],"toc":[{"text":"Syntax","id":"syntax"},{"text":"Examples","id":"examples"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"The createBuffer() method of the BaseAudioContext\n  Interface is used to create a new, empty AudioBuffer object, which\n  can then be populated by data, and played via an AudioBufferSourceNode","popularity":0.0005,"modified":"2022-09-15T18:16:38.000Z","other_translations":[{"title":"BaseAudioContext.createBuffer()","locale":"fr","native":"Français"},{"title":"BaseAudioContext.createBuffer()","locale":"ja","native":"日本語"},{"title":"AudioContext.createBuffer()","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"en-us/web/api/baseaudiocontext/createbuffer","github_url":"https://github.com/mdn/content/blob/style/old/files/en-us/web/api/baseaudiocontext/createbuffer/index.md","last_commit_url":"https://github.com/mdn/content/commit/418f9cf461de0c7845665c0c677ad0667740f52a","filename":"index.md"},"parents":[{"uri":"/en-US/docs/Web","title":"Web technology for developers"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/BaseAudioContext","title":"BaseAudioContext"},{"uri":"/en-US/docs/Web/API/BaseAudioContext/createBuffer","title":"BaseAudioContext.createBuffer()"}],"pageTitle":"BaseAudioContext.createBuffer() - Web APIs | MDN","noIndexing":false}}