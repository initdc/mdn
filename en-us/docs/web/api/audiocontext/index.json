{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"AudioContext","mdn_url":"/en-US/docs/Web/API/AudioContext","locale":"en-US","native":"English (US)","sidebarHTML":"<ol><li><strong><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></strong></li><li><strong><a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Constructor</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioContext/AudioContext\"><code>AudioContext()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Properties</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioContext/baseLatency\"><code>baseLatency</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/outputLatency\"><code>outputLatency</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Methods</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioContext/close\"><code>close()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/createMediaElementSource\"><code>createMediaElementSource()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamDestination\"><code>createMediaStreamDestination()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamSource\"><code>createMediaStreamSource()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource\"><code>createMediaStreamTrackSource()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/getOutputTimestamp\"><code>getOutputTimestamp()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>resume()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/suspend\"><code>suspend()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Inheritance:</summary><ol><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/EventTarget\"><code>EventTarget</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Web Audio API</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>The <code>AudioContext</code> interface represents an audio-processing graph built from audio modules linked together, each represented by an <a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a>.</p>\n<p>An audio context controls both the creation of the nodes it contains and the execution of the audio processing, or decoding. You need to create an <code>AudioContext</code> before you do anything else, as everything happens inside a context. It's recommended to create one AudioContext and reuse it instead of initializing a new one each time, and it's OK to use a single <code>AudioContext</code> for several different audio sources and pipeline concurrently.</p><svg viewBox=\"-1 -1 650 42\" preserveAspectRatio=\"xMinYMin meet\">\n  <a style=\"text-decoration: none;\" xlink:href=\"/en-US/docs/Web/API/EventTarget\">\n    <rect x=\"0\" y=\"0\" width=\"88\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"44\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      EventTarget\n    </text>\n  </a>\n  <line x1=\"88\" y1=\"14\" x2=\"118\" y2=\"14\" stroke=\"#D4DDE4\" \"=\"\"></line>\n  <polyline points=\"88,14 98,9 98,19 88,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" xlink:href=\"/en-US/docs/Web/API/BaseAudioContext\">\n    <rect x=\"118\" y=\"0\" width=\"128\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"182\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      BaseAudioContext\n    </text>\n  </a>\n  <line x1=\"246\" y1=\"14\" x2=\"276\" y2=\"14\" stroke=\"#D4DDE4\" \"=\"\"></line>\n  <polyline points=\"246,14 256,9 256,19 246,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" xlink:href=\"/en-US/docs/Web/API/AudioContext\" aria-current=\"page\">\n    <rect x=\"276\" y=\"0\" width=\"96\" height=\"25\" fill=\"#F4F7F8\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"324\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      AudioContext\n    </text>\n  </a></svg>"}},{"type":"prose","value":{"id":"constructor","title":"Constructor","isH3":false,"content":"<dl>\n  <dt id=\"audiocontext\"><a href=\"/en-US/docs/Web/API/AudioContext/AudioContext\" title=\"AudioContext()\"><code>AudioContext()</code></a></dt>\n  <dd>\n    <p>Creates and returns a new <code>AudioContext</code> object.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"properties","title":"Properties","isH3":false,"content":"<p><em>Also inherits properties from its parent interface, <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>.</em></p>\n<dl>\n  <dt id=\"audiocontext.baselatency\"><a href=\"/en-US/docs/Web/API/AudioContext/baseLatency\"><code>AudioContext.baseLatency</code></a> <span title=\"This value may not be changed.\" class=\"badge inline readonly\">Read only </span></dt>\n  <dd>\n    <p>Returns the number of seconds of processing latency incurred by the <a href=\"/en-US/docs/Web/API/AudioContext\" aria-current=\"page\"><code>AudioContext</code></a> passing the audio from the <a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a> to the audio subsystem.</p>\n  </dd>\n  <dt id=\"audiocontext.outputlatency\"><a href=\"/en-US/docs/Web/API/AudioContext/outputLatency\"><code>AudioContext.outputLatency</code></a> <span title=\"This value may not be changed.\" class=\"badge inline readonly\">Read only </span></dt>\n  <dd>\n    <p>Returns an estimation of the output latency of the current audio context.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"methods","title":"Methods","isH3":false,"content":"<p><em>Also inherits methods from its parent interface, <a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a>.</em></p>\n<dl>\n  <dt id=\"audiocontext.close\"><a href=\"/en-US/docs/Web/API/AudioContext/close\"><code>AudioContext.close()</code></a></dt>\n  <dd>\n    <p>Closes the audio context, releasing any system audio resources that it uses.</p>\n  </dd>\n  <dt id=\"audiocontext.createmediaelementsource\"><a href=\"/en-US/docs/Web/API/AudioContext/createMediaElementSource\"><code>AudioContext.createMediaElementSource()</code></a></dt>\n  <dd>\n    <p>Creates a <a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a> associated with an <a href=\"/en-US/docs/Web/API/HTMLMediaElement\"><code>HTMLMediaElement</code></a>. This can be used to play and manipulate audio from <a href=\"/en-US/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a> or <a href=\"/en-US/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a> elements.</p>\n  </dd>\n  <dt id=\"audiocontext.createmediastreamsource\"><a href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamSource\"><code>AudioContext.createMediaStreamSource()</code></a></dt>\n  <dd>\n    <p>Creates a <a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a> associated with a <a href=\"/en-US/docs/Web/API/MediaStream\"><code>MediaStream</code></a> representing an audio stream which may come from the local computer microphone or other sources.</p>\n  </dd>\n  <dt id=\"audiocontext.createmediastreamdestination\"><a href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamDestination\"><code>AudioContext.createMediaStreamDestination()</code></a></dt>\n  <dd>\n    <p>Creates a <a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a> associated with a <a href=\"/en-US/docs/Web/API/MediaStream\"><code>MediaStream</code></a> representing an audio stream which may be stored in a local file or sent to another computer.</p>\n  </dd>\n  <dt id=\"audiocontext.createmediastreamtracksource\"><a href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource\"><code>AudioContext.createMediaStreamTrackSource()</code></a></dt>\n  <dd>\n    <p>Creates a <a href=\"/en-US/docs/Web/API/MediaStreamTrackAudioSourceNode\"><code>MediaStreamTrackAudioSourceNode</code></a> associated with a <a href=\"/en-US/docs/Web/API/MediaStream\"><code>MediaStream</code></a> representing an media stream track.</p>\n  </dd>\n  <dt id=\"audiocontext.getoutputtimestamp\"><a href=\"/en-US/docs/Web/API/AudioContext/getOutputTimestamp\"><code>AudioContext.getOutputTimestamp()</code></a></dt>\n  <dd>\n    <p>Returns a new <code>AudioTimestamp</code> object containing two audio timestamp values relating to the current audio context.</p>\n  </dd>\n  <dt id=\"audiocontext.resume\"><a href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>AudioContext.resume()</code></a></dt>\n  <dd>\n    <p>Resumes the progression of time in an audio context that has previously been suspended/paused.</p>\n  </dd>\n  <dt id=\"audiocontext.suspend\"><a href=\"/en-US/docs/Web/API/AudioContext/suspend\"><code>AudioContext.suspend()</code></a></dt>\n  <dd>\n    <p>Suspends the progression of time in the audio context, temporarily halting audio hardware access and reducing CPU/battery usage in the process.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"examples","title":"Examples","isH3":false,"content":"<p>Basic audio context declaration:</p>\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">const</span> audioCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">const</span> oscillatorNode <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createOscillator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> gainNode <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> finish <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">// etc.</span>\n</code></pre></div>"}},{"type":"specifications","value":{"title":"Specifications","id":"specifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#AudioContext","title":"Web Audio API"}],"query":"api.AudioContext"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.AudioContext","dataURL":"/en-US/docs/Web/API/AudioContext/bcd.json"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Using the Web Audio API</a></li>\n  <li><a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li>\n</ul>"}}],"toc":[{"text":"Constructor","id":"constructor"},{"text":"Properties","id":"properties"},{"text":"Methods","id":"methods"},{"text":"Examples","id":"examples"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"The AudioContext interface represents an audio-processing graph built from audio modules linked together, each represented by an AudioNode.","popularity":0.0032,"modified":"2022-09-09T05:07:36.000Z","other_translations":[{"title":"AudioContext","locale":"fr","native":"Français"},{"title":"AudioContext","locale":"ja","native":"日本語"},{"title":"AudioContext","locale":"ko","native":"한국어"},{"title":"AudioContext","locale":"pt-BR","native":"Português (do Brasil)"},{"title":"AudioContext","locale":"ru","native":"Русский"},{"title":"AudioContext","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"en-us/web/api/audiocontext","github_url":"https://github.com/mdn/content/blob/style/old/files/en-us/web/api/audiocontext/index.md","last_commit_url":"https://github.com/mdn/content/commit/bf30e32f3b51f59080f2c76795beadb247a551eb","filename":"index.md"},"parents":[{"uri":"/en-US/docs/Web","title":"Web technology for developers"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/AudioContext","title":"AudioContext"}],"pageTitle":"AudioContext - Web APIs | MDN","noIndexing":false}}