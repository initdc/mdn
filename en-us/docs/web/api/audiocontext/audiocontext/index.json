{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"AudioContext()","mdn_url":"/en-US/docs/Web/API/AudioContext/AudioContext","locale":"en-US","native":"English (US)","sidebarHTML":"<ol><li><strong><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></strong></li><li><strong><a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Constructor</summary><ol><li><em><code>AudioContext()</code></em></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Properties</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioContext/baseLatency\"><code>baseLatency</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/outputLatency\"><code>outputLatency</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Methods</summary><ol><li><a href=\"/en-US/docs/Web/API/AudioContext/close\"><code>close()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/createMediaElementSource\"><code>createMediaElementSource()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamDestination\"><code>createMediaStreamDestination()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamSource\"><code>createMediaStreamSource()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource\"><code>createMediaStreamTrackSource()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/getOutputTimestamp\"><code>getOutputTimestamp()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>resume()</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext/suspend\"><code>suspend()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Inheritance:</summary><ol><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/EventTarget\"><code>EventTarget</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Web Audio API</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>\n  The <strong><code>AudioContext()</code></strong> constructor\n  creates a new <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> object which represents an audio-processing\n  graph, built from audio modules linked together, each represented by an\n  <a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a>.\n</p>"}},{"type":"prose","value":{"id":"syntax","title":"Syntax","isH3":false,"content":"<div class=\"code-example\"><pre class=\"brush: js-nolint notranslate\">new AudioContext()\nnew AudioContext(options)\n</pre></div>"}},{"type":"prose","value":{"id":"parameters","title":"Parameters","isH3":true,"content":"<dl>\n  <dt id=\"options\"><code>options</code> <span class=\"badge inline optional\">Optional</span></dt>\n  <dd>\n    <p>An object used to configure the context. The available properties are:</p>\n    <dl>\n      <dt id=\"latencyhint\"><code>latencyHint</code> <span class=\"badge inline optional\">Optional</span></dt>\n      <dd>\n        <p>\n          The type of playback that the context will be used for, as a predefined string (<code>\"balanced\"</code>, <code>\"interactive\"</code> or <code>\"playback\"</code>)\n          or a double-precision floating-point value indicating the preferred maximum latency of the context in seconds.\n          The user agent may or may not choose to meet this request;\n          check the value of <a href=\"/en-US/docs/Web/API/AudioContext/baseLatency\"><code>AudioContext.baseLatency</code></a> to determine the true latency after creating the context.\n        </p>\n        <ul>\n          <li><code>\"balanced\"</code>: The browser balances audio output latency and power consumption when selecting a latency value.</li>\n          <li>\n            <code>\"interactive\"</code> (default value): The audio is involved in interactive elements,\n            such as responding to user actions or needing to coincide with visual cues such as a video or game action.\n            The browser selects the lowest possible latency that doesn't cause glitches in the audio. This is likely to require increased power consumption.\n          </li>\n          <li>\n            <code>\"playback\"</code>: The browser selects a latency that will maximize playback time by minimizing power consumption at the expense of latency.\n            Useful for non-interactive playback, such as playing music.\n          </li>\n        </ul>\n      </dd>\n      <dt id=\"samplerate\"><code>sampleRate</code> <span class=\"badge inline optional\">Optional</span></dt>\n      <dd>\n        <p>\n          Indicates the sample rate to use for the new context. The value must be a floating-point value indicating the sample rate,\n          in samples per second, for which to configure the new context;\n          additionally, the value must be one which is supported by <a href=\"/en-US/docs/Web/API/AudioBuffer/sampleRate\"><code>AudioBuffer.sampleRate</code></a>.\n          The value will typically be between 8,000 Hz and 96,000 Hz; the default will vary depending on the output device, but the sample rate 44,100 Hz is the most common.\n          If the <code>sampleRate</code> property is not included in the options, or the options are not specified when creating the audio context,\n          the new context's output device's preferred sample rate is used by default.\n        </p>\n      </dd>\n    </dl>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"return_value","title":"Return value","isH3":true,"content":"<p>A new <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> instance.</p>"}},{"type":"prose","value":{"id":"exceptions","title":"Exceptions","isH3":true,"content":"<dl>\n  <dt id=\"notsupportederror\"><code>NotSupportedError</code> <a href=\"/en-US/docs/Web/API/DOMException\"><code>DOMException</code></a></dt>\n  <dd>\n    <p>Thrown if the specified <code>sampleRate</code> isn't supported by the context.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"usage_notes","title":"Usage notes","isH3":false,"content":"<p>\n  The specification doesn't go into a lot of detail about things like how many audio\n  contexts a user agent should support, or minimum or maximum latency requirements (if\n  any), so these details can vary from browser to browser. Be sure to check the values if\n  they matter to you.\n</p>\n<p>\n  In particular, the specification doesn't indicate a maximum or minimum number of audio\n  contexts that must be able to be open at the same time, so this is left up to the\n  browser implementations to decide.\n</p>"}},{"type":"prose","value":{"id":"google_chrome","title":"Google Chrome","isH3":true,"content":"<h4 id=\"per-tab_audio_context_limitation_in_chrome\">Per-tab audio context limitation in Chrome</h4>\n<p>Prior to version 66 Google Chrome only supported up to six audio contexts <em>per\ntab</em> at a time.</p>\n<h4 id=\"non-standard_exceptions_in_chrome\">Non-standard exceptions in Chrome</h4>\n<p>\n  If the value of the <code>latencyHint</code> property isn't valid,\n  Chrome throws a <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypeError\"><code>TypeError</code></a> exception with the message\n  \"The provided value '...' is not a valid enum value of type\n  AudioContextLatencyCategory\".\n</p>"}},{"type":"prose","value":{"id":"example","title":"Example","isH3":false,"content":"<p>\n  This example creates a new <a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a> for interactive audio\n  (optimizing for latency) and a sample rate of 44.1kHz.\n</p>\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">const</span> audioCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n  <span class=\"token literal-property property\">latencyHint</span><span class=\"token operator\">:</span> <span class=\"token string\">\"interactive\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token literal-property property\">sampleRate</span><span class=\"token operator\">:</span> <span class=\"token number\">44100</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre></div>"}},{"type":"specifications","value":{"title":"Specifications","id":"specifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#dom-audiocontext-audiocontext","title":"Web Audio API"}],"query":"api.AudioContext.AudioContext"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.AudioContext.AudioContext","dataURL":"/en-US/docs/Web/API/AudioContext/AudioContext/bcd.json"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/OfflineAudioContext\" title=\"new OfflineAudioContext()\"><code>new OfflineAudioContext()</code></a> constructor</li>\n</ul>"}}],"toc":[{"text":"Syntax","id":"syntax"},{"text":"Usage notes","id":"usage_notes"},{"text":"Example","id":"example"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"The AudioContext() constructor\n  creates a new AudioContext object which represents an audio-processing\n  graph, built from audio modules linked together, each represented by an\n  AudioNode.","popularity":0.001,"modified":"2022-09-14T13:55:15.000Z","other_translations":[{"title":"AudioContext()","locale":"ja","native":"日本語"},{"title":"AudioContext()","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"en-us/web/api/audiocontext/audiocontext","github_url":"https://github.com/mdn/content/blob/style/old/files/en-us/web/api/audiocontext/audiocontext/index.md","last_commit_url":"https://github.com/mdn/content/commit/02e1bfcad5fd0de845fb033d331c3c027afa2d6e","filename":"index.md"},"parents":[{"uri":"/en-US/docs/Web","title":"Web technology for developers"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/AudioContext","title":"AudioContext"},{"uri":"/en-US/docs/Web/API/AudioContext/AudioContext","title":"AudioContext()"}],"pageTitle":"AudioContext() - Web APIs | MDN","noIndexing":false}}