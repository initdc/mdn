{"doc":{"isMarkdown":true,"isTranslated":true,"isActive":true,"flaws":{},"title":"Web Audio API","mdn_url":"/ja/docs/Web/API/Web_Audio_API","locale":"ja","native":"日本語","sidebarHTML":"<ol><li><strong><a href=\"/ja/docs/Web/API/Web_Audio_API\">Web Audio API</a></strong></li><li class=\"toggle\"><details open=\"\"><summary>ガイド</summary><ol><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Using the Web Audio API</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API\">Basic concepts behind Web Audio API</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Best_practices\">Web Audio API best practices</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Advanced_techniques\">Advanced techniques: Creating and sequencing audio</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Using_AudioWorklet\">Background audio processing using AudioWorklet</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Controlling_multiple_parameters_with_ConstantSourceNode\">Controlling multiple parameters with ConstantSourceNode</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Migrating_from_webkitAudioContext\">Migrating from webkitAudioContext</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Simple_synth\">Example and tutorial: Simple synth keyboard</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Tools\">Tools for analyzing Web Audio usage</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Using_IIR_filters\">Using IIR filters</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\">Visualizations with Web Audio API</a></li><li><a href=\"/ja/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics\">Web audio spatialization basics</a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>インターフェイス</summary><ol><li><a href=\"/ja/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/ja/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/ja/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/ja/docs/Web/API/AudioContext\"><code>AudioContext</code></a></li><li><a href=\"/ja/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/ja/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/ja/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/ja/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a></li><li><a href=\"/ja/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/ja/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/ja/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code></a></li><li><a href=\"/ja/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/ja/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/ja/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/ja/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/ja/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/ja/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/ja/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/ja/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/ja/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/ja/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/ja/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/ja/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/ja/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/ja/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/ja/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/ja/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/ja/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></li><li><a href=\"/ja/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/ja/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/ja/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/ja/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li><li><a href=\"/ja/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>Web Audio API はウェブ上で音声を扱うための強力で多機能なシステムを提供します。これにより開発者は音源を選択したり、エフェクトを加えたり、ビジュアライゼーションを加えたり、パンニングなどの特殊効果を適用したり、他にもたくさんのいろいろなことができるようになります。</p>"}},{"type":"prose","value":{"id":"web_audio_の概念と利用方法","title":"Web audio の概念と利用方法","isH3":false,"content":"<p>Web Audio API は音声操作を<strong>オーディオコンテキスト</strong>内の操作として実現し、モジュラールーティングできるようにデザインされています。基本的な操作は <strong>オーディオノード</strong>として表現されています。これを接続することで、オーディオグラフを作成します。チャンネル構成の異なる複数の音源も 1 つのコンテキスト内で扱えます。この構成によって、複雑で動的な音声操作を実現できるようになっています。</p>\n<p>オーディオノードは、入力と出力によってチェーンと単純なウェブにリンクされています。通常、1 つまたは複数の音源から始まります。音源は、非常に小さなタイムスライス、多くの場合は 1 秒間に数万個のサウンドインテンシティ (サンプル) の配列を提供します。これらは数学的に計算されたもの (<a href=\"/ja/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a> など) や、音声ファイルや動画ファイル (<a href=\"/ja/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a> や <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code> <small>(en-US)</small></a> など) やオーディオストリーム (<a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code> <small>(en-US)</small></a>) からの録音である場合もあります。実際には、サウンドファイルは、マイクや電気楽器から入ってきた音の強さそのものを録音したものであり、それがミックスされて一つの複雑な波になっています。</p>\n<p>ノードの出力は他のノードの入力に紐付けられます。つまり、入力ストリームにミックスや編集をして他へ出力できるわけです。一般的な編集の例としては音量の変更です( <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code> <small>(en-US)</small></a> )。意図した効果を十分に施したあと、ユーザーに音声を聞かせたい場合、サウンドをスピーカーやヘッドオンに流すために、<a href=\"/ja/docs/Web/API/BaseAudioContext/destination\"><code>AudioContext.destination</code></a> の入力に紐付ける必要があります。</p>\n<p>簡潔で通常の Web Audio の使い方は次のようになります:</p>\n<ol>\n  <li>オーディオコンテキストを作成する</li>\n  <li>コンテキストの中で、<code>&lt;audio&gt;</code>,オシレーター,ストリームなどの音源を作成する</li>\n  <li>リバーブ・フィルター・パンナー・コンプレッサーなどのエフェクトノードを作成する</li>\n  <li>最終的な音声の到達先を選ぶ(例えばスピーカー)</li>\n  <li>音源をエフェクトに繋げ、エフェクトを到達先(destination)に繋げる</li>\n</ol>\n<p>\n  <img src=\"/en-US/docs/Web/API/Web_Audio_API/audio-context_.png\" alt=\"オーディオコンテキストと書かれた外側のボックスと、音源、エフェクト、デスティネーションと書かれた3つのボックスからなるシンプルなボックスダイアグラムです。3つのボックスの間には矢印があり、オーディオ情報の流れを示しています。\" width=\"1200\" height=\"400\" loading=\"lazy\">\n</p>\n<p>タイミングは高精度で低遅延に制御されます。正確にイベントに反応したり特定の音声サンプルにアクセスしたりすることができます。ドラムマシンやシーケンサーのようなアプリケーションを作ることができます。</p>\n<p>Web Audio API では、立体音響を制御することもできます。<em>ソースリスナーモデル</em>に基づいたシステムを使用することで、<em>パンモデル</em>を制御し、音源の移動 (またはリスナーの移動) によって引き起こされる<em>距離に起因する減衰</em>を処理することができます。</p>\n<div class=\"notecard note\" id=\"sect1\">\n  <p><strong>Note:</strong> Web Audio API の理論に関する詳細は <a href=\"/ja/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API\">Basic concepts behind Web Audio API</a> をご覧ください。</p>\n</div>"}},{"type":"prose","value":{"id":"web_audio_api_がターゲットとする人","title":"Web Audio API がターゲットとする人","isH3":false,"content":"<p>Web Audio API は音声技術に馴染みがない人にとって、怖気づくかもしれません。また、多くの機能があるため、開発者にとってとっつきにくいものになっています。</p>\n<p>Web Audio API の用途としては、<a href=\"https://www.futurelibrary.no/\" class=\"external\" rel=\" noopener\">futurelibrary.no</a> のような雰囲気作りのためや<a href=\"https://css-tricks.com/form-validation-web-audio/\" class=\"external\" rel=\" noopener\">フォームの検証に音を活用</a>するために、単に音声をウェブサイトに組み込むために使用できます。一方で、高度な対話型ツールの作成にも利用できます。こうしたことを踏まえると、開発者とミュージシャンの双方に適していると言えます。</p>\n<p>プログラミングは得意だけど API の構造と用語の解説が必要な人のために、<a href=\"/ja/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">簡単なチュートリアル</a>があります。</p>\n<p>また、<a href=\"/ja/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API\">Web Audio API の背景にある基本理念</a>に関する記事もあり、特にこの API の範囲でデジタルオーディオがどのように動作するのかを理解するのに役立ちます。また API の基礎となる優れた概念の紹介も含んでいます。</p>\n<p>プログラムを書く作業はカードゲームに例えられます。ルールを学んで遊んでみて、またルールを学んで再び遊んでみて・・・。したがって最初のチュートリアルと記事を見たあとにピンとこなかった場合、最初のチュートリアルを拡張して、学んだことを実践して、段階的に高度なことを学んでいく<a href=\"/en-US/docs/Web/API/Web_Audio_API/Advanced_techniques\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">発展的なチュートリアル (en-US)</a>があります。</p>\n<p>それとは別に、この API のすべての機能を網羅したチュートリアルとリファレンスを用意しています。このページのサイドバーを参照してください。</p>\n<p>音楽的な側面に精通し、音楽理論の概念に精通し、楽器の構築を開始したい場合は、発展的チュートリアルやその他の解説を基に制作に移る事ができるでしょう(上記のリンク付きチュートリアルでは、スケジューリングに関する注意事項、オーダーメイドの発振器やエンベロープの作成、LFO などについて説明しています) 。</p>\n<p>プログラミングの基本に慣れていない場合は、まず初級者向けの JavaScript チュートリアルを参照してから、このページに戻ってください。<a href=\"/ja/docs/Learn/JavaScript\">初級者向けの JavaScript 学習モジュール</a>を参照してください。</p>"}},{"type":"prose","value":{"id":"web_audio_api_インターフェイス","title":"Web Audio API インターフェイス","isH3":false,"content":"<p>Web Audio API は全部で 28 のインターフェイスと関連するイベントを持ちます。それらは機能的に 9 個のカテゴリに分けられます。</p>"}},{"type":"prose","value":{"id":"一般的なオーディオグラフの定義","title":"一般的なオーディオグラフの定義","isH3":true,"content":"<p>Web Audio API で利用するオーディオグラフのコンテナと、その構成要素は以下の通りです。</p>\n<dl>\n  <dt id=\"audiocontext\"><a href=\"/ja/docs/Web/API/AudioContext\"><code>AudioContext</code></a></dt>\n  <dd>\n    <p>音声モジュールを組み合わせて作成される、音声処理のグラフを表します。グラフ内の各モジュールは <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> として表現されています。オーディオコンテキストは、コンテキスト内での処理を担当するノードの作成を行います。</p>\n  </dd>\n  <dt id=\"audiocontextoptions_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/AudioContext\"><code>AudioContextOptions</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><strong><code>AudioContextOptions</code></strong> は <code>AudioContext</code> を作成するときにオプションを渡したいときに使用します。</p>\n  </dd>\n  <dt id=\"audionode\"><a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a></dt>\n  <dd>\n    <p><strong><code>AudioNode</code></strong> インターフェイスは音声処理のモジュールの表現しています。これには<a href=\"/ja/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a>要素や<a href=\"/ja/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a> 要素のような音源、音声の出力先、<a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code> <small>(en-US)</small></a> や <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code> <small>(en-US)</small></a>) のようなフィルターなどが含まれます。</p>\n  </dd>\n  <dt id=\"audioparam\"><a href=\"/ja/docs/Web/API/AudioParam\"><code>AudioParam</code></a></dt>\n  <dd>\n    <p><strong><code>AudioParam</code></strong> インターフェイスは <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の持つような、音声に関するパラメータを表現しています。値をセットするだけでなく、差分を指定することも可能です。また指定した時間やパターンで、値を変更をすることもできます。</p>\n  </dd>\n  <dt id=\"audioparammap_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioParamMap\"><code>AudioParamMap</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><a href=\"/ja/docs/Web/API/AudioParam\"><code>AudioParam</code></a> のマップのようなインターフェイスを提供します。つまり <code>forEach()</code>、<code>get()</code>、<code>has()</code>、<code>keys()</code>、<code>values()</code> メソッドや <code>size</code> プロパティが使えます。</p>\n  </dd>\n  <dt id=\"baseaudiocontext\"><a href=\"/ja/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></dt>\n  <dd>\n    <p><strong><code>BaseAudioContext</code></strong> インターフェイスはオンライン音声処理グラフ( <a href=\"/ja/docs/Web/API/AudioContext\"><code>AudioContext</code></a>)やオフライン音声処理グラフ( <a href=\"/ja/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a>)の基底となるものです。直接 <code>BaseAudioContext</code> を使うことはなく、これを継承するこれら 2 つのインターフェイスを介して使用します。</p>\n  </dd>\n  <dt id=\"ended\"><code><a href=\"/en-US/docs/Web/API/HTMLMediaElement/ended_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">ended (en-US)</a></code> (event)</dt>\n  <dd>\n    <p><code>ended</code> イベントは、再生が終了した際に発火するイベントです。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"音源の定義","title":"音源の定義","isH3":true,"content":"<p>Web Audio API 内で利用できる音源は以下の通りです。</p>\n<dl>\n  <dt id=\"audioscheduledsourcenode\"><a href=\"/ja/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></dt>\n  <dd>\n    <p><strong><code>AudioScheduledSourceNode</code></strong> は <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、いくつかの音源ノードの親インターフェイスです。</p>\n  </dd>\n  <dt id=\"oscillatornode\"><a href=\"/ja/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></dt>\n  <dd>\n    <p><strong><code>OscillatorNode</code></strong> はサイン波を出力する <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> です。出力する波形の周波数を指定できます。</p>\n  </dd>\n  <dt id=\"audiobuffer\"><a href=\"/ja/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></dt>\n  <dd>\n    <p><strong><code>AudioBuffer</code></strong> はメモリー上に展開された短い音声データを表します。<a href=\"/ja/docs/Web/API/BaseAudioContext/createBuffer\"><code>AudioContext.createBuffer()</code></a> によって音声ファイルから、もしくは<a href=\"/ja/docs/Web/API/BaseAudioContext/createBuffer\"><code>AudioContext.createBuffer()</code></a> メソッドによって生データから作成されます。このデータは <a href=\"/ja/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a> を利用して再生されます。</p>\n  </dd>\n  <dt id=\"audiobuffersourcenode\"><a href=\"/ja/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></dt>\n  <dd>\n    <p><strong><code>AudioBufferSourceNode</code></strong> は <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、メモリー上の音声データを利用した音源です。音声データ自身は <a href=\"/ja/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> として保存されています。</p>\n  </dd>\n  <dt id=\"mediaelementaudiosourcenode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><strong><code>MediaElementAudioSourceNode</code></strong> は <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、<a href=\"/ja/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a> 要素や <a href=\"/ja/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a> 要素を利用する音源です。</p>\n  </dd>\n  <dt id=\"mediastreamaudiosourcenode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><strong><code>MediaStreamAudioSourceNode</code></strong> は <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、マイクや Web カメラといった <a href=\"/en-US/docs/Web/API/WebRTC_API\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">WebRTC (en-US)</a> <a href=\"/ja/docs/Web/API/MediaStream\"><code>MediaStream</code></a> からの入力を扱える音源です。複数の音声トラックがストリーム上にある場合、<a href=\"/ja/docs/Web/API/MediaStreamTrack/id\" title=\"id\"><code>id</code></a> は辞書順(アルファベット順)です。</p>\n  </dd>\n  <dt id=\"mediastreamtrackaudiosourcenode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamTrackAudioSourceNode\"><code>MediaStreamTrackAudioSourceNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><code>MediaStreamTrackAudioSourceNode</code> は<a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、<a href=\"/ja/docs/Web/API/MediaStreamTrack\"><code>MediaStreamTrack</code></a> からの入力を扱える音源です。<a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource\"><code>createMediaStreamTrackSource()</code> <small>(en-US)</small></a> メソッドによって作られたノードの場合、使用するトラックを指定してください。<code>MediaStreamAudioSourceNode</code> 以上の制御を提供します。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"オーディオエフェクトフィルターの定義","title":"オーディオエフェクトフィルターの定義","isH3":true,"content":"<p>これらを利用すると、音源からの音声にエフェクトをかけられます。</p>\n<dl>\n  <dt id=\"biquadfilternode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><strong><code>BiquadFilterNode</code></strong> は <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、単純な低次フィルターです。フィルターやトーンコントロール、グラフィックイコライザで利用されます。<code>BiquadFilterNode</code> の入力と出力はともに 1 つです。</p>\n  </dd>\n  <dt id=\"convolvernode\"><a href=\"/ja/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></dt>\n  <dd>\n    <p><strong><code>ConvolverNode</code></strong> は<a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、Audiobuffer に対して線形畳み込みを行います。リバーブの実現に利用されます。</p>\n  </dd>\n  <dt id=\"delaynode\"><a href=\"/ja/docs/Web/API/DelayNode\"><code>DelayNode</code></a></dt>\n  <dd>\n    <p><strong><code>DelayNode</code></strong> は <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、<a href=\"http://en.wikipedia.org/wiki/Digital_delay_line\" class=\"external\" rel=\" noopener\">delay-line</a> を表します。入力された音声を、遅らせて出力します。</p>\n  </dd>\n  <dt id=\"dynamicscompressornode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><strong><code>DynamicsCompressorNode</code></strong> はコンプレッサとして働きます。大きな音の音量を絞ることで、複数の音を同時に再生した時に起きがちな、音のクリッピングや歪みを回避します。</p>\n  </dd>\n  <dt id=\"gainnode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><strong><code>GainNode</code></strong> は <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、入力された音の音量を指定されたものに変更して出力します。</p>\n  </dd>\n  <dt id=\"waveshapernode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><strong><code>WaveShaperNode</code></strong> は <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、非線形のディストーションエフェクトを実現します。curve 属性に指定された関数を用いて、入力を歪ませます。音を歪ませ、温かみを与えるために用いられます。</p>\n  </dd>\n  <dt id=\"periodicwave_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><a href=\"/ja/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a> の出力の波形を変えるために用いられます。</p>\n  </dd>\n  <dt id=\"iirfilternode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>一般的な<a href=\"https://ja.wikipedia.org/wiki/%E7%84%A1%E9%99%90%E3%82%A4%E3%83%B3%E3%83%91%E3%83%AB%E3%82%B9%E5%BF%9C%E7%AD%94\" class=\"external\" rel=\" noopener\">無限インパルス応答(IIR)</a>フィルターの実装です。トーン制御デバイスやグラフィックイコライザーの実装に利用できます。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"音声の出力先の定義","title":"音声の出力先の定義","isH3":true,"content":"<p>処理した音声の出力先を、以下のもので定めます。</p>\n<dl>\n  <dt id=\"audiodestinationnode\"><a href=\"/ja/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></dt>\n  <dd>\n    <p><strong><code>AudioDestinationNode</code></strong> はコンテキスト内での出力先を表します。通常はスピーカとなっています。</p>\n  </dd>\n  <dt id=\"mediastreamaudiodestinationnode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><strong><code>MediaElementAudioSourceNode</code></strong> は音声の出力先となる <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、<a href=\"/en-US/docs/Web/API/WebRTC_API\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">WebRTC (en-US)</a> <a href=\"/ja/docs/Web/API/MediaStream\"><code>MediaStream</code></a> と 1 つの <code>AudioMediaStreamTrack</code> から構成されます。<a href=\"/ja/docs/Web/API/Navigator/getUserMedia\"><code>Navigator.getUserMedia</code></a> で取得された MediaStream と同様に扱えます。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"分析と可視化","title":"分析と可視化","isH3":true,"content":"<p>音声の時間領域 / 周波数領域分析には、<code>AnalyserNode</code> を利用します。</p>\n<dl>\n  <dt id=\"analysernode\"><a href=\"/ja/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></dt>\n  <dd>\n    <p><strong><code>AnalyserNode</code></strong> を利用すると、音声のリアルタイムに時間領域分析と周波数領域分析が行えます。これを利用すると、音声の可視化が行えます。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"オーディオチャンネルの分岐と合成","title":"オーディオチャンネルの分岐と合成","isH3":true,"content":"<p>オーディオチャンネルを分岐したり合成したりするのにこれらのインターフェイスを使います。</p>\n<dl>\n  <dt id=\"channelsplitternode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>The <strong><code>ChannelSplitterNode</code></strong> は音源の複数のチャンネルを別々のモノラル出力へ分離します。</p>\n  </dd>\n  <dt id=\"channelmergernode\"><a href=\"/ja/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></dt>\n  <dd>\n    <p><strong><code>ChannelMergerNode</code></strong> は異なるモノラルの入力を、1 つの出力へとまとめます。それぞれの入力は、出力内のチャンネルとなります。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"立体音響","title":"立体音響","isH3":true,"content":"<p>これらのインターフェイスを使用すると、立体音響のパンニング効果を音源に追加することができます。</p>\n<dl>\n  <dt id=\"audiolistener\"><a href=\"/ja/docs/Web/API/AudioListener\"><code>AudioListener</code></a></dt>\n  <dd>\n    <p><strong><code>AudioListener</code></strong> インターフェイスは聴者の向きと位置を表します。</p>\n  </dd>\n  <dt id=\"pannernode\"><a href=\"/ja/docs/Web/API/PannerNode\"><code>PannerNode</code></a></dt>\n  <dd>\n    <p><strong><code>PannerNode</code></strong> は <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、空間内での音の振る舞いを規定します。位置はカルテシアンの右手座標系で表され、速度ベクトルで動きを表します。向きはコーンの向きで表現します。</p>\n  </dd>\n  <dt id=\"stereopannernode\"><a href=\"/ja/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></dt>\n  <dd>\n    <p><strong><code>StereoPannerNode</code></strong> インターフェイスは単純なステレオプランナーで、音声ストリームのパン(左右バランス)を調整できます。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"javascript_による音声処理","title":"JavaScript による音声処理","isH3":true,"content":"<p>音声 Worklet を使うことで、JavaScript や <a href=\"/ja/docs/WebAssembly\">WebAssembly</a> を使って自作の<a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a>を定義できます。音声 Worklet は <a href=\"/ja/docs/Web/API/Worklet\"><code>Worklet</code></a> インターフェイスという軽量版 <a href=\"/ja/docs/Web/API/Worker\"><code>Worker</code></a> インターフェイスを実装しています。Chrome 66 以降で既定で有効です。</p>\n<dl>\n  <dt id=\"audioworklet_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code> <small>(en-US)</small></a> <svg class=\"icon icon-experimental\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-experimental\"></use>\n</svg></dt>\n  <dd>\n    <p><code>AudioWorklet</code> インターフェイスは <a href=\"/ja/docs/Web/API/AudioContext\"><code>AudioContext</code></a> オブジェクトの <a href=\"/ja/docs/Web/API/BaseAudioContext/audioWorklet\" title=\"audioWorklet\"><code>audioWorklet</code></a> を通して利用することができ、メインスレッドから実行されるオーディオワークレットにモジュールを追加することができます。</p>\n  </dd>\n  <dt id=\"audioworkletnode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code> <small>(en-US)</small></a> <svg class=\"icon icon-experimental\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-experimental\"></use>\n</svg></dt>\n  <dd>\n    <p><code>AudioWorkletNode</code> インターフェイスは <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、音声グラフに組み込んだり、対応する <code>AudioWorkletProcessor</code> にメッセージを送信できます。</p>\n  </dd>\n  <dt id=\"audioworkletprocessor_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code> <small>(en-US)</small></a> <svg class=\"icon icon-experimental\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-experimental\"></use>\n</svg></dt>\n  <dd>\n    <p><code>AudioWorkletProcessor</code> インターフェイスは <code>AudioWorkletGlobalScope</code> で実行する音声処理コードで、音声の生成・処理・分析を直接行ったり、対応する <code>AudioWorkletNode</code> にメッセージを送信できます。</p>\n  </dd>\n  <dt id=\"audioworkletglobalscope_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code> <small>(en-US)</small></a> <svg class=\"icon icon-experimental\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-experimental\"></use>\n</svg></dt>\n  <dd>\n    <p><code>AudioWorkletGlobalScope</code> インターフェイスは <code>WorkletGlobalScope</code> から派生するオブジェクトで、音声処理スクリプトが実行されるワーカーコンテキストを表現します。メインスレッド上ではなく、ワークレットスレッド上で JavaScript を使って直接オーディオデータの生成、処理、分析ができるように設計されています。</p>\n  </dd>\n</dl>\n<h4 id=\"obsolete_script_processor_nodes\">Obsolete: script processor nodes</h4>\n<p>音声 Worklet が定義されるよりも昔、Web Audio API は JavaScript を使用する音声処理に <code>ScriptProcessorNode</code> を利用していました。しかしながら処理がメインスレッドで走るためにパフォーマンスが良くありませんでした。歴史的な理由から <code>ScriptProcessorNode</code> は維持されていますが非推奨であり、将来の規格から取り除かれる予定です。</p>\n<dl>\n  <dt id=\"scriptprocessornode\"><a href=\"/ja/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code></a> <svg class=\"icon icon-deprecated\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-deprecated\"></use>\n</svg></dt>\n  <dd>\n    <p><strong><code>ScriptProcessorNode</code></strong> を利用すると、JavaScript から音声データの生成、処理、分析を行えます。このノードは <a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> の一種で、入力と出力の二つのバッファとリンクしています。入力バッファに新しいデータがセットされる度に <a href=\"/ja/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a> インターフェイスを実装したイベントが生起します。イベントハンドラは出力バッファにデータをセットして処理を終了します。</p>\n  </dd>\n  <dt id=\"audioprocess\"><code><a href=\"/en-US/docs/Web/API/ScriptProcessorNode/audioprocess_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">audioprocess (en-US)</a></code> (event) <svg class=\"icon icon-deprecated\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-deprecated\"></use>\n</svg></dt>\n  <dd>\n    <p><code>audioprocess</code> イベントは <a href=\"/ja/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code></a> の処理が可能になった際に発火します。</p>\n  </dd>\n  <dt id=\"audioprocessingevent\"><a href=\"/ja/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a> <svg class=\"icon icon-deprecated\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-deprecated\"></use>\n</svg></dt>\n  <dd>\n    <p><code>AudioProcessingEvent</code> は <a href=\"/ja/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code></a> の入力バッファが処理可能になったことを表すイベントです。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"オフライン_バックグラウンドでの処理","title":"オフライン / バックグラウンドでの処理","isH3":true,"content":"<p>以下のようにすると、バックグラウンドでオーディオグラフを非常に高速に処理/レンダリングし、端末のスピーカーではなく <a href=\"/ja/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> にレンダリングすることができます。</p>\n<dl>\n  <dt id=\"offlineaudiocontext\"><a href=\"/ja/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></dt>\n  <dd>\n    <p><strong><code>OfflineAudioContext</code></strong> は <a href=\"/ja/docs/Web/API/AudioContext\"><code>AudioContext</code></a> の一種で、<a href=\"/ja/docs/Web/API/AudioNode\"><code>AudioNode</code></a> を組み合わせて、音声処理を行うグラフを表現しています。通常の <code>AudioContext</code>と異なり<code>、</code>OfflineAudioContext` は音声を出力せず、バッファ内で高速に処理を行います。</p>\n  </dd>\n  <dt id=\"complete\"><code><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">complete (en-US)</a></code> (event)</dt>\n  <dd>\n    <p><code>complete</code> イベントは <a href=\"/ja/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a> の処理が終了した時に発火します。</p>\n  </dd>\n  <dt id=\"offlineaudiocompletionevent_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p><code>OfflineAudioCompletionEvent</code> は <a href=\"/ja/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a> の処理が終了したことを表します。<code><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">complete (en-US)</a></code> イベントは、これを実装しています。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"廃止されたインターフェイス","title":"廃止されたインターフェイス","isH3":false,"content":"<p>以下のものは、Web Audio API の古い仕様には存在しましたが、現在は廃止され、別のものに置き換えられています。</p>\n<dl>\n  <dt id=\"javascriptnode\"><a class=\"page-not-created\" title=\"この項目についての文書はまだ書かれていません。書いてみませんか？\"><code>JavaScriptNode</code></a></dt>\n  <dd>\n    <p>JavaScript で音声を直接処理できます。廃止され、<a href=\"/ja/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code></a> に置き換えられています。</p>\n  </dd>\n  <dt id=\"wavetablenode\"><a class=\"page-not-created\" title=\"この項目についての文書はまだ書かれていません。書いてみませんか？\"><code>WaveTableNode</code></a></dt>\n  <dd>\n    <p>定期的な波形変換を行います。廃止され <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code> <small>(en-US)</small></a> に置き換えられています。</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"ガイドとチュートリアル","title":"ガイドとチュートリアル","isH3":false,"content":"<div class=\"row topicpage-table\" id=\"sect2\">\n    <div class=\"section\" id=\"sect3\"><dl><dl><dt class=\"landingPageList\" id=\"basic_concepts_behind_web_audio_api\"><a href=\"/ja/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API\">Basic concepts behind Web Audio API</a></dt><dd class=\"landingPageList\">この記事では、アプリを経由した音声伝達方法の設計をする際に、十分な情報に基づいた決断をする助けとなるよう、 Web Audio API の特徴がいかに働いているか、その背後にある音声理論について説明します。この記事はあなたを熟練のサウンドエンジニアにさせることはできないものの、Web Audio API が動く理由を理解するための十分な背景を提供します。</dd><dt class=\"landingPageList\" id=\"visualizations_with_web_audio_api\"><a href=\"/ja/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\">Visualizations with Web Audio API</a></dt><dd class=\"landingPageList\">Web Audio API の最も興味深い機能の 1 つは、オーディオソースから周波数、波形、その他のデータを抽出し、それを使用してビジュアライゼーションを作成する機能です。この記事では、方法について説明し、いくつかの基本的な使用例を示します。</dd></dl></dl></div>\n    <div class=\"section\" id=\"sect4\"><dl><dt class=\"landingPageList\" id=\"web_audio_api_の使用\"><a href=\"/ja/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Web Audio API の使用</a></dt><dd class=\"landingPageList\"><a href=\"/ja/docs/Web/API/Web_Audio_API\" aria-current=\"page\">Web Audio API</a> の入門を見てみましょう。ここではいくつかの概念を短く確認してから、簡単な boombox の例で、音声トラックの読み込み、再生と一時停止、音量やステレオ位置の変更の方法を学びましょう。</dd></dl></div>\n    </div>"}},{"type":"prose","value":{"id":"例","title":"例","isH3":false,"content":"<p>GitHub の <a href=\"https://github.com/mdn/webaudio-examples/\" class=\"external\" rel=\" noopener\">webaudio-example</a> に多数の例が掲載されています。</p>"}},{"type":"prose","value":{"id":"仕様書","title":"仕様書","isH3":false,"content":"<table>\n  <thead>\n    <tr>\n      <th>仕様書</th>\n      <th>状態</th>\n      <th>備考</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><a href=\"https://www.w3.org/TR/webaudio/\" hreflang=\"en\" lang=\"en\" class=\"external\" title=\"Web Audio APIの仕様書\" rel=\" noopener\">Web Audio API</a></td>\n      <td><span class=\"spec-rec\">勧告</span></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>"}},{"type":"prose","value":{"id":"ブラウザーの互換性","title":"ブラウザーの互換性","isH3":false,"content":""}},{"type":"browser_compatibility","value":{"title":"AudioContext","id":"audiocontext_2","isH3":true,"query":"api.AudioContext","dataURL":"/ja/docs/Web/API/Web_Audio_API/bcd.json"}},{"type":"prose","value":{"id":"関連情報","title":"関連情報","isH3":false,"content":""}},{"type":"prose","value":{"id":"チュートリアルガイド","title":"チュートリアル/ガイド","isH3":true,"content":"<ul>\n  <li><a href=\"/ja/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API\">Web Audio API の背後にある基本概念</a></li>\n  <li><a href=\"/ja/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Web Audio API の使用</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Advanced_techniques\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Advanced techniques: creating sound, sequencing, timing, scheduling (en-US)</a></li>\n  <li><a href=\"/ja/docs/Web/Media/Autoplay_guide\">メディアおよびウェブオーディオ API の自動再生ガイド</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_IIR_filters\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Using IIR filters (en-US)</a></li>\n  <li><a href=\"/ja/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\">Web Audio API による視覚化</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Web audio spatialisation basics (en-US)</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Controlling_multiple_parameters_with_ConstantSourceNode\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Controlling multiple parameters with ConstantSourceNode (en-US)</a></li>\n  <li><a href=\"https://www.html5rocks.com/tutorials/webaudio/positional_audio/\" class=\"external\" rel=\" noopener\">Mixing Positional Audio and WebGL</a></li>\n  <li><a href=\"https://www.html5rocks.com/tutorials/webaudio/games/\" class=\"external\" rel=\" noopener\">Developing Game Audio with the Web Audio API</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Migrating_from_webkitAudioContext\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Porting webkitAudioContext code to standards based AudioContext (en-US)</a></li>\n</ul>"}},{"type":"prose","value":{"id":"ライブラリ","title":"ライブラリ","isH3":true,"content":"<ul>\n  <li><a href=\"https://github.com/bit101/tones\" class=\"external\" rel=\" noopener\">Tones</a>: a simple library for playing specific tones/notes using the Web Audio API.</li>\n  <li><a href=\"https://tonejs.github.io/\" class=\"external\" rel=\" noopener\">Tone.js</a>: a framework for creating interactive music in the browser.</li>\n  <li><a href=\"https://github.com/goldfire/howler.js/\" class=\"external\" rel=\" noopener\">howler.js</a>: a JS audio library that defaults to <a href=\"https://webaudio.github.io/web-audio-api/\" class=\"external\" rel=\" noopener\">Web Audio API</a> and falls back to <a href=\"https://www.whatwg.org/specs/web-apps/current-work/#the-audio-element\" class=\"external\" rel=\" noopener\">HTML5 Audio</a>, as well as providing other useful features.</li>\n  <li><a href=\"https://github.com/mattlima/mooog\" class=\"external\" rel=\" noopener\">Mooog</a>: jQuery-style chaining of AudioNodes, mixer-style sends/returns, and more.</li>\n  <li><a href=\"https://korilakkuma.github.io/XSound/\" class=\"external\" rel=\" noopener\">XSound</a>: Web Audio API Library for Synthesizer, Effects, Visualization, Recording ... etc</li>\n  <li><a href=\"https://github.com/chrisjohndigital/OpenLang\" class=\"external\" rel=\" noopener\">OpenLang</a>: HTML5 video language lab web application using the Web Audio API to record and combine video and audio from different sources into a single file (<a href=\"https://github.com/chrisjohndigital/OpenLang\" class=\"external\" rel=\" noopener\">source on GitHub</a>)</li>\n  <li><a href=\"https://ptsjs.org/\" class=\"external\" rel=\" noopener\">Pts.js</a>: Simplifies web audio visualization (<a href=\"https://ptsjs.org/guide/sound-0800\" class=\"external\" rel=\" noopener\">guide</a>)</li>\n</ul>"}},{"type":"prose","value":{"id":"関連トピック","title":"関連トピック","isH3":true,"content":"<ul>\n  <li><a href=\"/ja/docs/Web/Media\">Web media technologies</a></li>\n  <li><a href=\"/ja/docs/Web/Media/Formats\">Guide to media types and formats on the web</a></li>\n</ul>"}}],"toc":[{"text":"Web audio の概念と利用方法","id":"web_audio_の概念と利用方法"},{"text":"Web Audio API がターゲットとする人","id":"web_audio_api_がターゲットとする人"},{"text":"Web Audio API インターフェイス","id":"web_audio_api_インターフェイス"},{"text":"廃止されたインターフェイス","id":"廃止されたインターフェイス"},{"text":"ガイドとチュートリアル","id":"ガイドとチュートリアル"},{"text":"例","id":"例"},{"text":"仕様書","id":"仕様書"},{"text":"ブラウザーの互換性","id":"ブラウザーの互換性"},{"text":"関連情報","id":"関連情報"}],"summary":"Web Audio API はウェブ上で音声を扱うための強力で多機能なシステムを提供します。これにより開発者は音源を選択したり、エフェクトを加えたり、ビジュアライゼーションを加えたり、パンニングなどの特殊効果を適用したり、他にもたくさんのいろいろなことができるようになります。","popularity":0.0006,"modified":"2022-10-01T03:41:16.000Z","other_translations":[{"title":"Web Audio API","locale":"en-US","native":"English (US)"},{"title":"Web Audio API","locale":"es","native":"Español"},{"title":"Web Audio API","locale":"fr","native":"Français"},{"title":"Web Audio API","locale":"ko","native":"한국어"},{"title":"API Web Áudio","locale":"pt-BR","native":"Português (do Brasil)"},{"title":"Web Audio API","locale":"ru","native":"Русский"},{"title":"Web Audio API","locale":"zh-CN","native":"中文 (简体)"},{"title":"Web Audio API","locale":"zh-TW","native":"正體中文 (繁體)"}],"source":{"folder":"ja/web/api/web_audio_api","github_url":"https://github.com/mdn/translated-content/blob/main/files/ja/web/api/web_audio_api/index.md","last_commit_url":"https://github.com/mdn/translated-content/commit/921c46a374ab0a9f4cc809af0370f8c412e54701","filename":"index.md"},"parents":[{"uri":"/ja/docs/Web","title":"開発者向けのウェブ技術"},{"uri":"/ja/docs/Web/API","title":"Web API"},{"uri":"/ja/docs/Web/API/Web_Audio_API","title":"Web Audio API"}],"pageTitle":"Web Audio API - Web API | MDN","noIndexing":false}}