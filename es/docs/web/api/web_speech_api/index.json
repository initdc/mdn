{"doc":{"isMarkdown":false,"isTranslated":true,"isActive":true,"flaws":{},"title":"Web Speech API","mdn_url":"/es/docs/Web/API/Web_Speech_API","locale":"es","native":"Español","sidebarHTML":"<ol><li><strong><a href=\"/es/docs/Web/API/Web_Speech_API\">Web Speech API</a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Interfaces</summary><ol><li><a href=\"/es/docs/Web/API/SpeechGrammar\"><code>SpeechGrammar</code></a></li><li><a href=\"/es/docs/Web/API/SpeechGrammarList\"><code>SpeechGrammarList</code></a></li><li><a href=\"/es/docs/Web/API/SpeechRecognition\"><code>SpeechRecognition</code></a></li><li><a href=\"/es/docs/Web/API/SpeechRecognitionAlternative\"><code>SpeechRecognitionAlternative</code></a></li><li><a href=\"/es/docs/Web/API/SpeechRecognitionErrorEvent\"><code>SpeechRecognitionErrorEvent</code></a></li><li><a href=\"/es/docs/Web/API/SpeechRecognitionEvent\"><code>SpeechRecognitionEvent</code></a></li><li><a href=\"/es/docs/Web/API/SpeechRecognitionResult\"><code>SpeechRecognitionResult</code></a></li><li><a href=\"/es/docs/Web/API/SpeechRecognitionResultList\"><code>SpeechRecognitionResultList</code></a></li><li><a href=\"/es/docs/Web/API/SpeechSynthesis\"><code>SpeechSynthesis</code></a></li><li><a href=\"/es/docs/Web/API/SpeechSynthesisErrorEvent\"><code>SpeechSynthesisErrorEvent</code></a></li><li><a href=\"/es/docs/Web/API/SpeechSynthesisEvent\"><code>SpeechSynthesisEvent</code></a></li><li><a href=\"/es/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code></a></li><li><a href=\"/es/docs/Web/API/SpeechSynthesisVoice\"><code>SpeechSynthesisVoice</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<div id=\"sect1\"><div class=\"notecard experimental\" id=\"sect2\"><p><strong>Experimental:</strong> <strong>Esta es una <a href=\"/en-US/docs/MDN/Writing_guidelines/Experimental_deprecated_obsolete#experimental\">tecnología experimental</a></strong><br>Comprueba la <a href=\"#browser_compatibility\">Tabla de compabilidad de navegadores</a> cuidadosamente antes de usarla en producción.</p></div></div>\n\n<div class=\"summary\" id=\"sect3\">\n<p>The Web Speech API enables you to incorporate voice data into web apps. The Web Speech API has two parts: SpeechSynthesis (Text-to-Speech), and SpeechRecognition (Asynchronous Speech Recognition.)</p>\n</div>"}},{"type":"prose","value":{"id":"web_speech_concepts_and_usage","title":"Web Speech Concepts and Usage","isH3":false,"content":"<p>The Web Speech API makes web apps able to handle voice data. There are two components to this API:</p>\n\n<ul>\n <li>Speech recognition is accessed via the <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognition\"><code>SpeechRecognition</code> <small>(en-US)</small></a> interface, which provides the ability to recognize voice context from an audio input (normally via the device's default speech recognition service) and respond appropriately. Generally you'll use the interface's constructor to create a new <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognition\"><code>SpeechRecognition</code> <small>(en-US)</small></a> object, which has a number of event handlers available for detecting when speech is input through the device's microphone. The <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechGrammar\"><code>SpeechGrammar</code> <small>(en-US)</small></a> interface represents a container for a particular set of grammar that your app should recognise. Grammar is defined using <a href=\"https://www.w3.org/TR/jsgf/\" class=\"external\" rel=\" noopener\">JSpeech Grammar Format</a> (<strong>JSGF</strong>.)</li>\n <li>Speech synthesis is accessed via the <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesis\"><code>SpeechSynthesis</code> <small>(en-US)</small></a> interface, a text-to-speech component that allows programs to read out their text content (normally via the device's default speech synthesiser.) Different voice types are represented by <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisVoice\"><code>SpeechSynthesisVoice</code> <small>(en-US)</small></a> objects, and different parts of text that you want to be spoken are represented by <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code> <small>(en-US)</small></a> objects. You can get these spoken by passing them to the <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesis/speak\"><code>SpeechSynthesis.speak()</code> <small>(en-US)</small></a> method.</li>\n</ul>\n\n<p>For more details on using these features, see <a href=\"/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API\">Using the Web Speech API</a>.</p>"}},{"type":"prose","value":{"id":"web_speech_api_interfaces","title":"Web Speech API Interfaces","isH3":false,"content":""}},{"type":"prose","value":{"id":"speech_recognition","title":"Speech recognition","isH3":true,"content":"<dl>\n <dt id=\"speechrecognition_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognition\"><code>SpeechRecognition</code> <small>(en-US)</small></a></dt>\n <dd>The controller interface for the recognition service; this also handles the <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionEvent\"><code>SpeechRecognitionEvent</code> <small>(en-US)</small></a> sent from the recognition service.</dd>\n <dt id=\"speechrecognitionalternative_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionAlternative\"><code>SpeechRecognitionAlternative</code> <small>(en-US)</small></a></dt>\n <dd>Represents a single word that has been recognised by the speech recognition service.</dd>\n <dt id=\"speechrecognitionerror_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionErrorEvent\"><code>SpeechRecognitionError</code> <small>(en-US)</small></a></dt>\n <dd>Represents error messages from the recognition service.</dd>\n <dt id=\"speechrecognitionevent_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionEvent\"><code>SpeechRecognitionEvent</code> <small>(en-US)</small></a></dt>\n <dd>The event object for the <code><a href=\"/es/docs/Web/Reference/Events/result\" title=\"This is a link to an unwritten page\" class=\"page-not-created\">result</a></code> and <code><a href=\"/es/docs/Web/Reference/Events/nomatch\" title=\"This is a link to an unwritten page\" class=\"page-not-created\">nomatch</a></code> events, and contains all the data associated with an interim or final speech recognition result.</dd>\n <dt id=\"speechgrammar_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechGrammar\"><code>SpeechGrammar</code> <small>(en-US)</small></a></dt>\n <dd>The words or patterns of words that we want the recognition service to recognize.</dd>\n <dt id=\"speechgrammarlist_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechGrammarList\"><code>SpeechGrammarList</code> <small>(en-US)</small></a></dt>\n <dd>Represents a list of <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechGrammar\"><code>SpeechGrammar</code> <small>(en-US)</small></a> objects.</dd>\n <dt id=\"speechrecognitionresult_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionResult\"><code>SpeechRecognitionResult</code> <small>(en-US)</small></a></dt>\n <dd>Represents a single recognition match, which may contain multiple <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionAlternative\"><code>SpeechRecognitionAlternative</code> <small>(en-US)</small></a> objects.</dd>\n <dt id=\"speechrecognitionresultlist_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionResultList\"><code>SpeechRecognitionResultList</code> <small>(en-US)</small></a></dt>\n <dd>Represents a list of <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionResult\"><code>SpeechRecognitionResult</code> <small>(en-US)</small></a> objects, or a single one if results are being captured in <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognition/continuous\"><code>continuous</code> <small>(en-US)</small></a> mode.</dd>\n</dl>"}},{"type":"prose","value":{"id":"speech_synthesis","title":"Speech synthesis","isH3":true,"content":"<dl>\n <dt id=\"speechsynthesis_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesis\"><code>SpeechSynthesis</code> <small>(en-US)</small></a></dt>\n <dd>The controller interface for the speech service; this can be used to retrieve information about the synthesis voices available on the device, start and pause speech, and other commands besides.</dd>\n <dt id=\"speechsynthesiserrorevent_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisErrorEvent\"><code>SpeechSynthesisErrorEvent</code> <small>(en-US)</small></a></dt>\n <dd>Contains information about any errors that occur while processing <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code> <small>(en-US)</small></a> objects in the speech service.</dd>\n <dt id=\"speechsynthesisevent_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisEvent\"><code>SpeechSynthesisEvent</code> <small>(en-US)</small></a></dt>\n <dd>Contains information about the current state of <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code> <small>(en-US)</small></a> objects that have been processed in the speech service.</dd>\n <dt id=\"speechsynthesisutterance_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code> <small>(en-US)</small></a></dt>\n <dd>Represents a speech request. It contains the content the speech service should read and information about how to read it (e.g. language, pitch and volume.)</dd>\n</dl>\n\n<dl>\n <dt id=\"speechsynthesisvoice_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisVoice\"><code>SpeechSynthesisVoice</code> <small>(en-US)</small></a></dt>\n <dd>Represents a voice that the system supports. Every <code>SpeechSynthesisVoice</code> has its own relative speech service including information about language, name and URI.</dd>\n <dt id=\"window.speechsynthesis_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/Window/speechSynthesis\"><code>Window.speechSynthesis</code> <small>(en-US)</small></a></dt>\n <dd>Specced out as part of a <code>[NoInterfaceObject]</code> interface called <code>SpeechSynthesisGetter</code>, and Implemented by the <code>Window</code> object, the <code>speechSynthesis</code> property provides access to the <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesis\"><code>SpeechSynthesis</code> <small>(en-US)</small></a> controller, and therefore the entry point to speech synthesis functionality.</dd>\n</dl>"}},{"type":"prose","value":{"id":"examples","title":"Examples","isH3":false,"content":"<p>The <a href=\"https://github.com/mdn/web-speech-api/\" class=\"external\" rel=\" noopener\">Web Speech API repo</a> on GitHub contains demos to illustrate speech recognition and synthesis.</p>"}},{"type":"prose","value":{"id":"specifications","title":"Specifications","isH3":false,"content":"<table class=\"standard-table\">\n <tbody>\n  <tr>\n   <th scope=\"col\">Specification</th>\n   <th scope=\"col\">Status</th>\n   <th scope=\"col\">Comment</th>\n  </tr>\n  <tr>\n   <td><a href=\"https://wicg.github.io/speech-api/\" hreflang=\"en\" lang=\"en\" class=\"external\" title=\"La especificación 'Web Speech API'\" rel=\" noopener\">Web Speech API</a></td>\n   <td><span class=\"spec-draft\">Draft</span></td>\n   <td>Initial definition</td>\n  </tr>\n </tbody>\n</table>"}},{"type":"prose","value":{"id":"browser_compatibility","title":"Browser compatibility","isH3":false,"content":""}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<h3 id=\"speechrecognition\"><code>SpeechRecognition</code></h3>\n\n<div id=\"sect4\">\n\n\n<p></p><div class=\"bc-data\" id=\"bcd:api.SpeechRecognition\" data-depth=\"0\">\n  If you're able to see this, something went wrong on this page.\n</div><p></p>\n\n<h3 id=\"speechsynthesis\"><code>SpeechSynthesis</code></h3>\n\n\n\n<p></p><div class=\"bc-data\" id=\"bcd:api.SpeechSynthesis\" data-depth=\"0\">\n  If you're able to see this, something went wrong on this page.\n</div><p></p>\n\n\n\n<ul>\n <li><a href=\"/en-US/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API\">Using the Web Speech API</a></li>\n <li><a href=\"https://www.sitepoint.com/talking-web-pages-and-the-speech-synthesis-api/\" class=\"external\" rel=\" noopener\">SitePoint article</a></li>\n <li><a href=\"http://updates.html5rocks.com/2014/01/Web-apps-that-talk---Introduction-to-the-Speech-Synthesis-API\" class=\"external\" rel=\" noopener\">HTML5Rocks article</a></li>\n <li><a href=\"https://aurelio.audero.it/demo/speech-synthesis-api-demo.html\" class=\"external\" rel=\" noopener\">Demo</a> [aurelio.audero.it]</li>\n</ul>\n</div>"}}],"toc":[{"text":"Web Speech Concepts and Usage","id":"web_speech_concepts_and_usage"},{"text":"Web Speech API Interfaces","id":"web_speech_api_interfaces"},{"text":"Examples","id":"examples"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"\nThe Web Speech API enables you to incorporate voice data into web apps. The Web Speech API has two parts: SpeechSynthesis (Text-to-Speech), and SpeechRecognition (Asynchronous Speech Recognition.)\n","popularity":0.0002,"modified":"2022-10-01T03:41:16.000Z","other_translations":[{"title":"Web Speech API","locale":"en-US","native":"English (US)"},{"title":"L'API Web Speech","locale":"fr","native":"Français"},{"title":"Web Speech API","locale":"ja","native":"日本語"},{"title":"Web Speech API","locale":"ru","native":"Русский"},{"title":"Web Speech API","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"es/web/api/web_speech_api","github_url":"https://github.com/mdn/translated-content/blob/main/files/es/web/api/web_speech_api/index.html","last_commit_url":"https://github.com/mdn/translated-content/commit/921c46a374ab0a9f4cc809af0370f8c412e54701","filename":"index.html"},"parents":[{"uri":"/es/docs/Web","title":"Tecnología para desarrolladores web"},{"uri":"/es/docs/Web/API","title":"Referencia de la API Web"},{"uri":"/es/docs/Web/API/Web_Speech_API","title":"Web Speech API"}],"pageTitle":"Web Speech API - Referencia de la API Web | MDN","noIndexing":false}}