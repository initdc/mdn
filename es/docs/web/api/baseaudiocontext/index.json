{"doc":{"isMarkdown":false,"isTranslated":true,"isActive":true,"flaws":{},"title":"BaseAudioContext","mdn_url":"/es/docs/Web/API/BaseAudioContext","locale":"es","native":"Español","sidebarHTML":"","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>{APIRef(\"Web Audio API\")}}</p>\n\n\n<p>The <code>BaseAudioContext</code> interface acts as a base definition for online and offline audio-processing graphs, as represented by <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code> <small>(en-US)</small></a> and <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code> <small>(en-US)</small></a> resepectively. You wouldn't use <code>BaseAudioContext</code> directly — you'd use its features via one of these two inheriting interfaces.</p>\n\n<p>A <code>BaseAudioContext</code> can be a target of events, therefore it implements the <a href=\"/es/docs/Web/API/EventTarget\"><code>EventTarget</code></a> interface.</p>\n\n<p><svg viewBox=\"-1 -1 650 42\" preserveAspectRatio=\"xMinYMin meet\">\n  <a style=\"text-decoration: none;\" xlink:href=\"/es/docs/Web/API/EventTarget\">\n    <rect x=\"0\" y=\"0\" width=\"88\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"44\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      EventTarget\n    </text>\n  </a>\n  <line x1=\"88\" y1=\"14\" x2=\"118\" y2=\"14\" stroke=\"#D4DDE4\" \"=\"\"></line>\n  <polyline points=\"88,14 98,9 98,19 88,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" xlink:href=\"/es/docs/Web/API/BaseAudioContext\" aria-current=\"page\">\n    <rect x=\"118\" y=\"0\" width=\"128\" height=\"25\" fill=\"#F4F7F8\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"182\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      BaseAudioContext\n    </text>\n  </a></svg></p>"}},{"type":"prose","value":{"id":"properties","title":"Properties","isH3":false,"content":"<dl>\n <dt id=\"baseaudiocontext.baselatency\"><a class=\"page-not-created\" title=\"La documentación acerca de este tema no ha sido escrita todavía . ¡Por favor  considera contribuir !\"><code>BaseAudioContext.baseLatency</code></a> <span title=\"This value may not be changed.\" class=\"badge inline readonly\">Read only </span></dt>\n <dd>Returns a double epresents the number of seconds of processing latency incurred by the AudioContext passing the audio from the AudioDestinationNode to the audio subsystem. </dd>\n <dt id=\"baseaudiocontext.currenttime_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/currentTime\"><code>BaseAudioContext.currentTime</code> <small>(en-US)</small></a> <span title=\"This value may not be changed.\" class=\"badge inline readonly\">Read only </span></dt>\n <dd>Returns a double representing an ever-increasing hardware time in seconds used for scheduling. It starts at <code>0</code>.</dd>\n <dt id=\"baseaudiocontext.destination_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/destination\"><code>BaseAudioContext.destination</code> <small>(en-US)</small></a> <span title=\"This value may not be changed.\" class=\"badge inline readonly\">Read only </span></dt>\n <dd>Returns an <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code> <small>(en-US)</small></a> representing the final destination of all audio in the context. It can be thought of as the audio-rendering device.</dd>\n <dt id=\"baseaudiocontext.listener_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/listener\"><code>BaseAudioContext.listener</code> <small>(en-US)</small></a> <span title=\"This value may not be changed.\" class=\"badge inline readonly\">Read only </span></dt>\n <dd>Returns the <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code> <small>(en-US)</small></a> object, used for 3D spatialization.</dd>\n <dt id=\"baseaudiocontext.samplerate_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/sampleRate\"><code>BaseAudioContext.sampleRate</code> <small>(en-US)</small></a> <span title=\"This value may not be changed.\" class=\"badge inline readonly\">Read only </span></dt>\n <dd>Returns a float representing the sample rate (in samples per second) used by all nodes in this context. The sample-rate of an <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code> <small>(en-US)</small></a> cannot be changed.</dd>\n <dt id=\"baseaudiocontext.state_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/state\"><code>BaseAudioContext.state</code> <small>(en-US)</small></a> <span title=\"This value may not be changed.\" class=\"badge inline readonly\">Read only </span></dt>\n <dd>Returns the current state of the <code>AudioContext</code>.</dd>\n</dl>"}},{"type":"prose","value":{"id":"event_handlers","title":"Event handlers","isH3":true,"content":"<dl>\n <dt id=\"baseaudiocontext.onstatechange_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/statechange_event\"><code>BaseAudioContext.onstatechange</code> <small>(en-US)</small></a></dt>\n <dd>An event handler that runs when an event of type <code><a href=\"/en-US/docs/Web/API/RTCIceTransport/statechange_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">statechange (en-US)</a></code> has fired. This occurs when the <code>AudioContext</code>'s state changes, due to the calling of one of the state change methods (<a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/suspend\"><code>AudioContext.suspend</code> <small>(en-US)</small></a>, <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>AudioContext.resume</code> <small>(en-US)</small></a>, or <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/close\"><code>AudioContext.close</code> <small>(en-US)</small></a>).</dd>\n</dl>"}},{"type":"prose","value":{"id":"methods","title":"Methods","isH3":false,"content":"<p><em>Also implements methods from the interface </em><a href=\"/es/docs/Web/API/EventTarget\"><code>EventTarget</code></a>.</p>\n\n<dl>\n <dt id=\"baseaudiocontext.createbuffer_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createBuffer\"><code>BaseAudioContext.createBuffer()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a new, empty <a href=\"/es/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> object, which can then be populated by data and played via an <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code> <small>(en-US)</small></a>.</dd>\n <dt id=\"baseaudiocontext.createconstantsource_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createConstantSource\"><code>BaseAudioContext.createConstantSource()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code> <small>(en-US)</small></a> object, which is an audio source that continuously outputs a monaural (one-channel) sound signal whose samples all have the same value.</dd>\n <dt id=\"baseaudiocontext.createbuffersource_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createBufferSource\"><code>BaseAudioContext.createBufferSource()</code> <small>(en-US)</small></a></dt>\n <dd>Creates an <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code> <small>(en-US)</small></a>, which can be used to play and manipulate audio data contained within an <a href=\"/es/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> object. <a href=\"/es/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a>s are created using <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createBuffer\"><code>AudioContext.createBuffer</code> <small>(en-US)</small></a> or returned by <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/decodeAudioData\"><code>AudioContext.decodeAudioData</code> <small>(en-US)</small></a> when it successfully decodes an audio track.</dd>\n <dt id=\"baseaudiocontext.createscriptprocessor_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor\"><code>BaseAudioContext.createScriptProcessor()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code> <small>(en-US)</small></a>, which can be used for direct audio processing via JavaScript.</dd>\n <dt id=\"baseaudiocontext.createstereopanner_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createStereoPanner\"><code>BaseAudioContext.createStereoPanner()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code> <small>(en-US)</small></a>, which can be used to apply stereo panning to an audio source.</dd>\n <dt id=\"baseaudiocontext.createanalyser_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createAnalyser\"><code>BaseAudioContext.createAnalyser()</code> <small>(en-US)</small></a></dt>\n <dd>Creates an <a href=\"/es/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a>, which can be used to expose audio time and frequency data and for example to create data visualisations.</dd>\n <dt id=\"baseaudiocontext.createbiquadfilter\"><a href=\"/es/docs/Web/API/BaseAudioContext/createBiquadFilter\"><code>BaseAudioContext.createBiquadFilter()</code></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code> <small>(en-US)</small></a>, which represents a second order filter configurable as several different common filter types: high-pass, low-pass, band-pass, etc.</dd>\n <dt id=\"baseaudiocontext.createchannelmerger_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createChannelMerger\"><code>BaseAudioContext.createChannelMerger()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code> <small>(en-US)</small></a>, which is used to combine channels from multiple audio streams into a single audio stream.</dd>\n <dt id=\"baseaudiocontext.createchannelsplitter_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createChannelSplitter\"><code>BaseAudioContext.createChannelSplitter()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code> <small>(en-US)</small></a>, which is used to access the individual channels of an audio stream and process them separately.</dd>\n <dt id=\"baseaudiocontext.createconvolver_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createConvolver\"><code>BaseAudioContext.createConvolver()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code> <small>(en-US)</small></a>, which can be used to apply convolution effects to your audio graph, for example a reverberation effect.</dd>\n <dt id=\"baseaudiocontext.createdelay_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createDelay\"><code>BaseAudioContext.createDelay()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code> <small>(en-US)</small></a>, which is used to delay the incoming audio signal by a certain amount. This node is also useful to create feedback loops in a Web Audio API graph.</dd>\n <dt id=\"baseaudiocontext.createdynamicscompressor_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createDynamicsCompressor\"><code>BaseAudioContext.createDynamicsCompressor()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code> <small>(en-US)</small></a>, which can be used to apply acoustic compression to an audio signal.</dd>\n <dt id=\"baseaudiocontext.creategain_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createGain\"><code>BaseAudioContext.createGain()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code> <small>(en-US)</small></a>, which can be used to control the overall volume of the audio graph.</dd>\n <dt id=\"baseaudiocontext.createiirfilter_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createIIRFilter\"><code>BaseAudioContext.createIIRFilter()</code> <small>(en-US)</small></a></dt>\n <dd>Creates an <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code> <small>(en-US)</small></a>, which represents a second order filter configurable as several different common filter types.</dd>\n <dt id=\"baseaudiocontext.createoscillator_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createOscillator\"><code>BaseAudioContext.createOscillator()</code> <small>(en-US)</small></a></dt>\n <dd>Creates an <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code> <small>(en-US)</small></a>, a source representing a periodic waveform. It basically generates a tone.</dd>\n <dt id=\"baseaudiocontext.createpanner_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createPanner\"><code>BaseAudioContext.createPanner()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code> <small>(en-US)</small></a>, which is used to spatialise an incoming audio stream in 3D space.</dd>\n <dt id=\"baseaudiocontext.createperiodicwave_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createPeriodicWave\"><code>BaseAudioContext.createPeriodicWave()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code> <small>(en-US)</small></a>, used to define a periodic waveform that can be used to determine the output of an <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code> <small>(en-US)</small></a>.</dd>\n <dt id=\"baseaudiocontext.createwaveshaper_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createWaveShaper\"><code>BaseAudioContext.createWaveShaper()</code> <small>(en-US)</small></a></dt>\n <dd>Creates a <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code> <small>(en-US)</small></a>, which is used to implement non-linear distortion effects.</dd>\n <dt id=\"baseaudiocontext.decodeaudiodata_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/decodeAudioData\"><code>BaseAudioContext.decodeAudioData()</code> <small>(en-US)</small></a></dt>\n <dd>Asynchronously decodes audio file data contained in an <a class=\"page-not-created\" title=\"La documentación acerca de este tema no ha sido escrita todavía . ¡Por favor  considera contribuir !\"><code>ArrayBuffer</code></a>. In this case, the ArrayBuffer is usually loaded from an <a href=\"/es/docs/Web/API/XMLHttpRequest\"><code>XMLHttpRequest</code></a>'s <code>response</code> attribute after setting the <code>responseType</code> to <code>arraybuffer</code>. This method only works on complete files, not fragments of audio files.</dd>\n <dt id=\"baseaudiocontext.resume_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>BaseAudioContext.resume()</code> <small>(en-US)</small></a></dt>\n <dd>Resumes the progression of time in an audio context that has previously been suspended/paused.</dd>\n</dl>"}},{"type":"prose","value":{"id":"examples","title":"Examples","isH3":false,"content":"<p>Basic audio context declaration:</p>\n\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">var</span> audioCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n\n<p>Cross browser variant:</p>\n\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">var</span> AudioContext <span class=\"token operator\">=</span> window<span class=\"token punctuation\">.</span>AudioContext <span class=\"token operator\">||</span> window<span class=\"token punctuation\">.</span>webkitAudioContext<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> audioCtx <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">var</span> oscillatorNode <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createOscillator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> gainNode <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> finish <span class=\"token operator\">=</span> audioCtx<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">// etc.</span></code></pre></div>"}},{"type":"prose","value":{"id":"specifications","title":"Specifications","isH3":false,"content":"<table class=\"standard-table\">\n <tbody>\n  <tr>\n   <th scope=\"col\">Specification</th>\n   <th scope=\"col\">Status</th>\n   <th scope=\"col\">Comment</th>\n  </tr>\n  <tr>\n   <td><a href=\"https://www.w3.org/TR/webaudio/#BaseAudioContext\" hreflang=\"en\" lang=\"en\" class=\"external\" rel=\" noopener\">Web Audio API<br><small lang=\"es\">La definición de 'BaseAudioContext' en esta especificación.</small></a></td>\n   <td><span class=\"spec-rec\">Recommendation</span></td>\n   <td> </td>\n  </tr>\n </tbody>\n</table>"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.BaseAudioContext","dataURL":"/es/docs/Web/API/BaseAudioContext/bcd.json"}},{"type":"prose","value":{"id":"see_also","title":"See also","isH3":false,"content":"<ul>\n <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Using the Web Audio API</a></li>\n <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code> <small>(en-US)</small></a></li>\n <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code> <small>(en-US)</small></a></li>\n</ul>"}}],"toc":[{"text":"Properties","id":"properties"},{"text":"Methods","id":"methods"},{"text":"Examples","id":"examples"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"},{"text":"See also","id":"see_also"}],"summary":"{APIRef(\"Web Audio API\")}}","popularity":0,"modified":"2022-10-01T03:41:16.000Z","other_translations":[{"title":"BaseAudioContext","locale":"en-US","native":"English (US)"},{"title":"BaseAudioContext","locale":"fr","native":"Français"},{"title":"BaseAudioContext","locale":"ja","native":"日本語"},{"title":"BaseAudioContext","locale":"ko","native":"한국어"},{"title":"BaseAudioContext","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"es/web/api/baseaudiocontext","github_url":"https://github.com/mdn/translated-content/blob/main/files/es/web/api/baseaudiocontext/index.html","last_commit_url":"https://github.com/mdn/translated-content/commit/921c46a374ab0a9f4cc809af0370f8c412e54701","filename":"index.html"},"parents":[{"uri":"/es/docs/Web","title":"Tecnología para desarrolladores web"},{"uri":"/es/docs/Web/API","title":"Referencia de la API Web"},{"uri":"/es/docs/Web/API/BaseAudioContext","title":"BaseAudioContext"}],"pageTitle":"BaseAudioContext - Referencia de la API Web | MDN","noIndexing":false}}