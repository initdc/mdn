{"doc":{"isMarkdown":true,"isTranslated":true,"isActive":true,"flaws":{},"title":"Web Audio API","mdn_url":"/fr/docs/Web/API/Web_Audio_API","locale":"fr","native":"Français","sidebarHTML":"","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>La Web Audio API propose un système puissant et flexible pour contrôler les données audio sur internet. Elle permet notamment de sélectionner des sources audio (microphone, flux media), d'y ajouter des effets, de créer des visualisations, d'appliquer des effets de spatialisation (comme la balance), etc.</p>"}},{"type":"prose","value":{"id":"concepts_et_usages","title":"Concepts et usages","isH3":false,"content":"<p>La Web Audio API effectue des opérations dans un <strong>contexte audio</strong>; elle a été conçue pour supporter le <strong>routing modulaire</strong>. Les opérations audio basiques sont réalisées via des <strong>noeuds audio</strong> reliés entre eux pour former un <strong>graphe de routage audio</strong>. Plusieurs sources - avec différents types d'agencements de canaux - peuvent être supportées, même dans un seul contexte. Ce design modulaire et flexible permet de créer des fonctions audio complexes avec des effets dynamiques.</p>\n<p>Les noeuds audio sont reliés au niveau de leurs entrées et sorties, formant des chaînes ou des réseaux simples. Il peut y avoir une ou plusieurs sources. Les sources fournissent des tableaux d'intensités sonores (échantillons), souvent plusieurs dizaines de milliers par seconde. Ceux-ci peuvent être calculées mathématiquement (avec un <a href=\"/fr/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a>), ou peuvent provenir de fichiers sons ou vidéos (comme <a href=\"/fr/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a> ou <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code> <small>(en-US)</small></a>) ou de flux audio (<a href=\"/fr/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a>). En réalité, les fichiers sons sont eux-même des enregistrements d'intensités sonores, qui viennent de microphones ou d'instruments électriques, et sont mixés dans une seule onde complexe.</p>\n<p>Les sorties de ces noeuds peuvent être liées aux entrées d'autres noeuds, qui mixent ces flux d'échantillons sonores ou les séparent en différents flux. Une modification courante est la multiplications des échantillons par une valeur afin d'en augmenter ou diminuer le volume sonore (comme c'est le cas pour le <a href=\"/fr/docs/Web/API/GainNode\"><code>GainNode</code></a>). Le son est ensuite lié à une destination (<a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/destination\"><code>AudioContext.destination</code> <small>(en-US)</small></a>), qui l'envoie aux enceintes ou au casque audio. Cette dernière connexion n'est utile que si le son doit être entendu.</p>\n<p>Un processus de développement typique avec web audio ressemble à ceci :</p>\n<ul>\n  <li>Création d'un contexte audio</li>\n  <li>Dans ce contexte, création des sources — comme <code>&lt;audio&gt;</code>, oscillator, stream</li>\n  <li>Création de noeuds d'effets, comme la réverbération, les filtres biquad, la balance, le compresseur</li>\n  <li>Choix de la sortie audio (appelée destination), par exemple les enceintes du système</li>\n  <li>Connection des sources aux effets, et des effets à la destination</li>\n</ul>\n<p>\n  <img src=\"/en-US/docs/Web/API/Web_Audio_API/audio-context_.png\" alt=\"Un diagramme de boîte avec une boîte extérieure intitulée contexte audio et trois boîtes à l'intérieur intitulées source, effets et destination. Les trois boîtes intérieures ont des flèches qui pointent de la gauche vers la droite, indiquant le sens du flux de l'information audio.\" width=\"1200\" height=\"400\" loading=\"lazy\">\n</p>\n<p>Le timing est contrôlé avec une grande précision et une latence faible, ce qui permet aux développeurs d'écrire un code qui réagit précisément aux événements et qui est capable de traiter des échantillons précis, même avec un taux d'échantillonnage élevé. Cela permet d'envisager des applications telles que des boîtes à rythme ou des séquenceurs.</p>\n<p>La Web Audio API permet également de contrôler la <em>spatialisation</em> du son. En utilisant un système basé sur le modèle <em>émetteur - récepteur,</em> elle permet le contrôle de la balance ainsi que la gestion de l'atténuation du son en fonction de la distance, ou effet doppler, induite par un déplacement de la source sonore (ou de l'auditeur).</p>\n<div class=\"notecard note\" id=\"sect1\">\n  <p><strong>Note :</strong> Vous pouvez lire davantage de détails sur l'API <i lang=\"en\">Web Audio</i> en vous rendant sur notre article <a href=\"/fr/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API\">Les concepts de base de l'API <i lang=\"en\">Web Audio</i></a>.</p>\n</div>"}},{"type":"prose","value":{"id":"interface_de_la_web_audio_api","title":"Interface de la Web Audio API","isH3":false,"content":"<p>La Web Audio API expose 28 interfaces avec des événements associés, classés selon leur fonction en 9 catégories.</p>"}},{"type":"prose","value":{"id":"définition_du_graphe_audio","title":"Définition du graphe audio","isH3":true,"content":"<p>Conteneurs et définitions qui donnent sa forme au graphe audio</p>\n<dl>\n  <dt id=\"audiocontext\"><a href=\"/fr/docs/Web/API/AudioContext\"><code>AudioContext</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>AudioContext</code></strong> désigne un graphe de traitement audio construit à partir de modules reliés entre eux, chacun représenté par un noeud audio (<a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a>). Le contexte audio contrôle la création des noeuds qu'il contient, ainsi que l'exécution du traitement audio, et du décodage. Il est nécessaire de créer un <code>AudioContext</code> avant de faire quoi que ce soit d'autre, puisque tout se passe dans un contexte.</p>\n  </dd>\n  <dt id=\"audionode\"><a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>AudioNode</code></strong> est un module de traitement audio, tel qu'une <em>source audio</em> (c'est-à-dire un élément HTML <a href=\"/fr/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a> ou <a href=\"/fr/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a>), une <em>destination audio</em>, un module de traitement intermédiaire (par exemple un filtre <a href=\"/fr/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a>), ou un contrôle du volume <a href=\"/fr/docs/Web/API/GainNode\"><code>GainNode</code></a>).</p>\n  </dd>\n  <dt id=\"audioparam\"><a href=\"/fr/docs/Web/API/AudioParam\"><code>AudioParam</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>AudioParam</code></strong> est un paramètre audio, qui est lié à un <a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a>. On peut lui assigner une valeur ou un changement de valeur, que l'on peut programmer à un moment spécifique et/ou selon un motif particulier.</p>\n  </dd>\n  <dt id=\"ended\"><code><a href=\"/en-US/docs/Web/API/HTMLMediaElement/ended_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">ended (en-US)</a></code> (event)</dt>\n  <dd>\n    <p>L'évènement <code>ended</code> est diffusé lorsque la lecture s'arrête en arrivant à la fin d'un media.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"définition_des_sources_audio","title":"Définition des sources audio","isH3":true,"content":"<dl>\n  <dt id=\"oscillatornode\"><a href=\"/fr/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>OscillatorNode</code></strong> est un module de traitement audio qui génère la création d'une onde sinusoïdale d'une certaine fréquence.</p>\n  </dd>\n  <dt id=\"audiobuffer\"><a href=\"/fr/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>AudioBuffer</code></strong> est un petit morceau de contenu audio monté en mémoire. Il peut être créé à partir d'un fichier audio avec la méthode <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/decodeAudioData\"><code>AudioContext.decodeAudioData()</code> <small>(en-US)</small></a>, ou à partir de données brutes en utilisant <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createBuffer\"><code>AudioContext.createBuffer()</code> <small>(en-US)</small></a>. Une fois décodé sous cette forme, la source audio peut être placée dans un <a href=\"/fr/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a>.</p>\n  </dd>\n  <dt id=\"audiobuffersourcenode\"><a href=\"/fr/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>AudioBufferSourceNode</code></strong> est une source audio composée de données audio montées en mémoire dans un <a href=\"/fr/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a>. C'est un <a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a> qui se comporte comme une source audio.</p>\n  </dd>\n  <dt id=\"mediaelementaudiosourcenode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un objet <strong><code>MediaElementAudio.SourceNode</code></strong> est une source audio composée d'un élément HTML5 <a href=\"/fr/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a> ou <a href=\"/fr/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a>. C'est un <a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a> qui se comporte comme une source audio.</p>\n  </dd>\n  <dt id=\"mediastreamaudiosourcenode\"><a href=\"/fr/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>MediaStreamAudio.SourceNode</code></strong> est une source audio composée d'un <a href=\"/fr/docs/Web/API/WebRTC_API\">WebRTC</a> <a href=\"/fr/docs/Web/API/MediaStream\"><code>MediaStream</code></a> (tel qu'une webcam ou un microphone). C'est un <a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a> qui se comporte comme une source audio.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"définition_des_filtres_deffets_audio","title":"Définition des filtres d'effets audio","isH3":true,"content":"<dl>\n  <dt id=\"biquadfilternode\"><a href=\"/fr/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>BiquadFilterNode</code></strong> est un simple filtre de bas niveau. Il peut s'agir de différents types de filtres, contrôle du volume ou égaliseurs graphiques. Un <code>BiquadFilterNode</code> a toujours exactement une entrée et une sortie.</p>\n  </dd>\n  <dt id=\"convolvernode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un objet <strong><code>Convolver.Node</code></strong> est un <a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a> qui exécute une circonvolution linéaire sur un AudioBuffer donné, souvent utilisé pour créer un effet de réverbération.</p>\n  </dd>\n  <dt id=\"delaynode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un objet <strong><code>DelayNode</code></strong> est une ligne à retard numérique, c'est-à-dire un module de traitement automatique qui provoque un délai entre l'arrivée du son en entrée et sa propagation en sortie.</p>\n  </dd>\n  <dt id=\"dynamicscompressornode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un objet <strong><code>DynamicsCompressorNode</code></strong> permet un effet de compression, qui réduit le volume des parties les plus fortes du signal de façon à éviter les effets de clipping et la distortion qui peuvent se produire lorsque des sons multiples sont diffusés simultanément.</p>\n  </dd>\n  <dt id=\"gainnode\"><a href=\"/fr/docs/Web/API/GainNode\"><code>GainNode</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>GainNode</code></strong> représente une modification du volume sonore. C'est un module de traitement audio qui provoque l'application d'un <em>gain</em> aux données récupérées en entrée avant leur propagation vers la sortie.</p>\n  </dd>\n  <dt id=\"waveshapernode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un objet <strong><code>WaveShaperNode</code></strong> représente une distortion non linéaire. C'est un <a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a> qui utilise une courbe pour appliquer au signal une distortion de mise en forme des ondes. En dehors de l'effet de distortion évident, il est souvent utilisé pour donner un caractère plus chaleureux au son.</p>\n  </dd>\n  <dt id=\"periodicwave\"><a href=\"/fr/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></dt>\n  <dd>\n    <p>Un objet <a href=\"/fr/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a> est utilisé pour définir une forme d'onde périodique qui peut être utilisée pour façonner la sortie d'un <a href=\"/fr/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a>.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"définition_des_destinations_audio","title":"Définition des destinations audio","isH3":true,"content":"<p>Une fois que le signal audio a été traité, ces interfaces définissent sa destination.</p>\n<dl>\n  <dt id=\"audiodestinationnode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un noeud <strong><code>AudioDestinationNode</code></strong> représente la destination finale d'une source audio source dans un contexte donné — en général les enceintes du matériel.</p>\n  </dd>\n  <dt id=\"mediastreamaudiodestinationnode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un noeud <strong><code>MediaStreamAudio.DestinationNode</code></strong> représente une destination audio constituée d'un <a href=\"/fr/docs/Web/API/MediaStream\"><code>MediaStream</code></a> <a href=\"/fr/docs/Web/API/WebRTC_API\">WebRTC</a> à une seule piste <code>AudioMediaStreamTrack</code>; il peut être utilisé de façon similaire à un <a href=\"/fr/docs/Web/API/MediaStream\"><code>MediaStream</code></a> obtenu avec <a href=\"/fr/docs/Web/API/Navigator/getUserMedia\"><code>Navigator.getUserMedia</code></a>. C'est un <a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a> qui se comporte comme une destination audio.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"analyse_des_données_et_visualisation","title":"Analyse des données et visualisation","isH3":true,"content":"<dl>\n  <dt id=\"analysernode\"><a href=\"/fr/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>AnalyserNode</code></strong> fournit en temps réel des informations concernant la fréquence et le temps, afin de les analyser et les visualiser.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"division_et_fusion_des_pistes_audio","title":"Division et fusion des pistes audio","isH3":true,"content":"<dl>\n  <dt id=\"channelsplitternode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un noeud <strong><code>ChannelSplitterNode</code></strong> prend en entrée une source audio et sépare ses différentes pistes en une série de sorties <em>mono</em>.</p>\n  </dd>\n  <dt id=\"channelmergernode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un noeud <strong><code>ChannelMergerNode</code></strong> réunit différentes entrées mono en une seule sortie. Chaque entrée devient une des pistes de la sortie unique.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"spatialisation_audio","title":"Spatialisation audio","isH3":true,"content":"<dl>\n  <dt id=\"audiolistener\"><a href=\"/fr/docs/Web/API/AudioListener\"><code>AudioListener</code></a></dt>\n  <dd>\n    <p>Un objet <strong><code>AudioListener</code></strong> représente la position et l'orientation de l'unique personne écoutant la scene audio utilisée dans la spatialisation audio.</p>\n  </dd>\n  <dt id=\"pannernode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un noeud <strong><code>PannerNode</code></strong> représente le comportement d'un signal dans l'espace. C'est un module de traitement audio qui décrit sa position avec des coordonnées cartésiennes fondées sur la règle de la main droite; ses mouvements utilisent un vecteur de vélocité et sa directionnalité un cône de direction.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"traitement_audio_avec_javascript","title":"Traitement audio avec JavaScript","isH3":true,"content":"<div class=\"notecard note\" id=\"sect2\">\n  <p><strong>Note :</strong> Au jour de la publication de la spécification Web Audio API le 29 août 2014, ces fonctionnalités sont dépréciées, et seront bientôt remplacées par <a href=\"#audio_workers\">Audio_Workers</a>.</p>\n</div>\n<dl>\n  <dt id=\"scriptprocessornode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un noeud <strong><code>ScriptProcessorNode</code></strong> permet de générer, traiter ou analyser du son avec JavaScript. C'est un module de traitement audio qui est lié à deux buffers, l'un en entrée, et l'autre en sortie. Un évènement implémentant <a href=\"/fr/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a> est envoyé à l'objet à chaque fois que le buffer d'entrée reçoit de nouvelles données, et le gestionnaire d'évènement prend fin lorsque les nouvelles données ont été communiquées au buffer de sortie.</p>\n  </dd>\n  <dt id=\"audioprocess\"><code><a href=\"/en-US/docs/Web/API/ScriptProcessorNode/audioprocess_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">audioprocess (en-US)</a></code> (event)</dt>\n  <dd>\n    <p>L'évènement <code>audioprocess</code> est émis lorsque le buffer d'entrée d'un <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code> <small>(en-US)</small></a> de la Web Audio API est prêt à être traité.</p>\n  </dd>\n  <dt id=\"audioprocessingevent\"><a href=\"/fr/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a></dt>\n  <dd>\n    <p>L'objet <code>AudioProcessingEvent</code> est envoyé aux fonctions de rappel (<i lang=\"en\">callback</i>) qui écoutent l'évènement <code>audioprocess</code>.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"traitement_audio_hors_ligne_ou_en_tâche_de_fond","title":"Traitement audio hors ligne ou en tâche de fond","isH3":true,"content":"<p>Il est possible de traiter et exporter un graphe audio très rapidement en tâche de fond — en l'exportant dans un <a href=\"/fr/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> plutôt que sur les enceintes du matériel — grâce aux objets suivants.</p>\n<dl>\n  <dt id=\"offlineaudiocontext_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un objet <strong><code>OfflineAudioContext</code></strong> est une interface <a href=\"/fr/docs/Web/API/AudioContext\"><code>AudioContext</code></a> qui représente un graphe de traitement audio construit à partir de nœuds audio. À la différence d'une interface <code>AudioContext</code> standard, une interface <code>OfflineAudioContext</code> n'exporte pas vraiment le son, mais le génère <em>aussi vite que possible</em> dans un buffer.</p>\n  </dd>\n  <dt id=\"complete\"><code><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">complete (en-US)</a></code> (event)</dt>\n  <dd>\n    <p>Un évènement <code>complete</code> est émis lorsque le rendu d'un <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code> <small>(en-US)</small></a> est terminé.</p>\n  </dd>\n  <dt id=\"offlineaudiocompletionevent_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>The <code>OfflineAudioCompletionEvent</code> est envoyé aux fonctions de callback qui écoutent l'évènement <code><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">complete (en-US)</a></code> event implements this interface.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"audio_workers","title":"Audio Workers","isH3":true,"content":"<p>Les Audio workers offrent la possibilité de traiter le son directement dans le contexte d'un <a href=\"/en-US/docs/Web/API/Web_Workers_API/Using_web_workers\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">web worker (en-US)</a>. En date du 29 August 2014, ils ne sont encore implémentés par aucun navigateur. Lorsqu'ils seront implémentés, ils remplaceront <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code> <small>(en-US)</small></a>, et les autres fonctionnalités mentionnées dans la section <a href=\"#audio_processing_via_javascript\">Traitement audio avec JavaScript</a> ci-avant.</p>\n<dl>\n  <dt id=\"audioworkernode\"><a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>AudioWorkerNode</code></a></dt>\n  <dd>\n    <p>Un objet AudioWorkerNode représente un <a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a> qui interagit avec le thread d'un worker pour générer, traiter, ou analyse le son directement.</p>\n  </dd>\n  <dt id=\"audioworkerglobalscope\"><a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>AudioWorkerGlobalScope</code></a></dt>\n  <dd>\n    <p>Un objet <code>AudioWorkerGlobalScope</code> est un objet dérivé d'un objet <code>DedicatedWorkerGlobalScope</code>. Il représente le contexte d'un worker dans lequel un script de traitement audio est lancé; il est conçu pour permettre la génération, le traitement, et l'analyse de données audio directement avec JavaScript dans le thread d'un worker.</p>\n  </dd>\n  <dt id=\"audioprocessevent\"><a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>AudioProcessEvent</code></a></dt>\n  <dd>\n    <p>UN objet <code>Event</code> est transmis aux objets <a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>AudioWorkerGlobalScope</code></a> pour effectuer un traitement audio.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"objets_obsolètes","title":"Objets obsolètes","isH3":false,"content":"<p>Les objets suivants étaient définis dans les versions précédentes de la spécification, mais sont maintenant obsolètes et ont été remplacés.</p>\n<dl>\n  <dt id=\"javascriptnode\"><a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>JavaScriptNode</code></a></dt>\n  <dd>\n    <p>Utilisé pour le traitement du son directement en Javascript. Cet objet est obsolète, et a été remplacé par <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code> <small>(en-US)</small></a>.</p>\n  </dd>\n  <dt id=\"wavetablenode\"><a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>WaveTableNode</code></a></dt>\n  <dd>\n    <p>Utilisé pour définir une forme d'onde périodique. Cet objet est obsolète, et a été remplacé par <a href=\"/fr/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a>.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"exemples","title":"Exemples","isH3":false,"content":"<p>Vous pouvez trouver différents exemples dans <a href=\"https://github.com/mdn/webaudio-examples/\" class=\"external\" rel=\" noopener\">le dépôt webaudio-example</a> sur GitHub.</p>"}},{"type":"specifications","value":{"title":"Spécifications","id":"spécifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#AudioContext","title":"Web Audio API"}],"query":"api.AudioContext"}},{"type":"browser_compatibility","value":{"title":"Compatibilité des navigateurs","id":"compatibilité_des_navigateurs","isH3":false,"query":"api.AudioContext","dataURL":"/fr/docs/Web/API/Web_Audio_API/bcd.json"}},{"type":"prose","value":{"id":"voir_aussi","title":"Voir aussi","isH3":false,"content":"<ul>\n  <li><a href=\"/fr/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Utiliser la Web Audio API</a></li>\n  <li><a href=\"/fr/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\">Visualizations with Web Audio API</a></li>\n  <li><a href=\"https://mdn.github.io/voice-change-o-matic/\" class=\"external\" rel=\" noopener\">Voice-change-O-matic example</a></li>\n  <li><a href=\"https://mdn.github.io/violent-theremin/\" class=\"external\" rel=\" noopener\">Violent Theremin example</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Web audio spatialisation basics (en-US)</a></li>\n  <li><a href=\"https://www.html5rocks.com/tutorials/webaudio/positional_audio/\" class=\"external\" rel=\" noopener\">Mixing Positional Audio and WebGL</a></li>\n  <li><a href=\"https://www.html5rocks.com/tutorials/webaudio/games/\" class=\"external\" rel=\" noopener\">Developing Game Audio with the Web Audio API</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Migrating_from_webkitAudioContext\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Porting webkitAudioContext code to standards based AudioContext (en-US)</a></li>\n  <li><a href=\"https://github.com/bit101/tones\" class=\"external\" rel=\" noopener\">Tones</a>: a simple library for playing specific tones/notes using the Web Audio API.</li>\n  <li><a href=\"https://github.com/goldfire/howler.js/\" class=\"external\" rel=\" noopener\">howler.js</a>: a JS audio library that defaults to <a href=\"https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html\" class=\"external\" rel=\" noopener\">Web Audio API</a> and falls back to <a href=\"https://www.whatwg.org/specs/web-apps/current-work/#the-audio-element\" class=\"external\" rel=\" noopener\">HTML5 Audio</a>, as well as providing other useful features.</li>\n  <li><a href=\"https://github.com/mattlima/mooog\" class=\"external\" rel=\" noopener\">Mooog</a>: jQuery-style chaining of AudioNodes, mixer-style sends/returns, and more.</li>\n</ul>"}},{"type":"prose","value":{"id":"guides","title":"Guides","isH3":true,"content":"<ul>\n  <li><a href=\"/fr/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API\">Les concepts de base de la Web Audio API</a></li>\n  <li><a href=\"/fr/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\">Utiliser la Web Audio API</a></li>\n  <li><a href=\"/fr/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\">Visualizations with Web Audio API</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Web audio spatialisation basics (en-US)</a></li>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Migrating_from_webkitAudioContext\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Porting webkitAudioContext code to standards based AudioContext (en-US)</a></li>\n</ul>"}},{"type":"prose","value":{"id":"démos","title":"Démos","isH3":true,"content":"<ul>\n  <li><a href=\"https://mdn.github.io/voice-change-o-matic/\" class=\"external\" rel=\" noopener\">Voice-change-O-matic</a></li>\n  <li><a href=\"https://mdn.github.io/violent-theremin/\" class=\"external\" rel=\" noopener\">Violent Theremin</a></li>\n</ul>"}},{"type":"prose","value":{"id":"api","title":"API","isH3":true,"content":"<ul>\n  <li><a href=\"/fr/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li>\n  <li><a href=\"/fr/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li>\n  <li><a href=\"/fr/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li>\n  <li><a href=\"/fr/docs/Web/API/AudioContext\"><code>AudioContext</code></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code> <small>(en-US)</small></a></li>\n  <li><a href=\"/fr/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li>\n  <li><a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li>\n  <li><a href=\"/fr/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li>\n  <li><code><a href=\"/en-US/docs/Web/API/ScriptProcessorNode/audioprocess_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">audioprocess (en-US)</a></code> (event)</li>\n  <li><a href=\"/fr/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a></li>\n  <li><a href=\"/fr/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code> <small>(en-US)</small></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code> <small>(en-US)</small></a></li>\n  <li><code><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">complete (en-US)</a></code> (event)</li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code> <small>(en-US)</small></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code> <small>(en-US)</small></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code> <small>(en-US)</small></a></li>\n  <li><code><a href=\"/en-US/docs/Web/API/HTMLMediaElement/ended_event\" title=\"Currently only available in English (US)\" class=\"only-in-en-us\">ended (en-US)</a></code> (event)</li>\n  <li><a href=\"/fr/docs/Web/API/GainNode\"><code>GainNode</code></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code> <small>(en-US)</small></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code> <small>(en-US)</small></a></li>\n  <li><a href=\"/fr/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code> <small>(en-US)</small></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code> <small>(en-US)</small></a></li>\n  <li><a href=\"/fr/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code> <small>(en-US)</small></a></li>\n  <li><a href=\"/fr/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code> <small>(en-US)</small></a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code> <small>(en-US)</small></a></li>\n</ul>"}}],"toc":[{"text":"Concepts et usages","id":"concepts_et_usages"},{"text":"Interface de la Web Audio API","id":"interface_de_la_web_audio_api"},{"text":"Objets obsolètes","id":"objets_obsolètes"},{"text":"Exemples","id":"exemples"},{"text":"Spécifications","id":"spécifications"},{"text":"Compatibilité des navigateurs","id":"compatibilité_des_navigateurs"},{"text":"Voir aussi","id":"voir_aussi"}],"summary":"La Web Audio API propose un système puissant et flexible pour contrôler les données audio sur internet. Elle permet notamment de sélectionner des sources audio (microphone, flux media), d'y ajouter des effets, de créer des visualisations, d'appliquer des effets de spatialisation (comme la balance), etc.","popularity":0.0004,"modified":"2022-10-01T03:41:16.000Z","other_translations":[{"title":"Web Audio API","locale":"en-US","native":"English (US)"},{"title":"Web Audio API","locale":"es","native":"Español"},{"title":"Web Audio API","locale":"ja","native":"日本語"},{"title":"Web Audio API","locale":"ko","native":"한국어"},{"title":"API Web Áudio","locale":"pt-BR","native":"Português (do Brasil)"},{"title":"Web Audio API","locale":"ru","native":"Русский"},{"title":"Web Audio API","locale":"zh-CN","native":"中文 (简体)"},{"title":"Web Audio API","locale":"zh-TW","native":"正體中文 (繁體)"}],"source":{"folder":"fr/web/api/web_audio_api","github_url":"https://github.com/mdn/translated-content/blob/main/files/fr/web/api/web_audio_api/index.md","last_commit_url":"https://github.com/mdn/translated-content/commit/921c46a374ab0a9f4cc809af0370f8c412e54701","filename":"index.md"},"parents":[{"uri":"/fr/docs/Web","title":"Technologies web pour développeurs"},{"uri":"/fr/docs/Web/API","title":"Référence Web API"},{"uri":"/fr/docs/Web/API/Web_Audio_API","title":"Web Audio API"}],"pageTitle":"Web Audio API - Référence Web API | MDN","noIndexing":false}}