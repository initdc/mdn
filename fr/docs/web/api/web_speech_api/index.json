{"doc":{"isMarkdown":true,"isTranslated":true,"isActive":true,"flaws":{},"title":"L'API Web Speech","mdn_url":"/fr/docs/Web/API/Web_Speech_API","locale":"fr","native":"Français","sidebarHTML":"<ol><li><strong><a href=\"/fr/docs/Web/API/Web_Speech_API\">Web Speech API</a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Interfaces</summary><ol><li><a href=\"/fr/docs/Web/API/SpeechGrammar\"><code>SpeechGrammar</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechGrammarList\"><code>SpeechGrammarList</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechRecognition\"><code>SpeechRecognition</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechRecognitionAlternative\"><code>SpeechRecognitionAlternative</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechRecognitionErrorEvent\"><code>SpeechRecognitionErrorEvent</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechRecognitionEvent\"><code>SpeechRecognitionEvent</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechRecognitionResult\"><code>SpeechRecognitionResult</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechRecognitionResultList\"><code>SpeechRecognitionResultList</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechSynthesis\"><code>SpeechSynthesis</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechSynthesisErrorEvent\"><code>SpeechSynthesisErrorEvent</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechSynthesisEvent\"><code>SpeechSynthesisEvent</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code></a></li><li><a href=\"/fr/docs/Web/API/SpeechSynthesisVoice\"><code>SpeechSynthesisVoice</code></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<div class=\"notecard experimental\" id=\"sect1\"><p><strong>Experimental:</strong> <strong>Cette fonction est expérimentale</strong><br>Puisque cette fonction est toujours en développement dans certains navigateurs, veuillez consulter le <a href=\"#browser_compatibility\">tableau de compatibilité</a> pour les préfixes à utiliser selon les navigateurs.<br>Il convient de noter qu'une fonctionnalité expérimentale peut voir sa syntaxe ou son comportement modifié dans le futur en fonction des évolutions de la spécification.</p></div>\n<p>L'API <i lang=\"en\">Web Speech</i> permet d'intégrer des données liées à la voix dans des applications web. L'API <i lang=\"en\">Web Speech</i> se compose de deux parties : <i lang=\"en\">SpeechSynthesis</i> (synthèse vocale) et <i lang=\"en\">SpeechRecognition</i> (reconnaissance vocale asynchrone).</p>"}},{"type":"prose","value":{"id":"concepts_et_usages_de_lapi_web_speech","title":"Concepts et usages de l'API Web Speech","isH3":false,"content":"<p>L'API <i lang=\"en\">Web Speech</i> rend les applications web capables de manipuler des données liées à la voix. Cette API se compose de deux parties :</p>\n<ul>\n  <li>\n    La reconnaissance vocale (\n    <i lang=\"en\">Speech recognition</i>\n    ) est accessible via l'interface <a href=\"/fr/docs/Web/API/SpeechRecognition\"><code>SpeechRecognition</code></a> qui fournit la capacité de reconnaitre la voix dans une source audio (normalement grâce à l'outil par défaut de reconnaissance vocale de l'appareil) et de réagir de façon pertinente. En général, on utilisera le constructeur de l'interface pour créer un nouvel objet <a href=\"/fr/docs/Web/API/SpeechRecognition\"><code>SpeechRecognition</code></a> qui a un nombre de gestionnaires d'événements disponibles pour détecter lorsque de la parole arrive dans le micro de l'appareil. L'interface <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechGrammar\"><code>SpeechGrammar</code> <small>(en-US)</small></a> représente un conteneur pour une série de règles de grammaire que votre application devrait reconnaître. La grammaire est définie en utilisant <a href=\"https://www.w3.org/TR/jsgf/\" class=\"external\" rel=\" noopener\">JSpeech Grammar Format</a> (<strong>JSGF</strong>).\n  </li>\n  <li>\n    La synthèse vocale (\n    <i lang=\"en\">Speech synthesis</i>\n    ) est disponible via l'interface <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesis\"><code>SpeechSynthesis</code> <small>(en-US)</small></a>, un composant qui permet aux programmes de vocaliser leur contenu textuel (normalement grâce au synthétiseur vocal par défaut de l'appareil). Differents types de voix sont disponibles dans les objets <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisVoice\"><code>SpeechSynthesisVoice</code> <small>(en-US)</small></a>, et les différentes parties de texte à vocaliser sont interprétés par les objets <a href=\"/fr/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code></a>. On peut les faire vocaliser en les passant à la méthode <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesis/speak\"><code>SpeechSynthesis.speak()</code> <small>(en-US)</small></a>.\n  </li>\n</ul>\n<p>Pour plus de détails concernant ces fonctionnalités, voir <a href=\"/fr/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API\">Using the Web Speech API.</a></p>"}},{"type":"prose","value":{"id":"les_interfaces_de_lapi_web_speech","title":"Les interfaces de l'API Web Speech","isH3":false,"content":""}},{"type":"prose","value":{"id":"le_reconnaissance_vocale","title":"Le reconnaissance vocale","isH3":true,"content":"<dl>\n  <dt id=\"speechrecognition\"><a href=\"/fr/docs/Web/API/SpeechRecognition\"><code>SpeechRecognition</code></a></dt>\n  <dd>\n    <p>L'interface de contrôle de l'outil de reconnaissance; elle traite aussi le <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionEvent\"><code>SpeechRecognitionEvent</code> <small>(en-US)</small></a> reçu de l'outil de reconnaissance.</p>\n  </dd>\n  <dt id=\"speechrecognitionalternative_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionAlternative\"><code>SpeechRecognitionAlternative</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Représente un mot unique qui a été reconnu par l'outil de reconnaissane vocale.</p>\n  </dd>\n  <dt id=\"speechrecognitionerror_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionErrorEvent\"><code>SpeechRecognitionError</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Répresente les messages d'erreur de l'outil de reconnaissance vocale.</p>\n  </dd>\n  <dt id=\"speechrecognitionevent_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionEvent\"><code>SpeechRecognitionEvent</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>L'objet événement pour les événements <code><a href=\"/fr/docs/Web/Reference/Events/result\" title=\"This is a link to an unwritten page\" class=\"page-not-created\">result</a></code> et <code><a href=\"/fr/docs/Web/Reference/Events/nomatch\" title=\"This is a link to an unwritten page\" class=\"page-not-created\">nomatch</a></code>, et contient toutes les données associées avec un résultat de reconnaissance vocale intermédiaire ou définitif.</p>\n  </dd>\n  <dt id=\"speechgrammar_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechGrammar\"><code>SpeechGrammar</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Les mots ou schémas de mots que l'on demande à l'outil de reconnaissance vocale de reconnaître.</p>\n  </dd>\n  <dt id=\"speechgrammarlist_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechGrammarList\"><code>SpeechGrammarList</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Répresente une liste des objets <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechGrammar\"><code>SpeechGrammar</code> <small>(en-US)</small></a>.</p>\n  </dd>\n  <dt id=\"speechrecognitionresult_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionResult\"><code>SpeechRecognitionResult</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Répresente une unique reconnaissance réussie, qui peut contenir plusieurs objets <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionAlternative\"><code>SpeechRecognitionAlternative</code> <small>(en-US)</small></a>.</p>\n  </dd>\n  <dt id=\"speechrecognitionresultlist_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionResultList\"><code>SpeechRecognitionResultList</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Répresente une liste d'objets <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognitionResult\"><code>SpeechRecognitionResult</code> <small>(en-US)</small></a>, ou bien un seul si les résultats sont récupérés en mode <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechRecognition/continuous\"><code>continuous</code> <small>(en-US)</small></a>.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"la_synthèse_vocale","title":"La synthèse vocale","isH3":true,"content":"<dl>\n  <dt id=\"speechsynthesis_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesis\"><code>SpeechSynthesis</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>L'interface de contrôle de l'outil de vocalisation; elle peut être utiliser pour rechercher des informations concernant les voix de synthèse disponible dans l'appareil, le démarrage et l'interruption de la vocalisation, et les commandes complémentaires.</p>\n  </dd>\n  <dt id=\"speechsynthesiserrorevent_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisErrorEvent\"><code>SpeechSynthesisErrorEvent</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Contient les informations concernant toutes les erreurs qui se produisent pendant le traitement des objets <a href=\"/fr/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code></a> dans l'outil de synthèse vocale.</p>\n  </dd>\n  <dt id=\"speechsynthesisevent_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisEvent\"><code>SpeechSynthesisEvent</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Contient les informations concernant l'état actuel des objets <a href=\"/fr/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code></a> qui ont été traités par l'outil de synthèse vocale.</p>\n  </dd>\n  <dt id=\"speechsynthesisutterance\"><a href=\"/fr/docs/Web/API/SpeechSynthesisUtterance\"><code>SpeechSynthesisUtterance</code></a></dt>\n  <dd>\n    <p>Répresente une requête de synthèse vocale. Il contient le contenu que l'outil de synthèse vocale devrait vocaliser et les informations sur comment le vocaliser (e.g. langue, ton et volume).</p>\n  </dd>\n</dl><!---->\n<dl>\n  <dt id=\"speechsynthesisvoice_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesisVoice\"><code>SpeechSynthesisVoice</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Représente une voix qui est supportée par le système. Chaque <code>SpeechSynthesisVoice</code> a son propre outil de synthèse vocale incluant les informations concernant la langue, le nom et l'URI.</p>\n  </dd>\n  <dt id=\"window.speechsynthesis_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/Window/speechSynthesis\"><code>Window.speechSynthesis</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Spécifiée comme une partie de l'interface <code>[NoInterfaceObject]</code> intitulée <code>SpeechSynthesisGetter</code>, et implémentée par l'objet <code>Window</code>, la propriété <code>speechSynthesis</code> fournit l'accès au controleur <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/SpeechSynthesis\"><code>SpeechSynthesis</code> <small>(en-US)</small></a>, et de ce fait un point d'entrée à la fonctionnalité de synthèse vocale.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"exemples","title":"Exemples","isH3":false,"content":"<p>Le <a href=\"https://github.com/mdn/web-speech-api/\" class=\"external\" rel=\" noopener\">Web Speech API repo</a> sur GitHub contient des démos qui illustrent la reconnaissance vocale et la synthèse vocale.</p>"}},{"type":"specifications","value":{"title":"Spécifications","id":"spécifications","isH3":false,"query":"api.SpeechRecognition,api.SpeechSynthesis","specifications":[]}},{"type":"browser_compatibility","value":{"title":"Compatibilité des navigateurs","id":"compatibilité_des_navigateurs","isH3":false,"data":null,"query":"api.SpeechRecognition,api.SpeechSynthesis","browsers":null}},{"type":"prose","value":{"id":"voir_aussi","title":"Voir aussi","isH3":false,"content":"<ul>\n  <li><a href=\"/fr/docs/Web/API/Web_Speech_API/Using_the_Web_Speech_API\">Using the Web Speech API</a></li>\n  <li><a href=\"https://www.sitepoint.com/talking-web-pages-and-the-speech-synthesis-api/\" class=\"external\" rel=\" noopener\">Article sur le site SitePoint</a></li>\n  <li><a href=\"http://updates.html5rocks.com/2014/01/Web-apps-that-talk---Introduction-to-the-Speech-Synthesis-API\" class=\"external\" rel=\" noopener\">Article HTML5Rocks</a></li>\n  <li><a href=\"https://aurelio.audero.it/demo/speech-synthesis-api-demo.html\" class=\"external\" rel=\" noopener\">Demo</a> [aurelio.audero.it]</li>\n</ul>"}}],"toc":[{"text":"Concepts et usages de l'API Web Speech","id":"concepts_et_usages_de_lapi_web_speech"},{"text":"Les interfaces de l'API Web Speech","id":"les_interfaces_de_lapi_web_speech"},{"text":"Exemples","id":"exemples"},{"text":"Spécifications","id":"spécifications"},{"text":"Compatibilité des navigateurs","id":"compatibilité_des_navigateurs"},{"text":"Voir aussi","id":"voir_aussi"}],"summary":"L'API Web Speech permet d'intégrer des données liées à la voix dans des applications web. L'API Web Speech se compose de deux parties : SpeechSynthesis (synthèse vocale) et SpeechRecognition (reconnaissance vocale asynchrone).","popularity":0.0002,"modified":"2022-10-01T03:41:16.000Z","other_translations":[{"title":"Web Speech API","locale":"en-US","native":"English (US)"},{"title":"Web Speech API","locale":"es","native":"Español"},{"title":"Web Speech API","locale":"ja","native":"日本語"},{"title":"Web Speech API","locale":"ru","native":"Русский"},{"title":"Web Speech API","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"fr/web/api/web_speech_api","github_url":"https://github.com/mdn/translated-content/blob/main/files/fr/web/api/web_speech_api/index.md","last_commit_url":"https://github.com/mdn/translated-content/commit/921c46a374ab0a9f4cc809af0370f8c412e54701","filename":"index.md"},"parents":[{"uri":"/fr/docs/Web","title":"Technologies web pour développeurs"},{"uri":"/fr/docs/Web/API","title":"Référence Web API"},{"uri":"/fr/docs/Web/API/Web_Speech_API","title":"L'API Web Speech"}],"pageTitle":"L'API Web Speech - Référence Web API | MDN","noIndexing":false}}