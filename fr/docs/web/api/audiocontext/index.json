{"doc":{"isMarkdown":true,"isTranslated":true,"isActive":true,"flaws":{},"title":"AudioContext","mdn_url":"/fr/docs/Web/API/AudioContext","locale":"fr","native":"Français","sidebarHTML":"<ol><li><strong><a href=\"/fr/docs/Web/API/Web_Audio_API\">Web Audio API</a></strong></li><li><strong><a href=\"/fr/docs/Web/API/AudioContext\"><code>AudioContext</code></a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Constructeur</summary><ol><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/AudioContext\"><code>AudioContext()</code> <small>(en-US)</small></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Propriétés</summary><ol><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/baseLatency\"><code>baseLatency</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/outputLatency\"><code>outputLatency</code> <small>(en-US)</small></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Méthodes</summary><ol><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/close\"><code>close()</code> <small>(en-US)</small></a></li><li><a href=\"/fr/docs/Web/API/AudioContext/createMediaElementSource\"><code>createMediaElementSource()</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamDestination\"><code>createMediaStreamDestination()</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamSource\"><code>createMediaStreamSource()</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamTrackSource\"><code>createMediaStreamTrackSource()</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/getOutputTimestamp\"><code>getOutputTimestamp()</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>resume()</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/suspend\"><code>suspend()</code> <small>(en-US)</small></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Héritage&nbsp;:</summary><ol><li><a href=\"/fr/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/fr/docs/Web/API/EventTarget\"><code>EventTarget</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Pages liées à Web Audio API</summary><ol><li><a href=\"/fr/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/fr/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/fr/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code> <small>(en-US)</small></a></li><li><a href=\"/fr/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/fr/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/fr/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code> <small>(en-US)</small></a></li><li><a href=\"/fr/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code> <small>(en-US)</small></a></li><li><a href=\"/fr/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/fr/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code> <small>(en-US)</small></a></li><li><a href=\"/fr/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code> <small>(en-US)</small></a></li><li><a href=\"/fr/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code> <small>(en-US)</small></a></li><li><a href=\"/fr/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code> <small>(en-US)</small></a></li><li><a href=\"/fr/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code> <small>(en-US)</small></a></li><li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code> <small>(en-US)</small></a></li></ol></details></li></ol>","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>L'interface AudioContext représente un graphe de traitement audio fait de modules audio reliés entre eux, chaque module correspondant à un <a href=\"/fr/docs/Web/API/AudioNode\"><code>AudioNode</code></a>. Un contexte audio contrôle à la fois la création des nœuds qu'il contient et l'exécution du traitement audio, ou du décodage. On commence toujours par créer un contexte audio, et tout ce qui va se passer ensuite se situera dans ce contexte.</p>\n<p>Un contexte audio peut être la cible d'événements, par conséquent il implémente l'interface <a href=\"/fr/docs/Web/API/EventTarget\"><code>EventTarget</code></a>.</p><svg viewBox=\"-1 -1 650 42\" preserveAspectRatio=\"xMinYMin meet\">\n  <a style=\"text-decoration: none;\" xlink:href=\"/fr/docs/Web/API/EventTarget\">\n    <rect x=\"0\" y=\"0\" width=\"88\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"44\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      EventTarget\n    </text>\n  </a>\n  <line x1=\"88\" y1=\"14\" x2=\"118\" y2=\"14\" stroke=\"#D4DDE4\" \"=\"\"></line>\n  <polyline points=\"88,14 98,9 98,19 88,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" xlink:href=\"/fr/docs/Web/API/BaseAudioContext\">\n    <rect x=\"118\" y=\"0\" width=\"128\" height=\"25\" fill=\"#fff\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"182\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      BaseAudioContext\n    </text>\n  </a>\n  <line x1=\"246\" y1=\"14\" x2=\"276\" y2=\"14\" stroke=\"#D4DDE4\" \"=\"\"></line>\n  <polyline points=\"246,14 256,9 256,19 246,14\" stroke=\"#D4DDE4\" fill=\"#fff\"></polyline>\n  <a style=\"text-decoration: none;\" xlink:href=\"/fr/docs/Web/API/AudioContext\" aria-current=\"page\">\n    <rect x=\"276\" y=\"0\" width=\"96\" height=\"25\" fill=\"#F4F7F8\" stroke=\"#D4DDE4\" stroke-width=\"2px\"></rect>\n    <text x=\"324\" y=\"16\" font-size=\"10px\" fill=\"#4D4E53\" text-anchor=\"middle\">\n      AudioContext\n    </text>\n  </a></svg>"}},{"type":"prose","value":{"id":"constructeur","title":"Constructeur","isH3":false,"content":"<dl>\n  <dt id=\"audiocontext_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/AudioContext\"><code>AudioContext()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée et retourne un nouvel objet <code>AudioContext</code>.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"propriétés","title":"Propriétés","isH3":false,"content":"<dl>\n  <dt id=\"audiocontext.currenttime_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/currentTime\"><code>AudioContext.currentTime</code> <small>(en-US)</small></a> <span title=\"Cette valeur ne peut pas être changée.\" class=\"badge inline readonly\">Lecture seule </span></dt>\n  <dd>\n    <p>Renvoie un double flottant, qui représente un temps en secondes en augmentation continue, utilisé pour situer dans le temps. Il commence à <code>0</code>.</p>\n  </dd>\n  <dt id=\"audiocontext.destination_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/destination\"><code>AudioContext.destination</code> <small>(en-US)</small></a> <span title=\"Cette valeur ne peut pas être changée.\" class=\"badge inline readonly\">Lecture seule </span></dt>\n  <dd>\n    <p>Retourne un <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code> <small>(en-US)</small></a> représentant la destination finale de tous les fichiers audio dans un contexte. On peut le considérer comme un dispositif de rendu audio.</p>\n  </dd>\n</dl><!---->\n<dl>\n  <dt id=\"audiocontext.listener_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/listener\"><code>AudioContext.listener</code> <small>(en-US)</small></a> <span title=\"Cette valeur ne peut pas être changée.\" class=\"badge inline readonly\">Lecture seule </span></dt>\n  <dd>\n    <p>Renvoie l'objet <a href=\"/fr/docs/Web/API/AudioListener\"><code>AudioListener</code></a>, utilisé pour la spatialisation 3D.</p>\n  </dd>\n</dl><!---->\n<dl>\n  <dt id=\"audiocontext.samplerate_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/sampleRate\"><code>AudioContext.sampleRate</code> <small>(en-US)</small></a> <span title=\"Cette valeur ne peut pas être changée.\" class=\"badge inline readonly\">Lecture seule </span></dt>\n  <dd>\n    <p>Renvoie un nombre flottant représentant la fréquence d'échantillonnage (échantillons par seconde) utilisée par tous les nœuds dans ce contexte.La fréquence d'échantillonnage d'un contexte audio ne peut pas être modifiée.</p>\n  </dd>\n  <dt id=\"audiocontext.state_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/state\"><code>AudioContext.state</code> <small>(en-US)</small></a> <span title=\"Cette valeur ne peut pas être changée.\" class=\"badge inline readonly\">Lecture seule </span></dt>\n  <dd>\n    <p>Renvoie l'état actuel du contexte audio.</p>\n  </dd>\n  <dt id=\"audiocontext.mozaudiochanneltype\"><a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>AudioContext.mozAudioChannelType</code></a> <svg class=\"icon icon-nonstandard\" tabindex=\"0\">\n    <use xlink:href=\"/assets/badges.svg#icon-nonstandard\"></use>\n</svg> <span title=\"Cette valeur ne peut pas être changée.\" class=\"badge inline readonly\">Lecture seule </span></dt>\n  <dd>\n    <p>Sur Firefox OS, utilisé pour renvoyer la piste audio dans laquelle sera jouée le son qui sera lancé dans le contexte audio.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"event_handlers","title":"Event handlers","isH3":true,"content":"<dl>\n  <dt id=\"audiocontext.onstatechange_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/statechange_event\"><code>AudioContext.onstatechange</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Un gestionnaire d'évènement déclenché par un évènement du type <code>statechange</code>. Cela a lieu quand l'état du contexte audio change, en raison de l'appel des méthodes de changement d'état (<a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/suspend\"><code>AudioContext.suspend</code> <small>(en-US)</small></a>, <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>AudioContext.resume</code> <small>(en-US)</small></a>, ou <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/close\"><code>AudioContext.close</code> <small>(en-US)</small></a>.)</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"méthodes","title":"Méthodes","isH3":false,"content":"<p><em>Met également en œuvre des méthodes de l'interface <a href=\"/fr/docs/Web/API/EventTarget\"><code>EventTarget</code></a>.</em></p>\n<dl>\n  <dt id=\"audiocontext.close_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/close\"><code>AudioContext.close()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Supprime le contexte audio, et libère toutes les ressources audio système qu'il utilisait.</p>\n  </dd>\n  <dt id=\"audiocontext.createbuffer_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createBuffer\"><code>AudioContext.createBuffer()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un nouvel objet <a href=\"/fr/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> vide, auquel on pourra assigner des données et que l'on pourra jouer via un <a href=\"/fr/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></p>\n  </dd>\n  <dt id=\"audiocontext.createbuffersource_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createBufferSource\"><code>AudioContext.createBufferSource()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a href=\"/fr/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a>, qui peut être utilisé pour jouer et manipuler des données audio contenues dans un objet <a href=\"/fr/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a>. Les <a href=\"/fr/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a>s sont créés avec la fonction <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createBuffer\"><code>AudioContext.createBuffer</code> <small>(en-US)</small></a> ou retournés par la fonction <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/decodeAudioData\"><code>AudioContext.decodeAudioData</code> <small>(en-US)</small></a> quand elle décode une piste audio avec succès.</p>\n  </dd>\n  <dt id=\"audiocontext.createmediaelementsource\"><a href=\"/fr/docs/Web/API/AudioContext/createMediaElementSource\"><code>AudioContext.createMediaElementSource()</code></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code> <small>(en-US)</small></a> associé à <a href=\"/fr/docs/Web/API/HTMLMediaElement\"><code>HTMLMediaElement</code></a>. Il peut être utilisé pour manipuler le son d'éléments <a href=\"/fr/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a> ou <a href=\"/fr/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a>.</p>\n  </dd>\n  <dt id=\"audiocontext.createmediastreamsource_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamSource\"><code>AudioContext.createMediaStreamSource()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a href=\"/fr/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a> associé à un <a href=\"/fr/docs/Web/API/MediaStream\"><code>MediaStream</code></a> correspondant à un flux audio, qui peut provenir du microphone de l'ordinateur local ou d'autres sources.</p>\n  </dd>\n  <dt id=\"audiocontext.createmediastreamdestination_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/createMediaStreamDestination\"><code>AudioContext.createMediaStreamDestination()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code> <small>(en-US)</small></a> associé à un <a href=\"/fr/docs/Web/API/MediaStream\"><code>MediaStream</code></a> correspondant à un flux audio, qui peut être stocké dans un fichier local ou envoyé à un autre ordinateur.</p>\n  </dd>\n  <dt id=\"audiocontext.createscriptprocessor_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor\"><code>AudioContext.createScriptProcessor()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ScriptProcessorNode\"><code>ScriptProcessorNode</code> <small>(en-US)</small></a> qui sert à faire du traitement audio directement avec JavaScript.</p>\n  </dd>\n  <dt id=\"audiocontext.createstereopanner_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createStereoPanner\"><code>AudioContext.createStereoPanner()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code> <small>(en-US)</small></a> qui permet d'appliquer une panoramique sonore à une source audio.</p>\n  </dd>\n  <dt id=\"audiocontext.createanalyser_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createAnalyser\"><code>AudioContext.createAnalyser()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a href=\"/fr/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a> qui expose les données de temps et de fréquence, et peut être utilisé pour créer des visualisations de données.</p>\n  </dd>\n</dl><!---->\n<dl>\n  <dt id=\"audiocontext.createbiquadfilter_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createBiquadFilter\"><code>AudioContext.createBiquadFilter()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a href=\"/fr/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a>, qui représente un filtre de deuxième niveau, qui combine différents types de filtres de base : fréquences hautes, fréquences basses, passe-bande, etc.</p>\n  </dd>\n</dl><!---->\n<dl>\n  <dt id=\"audiocontext.createchannelmerger_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createChannelMerger\"><code>AudioContext.createChannelMerger()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code> <small>(en-US)</small></a> qui permet de rassembler les canaux de différents flux audio en un seul flux.</p>\n  </dd>\n  <dt id=\"audiocontext.createchannelsplitter_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createChannelSplitter\"><code>AudioContext.createChannelSplitter()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code> <small>(en-US)</small></a> utilisé pour accéder aux différents canaux d'un même flux audio et les traiter séparément.</p>\n  </dd>\n  <dt id=\"audiocontext.createconvolver_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createConvolver\"><code>AudioContext.createConvolver()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code> <small>(en-US)</small></a>, qui permet d'appliquer des effets de convolution à un graphe audio, par exemple un effet de réverb.</p>\n  </dd>\n  <dt id=\"audiocontext.createdelay_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createDelay\"><code>AudioContext.createDelay()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code> <small>(en-US)</small></a>, utilisé pour retarder le signal audio entrant d'un certain temps. Il est également</p>\n  </dd>\n  <dt id=\"audiocontext.createdynamicscompressor_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createDynamicsCompressor\"><code>AudioContext.createDynamicsCompressor()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code> <small>(en-US)</small></a> qui permet d'appliquer une compression sur un signal audio.</p>\n  </dd>\n  <dt id=\"audiocontext.creategain\"><a href=\"/fr/docs/Web/API/BaseAudioContext/createGain\"><code>AudioContext.createGain()</code></a></dt>\n  <dd>\n    <p>Crée un objet <a href=\"/fr/docs/Web/API/GainNode\"><code>GainNode</code></a> qui permet de controller le niveau sonore global d'un graphe audio.</p>\n  </dd>\n  <dt id=\"audiocontext.createiirfilter_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createIIRFilter\"><code>AudioContext.createIIRFilter()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code> <small>(en-US)</small></a>, qui représente un filtre de second ordre configurable comme différents types de filtres communs.</p>\n  </dd>\n  <dt id=\"audiocontext.createoscillator_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createOscillator\"><code>AudioContext.createOscillator()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a href=\"/fr/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a> qui représente une onde périodique. Il génère simplement un son.</p>\n  </dd>\n  <dt id=\"audiocontext.createpanner_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createPanner\"><code>AudioContext.createPanner()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code> <small>(en-US)</small></a> utilisé pour spatialiser une source audio entrante dans un espace 3D.</p>\n  </dd>\n  <dt id=\"audiocontext.createperiodicwave_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createPeriodicWave\"><code>AudioContext.createPeriodicWave()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a href=\"/fr/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a>, utilisé pour définir une onde périodique qui peut être utilisée pour contrôler la sortie d'un <a href=\"/fr/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a>.</p>\n  </dd>\n  <dt id=\"audiocontext.createwaveshaper_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createWaveShaper\"><code>AudioContext.createWaveShaper()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code> <small>(en-US)</small></a>, qui permet d'implémenter des effets de distorsion non linéaires.</p>\n  </dd>\n  <dt id=\"audiocontext.createaudioworker\"><a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>AudioContext.createAudioWorker()</code></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>AudioWorkerNode</code></a>, qui permet d'interagir avec un thread web worker afin de générer, traiter, ou analyser le son directement. Ajouté à la spec le 29 août 2014, mais encore implémenté par aucun des navigateurs à ce jour.</p>\n  </dd>\n  <dt id=\"audiocontext.decodeaudiodata_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/decodeAudioData\"><code>AudioContext.decodeAudioData()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Décode de façon asynchrone les données d'un fichier audio contenues dans un objet <a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>ArrayBuffer</code></a>. Dans ce cas, le ArrayBuffer est en général chargé depuis un attribut de réponse <a href=\"/fr/docs/Web/API/XMLHttpRequest\"><code>XMLHttpRequest</code></a> quand l'attribut <code>responseType</code> est <code>arraybuffer</code>. Cette méthode ne fonctionne que sur des fichiers complets, pas sur des fragments de fichiers.</p>\n  </dd>\n  <dt id=\"audiocontext.resume_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/resume\"><code>AudioContext.resume()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Reprend le défilement du temps dans un contexte audio où il a précédemment été suspendu.</p>\n  </dd>\n  <dt id=\"audiocontext.suspend_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/AudioContext/suspend\"><code>AudioContext.suspend()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Suspend le défilement du temps dans un contexte audio, empêchant de façon temporaire l'accès au hardware audio, et réduisant par là l'utilisation du CPU et de la batterie.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"méthodes_obsolètes","title":"Méthodes obsolètes","isH3":false,"content":"<dl>\n  <dt id=\"audiocontext.createjavascriptnode_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor\"><code>AudioContext.createJavaScriptNode()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>JavaScriptNode</code></a>, utilisé pour un traitement audio directement en JavaScript. Cette méthode est obsolète, et a été remplacée par <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createScriptProcessor\"><code>AudioContext.createScriptProcessor()</code> <small>(en-US)</small></a>.</p>\n  </dd>\n  <dt id=\"audiocontext.createwavetable_en-us\"><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createPeriodicWave\"><code>AudioContext.createWaveTable()</code> <small>(en-US)</small></a></dt>\n  <dd>\n    <p>Crée un objet <a class=\"page-not-created\" title=\"Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant&nbsp;!\"><code>WaveTableNode</code></a>, utilisé pour définir une onde audio périodique. Cette méthode est obsolète, et a été remplacée par <a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/BaseAudioContext/createPeriodicWave\"><code>AudioContext.createPeriodicWave()</code> <small>(en-US)</small></a>.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"exemples","title":"Exemples","isH3":false,"content":"<p>Déclaration basique d'un audio context :</p>\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">var</span> contexteAudio <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">;</span>\n</code></pre></div>\n<p>Variante avec gestion de la compatibilité navigateur:</p>\n<div class=\"code-example\"><pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">var</span> AudioContext <span class=\"token operator\">=</span> window<span class=\"token punctuation\">.</span>AudioContext <span class=\"token operator\">||</span> window<span class=\"token punctuation\">.</span>webkitAudioContext<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> contexteAudio <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">var</span> oscillatorNode <span class=\"token operator\">=</span> contexteAudio<span class=\"token punctuation\">.</span><span class=\"token function\">createOscillator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> gainNode <span class=\"token operator\">=</span> contexteAudio<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> finish <span class=\"token operator\">=</span> contexteAudio<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">;</span>\n<span class=\"token comment\">// etc.</span>\n</code></pre></div>"}},{"type":"specifications","value":{"title":"Spécifications","id":"spécifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#AudioContext","title":"Web Audio API"}],"query":"api.AudioContext"}},{"type":"browser_compatibility","value":{"title":"Compatibilité des navigateurs","id":"compatibilité_des_navigateurs","isH3":false,"query":"api.AudioContext","dataURL":"/fr/docs/Web/API/AudioContext/bcd.json"}},{"type":"prose","value":{"id":"voir_aussi","title":"Voir aussi","isH3":false,"content":"<ul>\n  <li><a href=\"/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API\" class=\"only-in-en-us\" title=\"Currently only available in English (US)\">Utiliser la Web Audio API (en-US)</a></li>\n  <li><a class=\"only-in-en-us\" title=\"Currently only available in English (US)\" href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code> <small>(en-US)</small></a></li>\n</ul>"}}],"toc":[{"text":"Constructeur","id":"constructeur"},{"text":"Propriétés","id":"propriétés"},{"text":"Méthodes","id":"méthodes"},{"text":"Méthodes obsolètes","id":"méthodes_obsolètes"},{"text":"Exemples","id":"exemples"},{"text":"Spécifications","id":"spécifications"},{"text":"Compatibilité des navigateurs","id":"compatibilité_des_navigateurs"},{"text":"Voir aussi","id":"voir_aussi"}],"summary":"L'interface AudioContext représente un graphe de traitement audio fait de modules audio reliés entre eux, chaque module correspondant à un AudioNode. Un contexte audio contrôle à la fois la création des nœuds qu'il contient et l'exécution du traitement audio, ou du décodage. On commence toujours par créer un contexte audio, et tout ce qui va se passer ensuite se situera dans ce contexte.","popularity":0,"modified":"2022-10-01T03:41:16.000Z","other_translations":[{"title":"AudioContext","locale":"en-US","native":"English (US)"},{"title":"AudioContext","locale":"ja","native":"日本語"},{"title":"AudioContext","locale":"ko","native":"한국어"},{"title":"AudioContext","locale":"pt-BR","native":"Português (do Brasil)"},{"title":"AudioContext","locale":"ru","native":"Русский"},{"title":"AudioContext","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"fr/web/api/audiocontext","github_url":"https://github.com/mdn/translated-content/blob/main/files/fr/web/api/audiocontext/index.md","last_commit_url":"https://github.com/mdn/translated-content/commit/921c46a374ab0a9f4cc809af0370f8c412e54701","filename":"index.md"},"parents":[{"uri":"/fr/docs/Web","title":"Technologies web pour développeurs"},{"uri":"/fr/docs/Web/API","title":"Référence Web API"},{"uri":"/fr/docs/Web/API/AudioContext","title":"AudioContext"}],"pageTitle":"AudioContext - Référence Web API | MDN","noIndexing":false}}